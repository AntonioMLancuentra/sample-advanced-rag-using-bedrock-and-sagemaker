{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92c5158-0cce-4ffa-bdab-6a397caba9ed",
   "metadata": {},
   "source": [
    "## Query Decomposition: Avoid semantic delutions in the queries\n",
    " * \"Semantic dilutions\" refer to the loss of meaning or relevance when chunks of text, intended to represent information for retrieval, become too large or lack semantic cohesion, leading to less accurate and useful results.\n",
    " * Semantic dilutions can be mitigated on the indexed documents side by applying optimized chunking strategies per each use case.\n",
    " * Query texts can also have semantic delutions when multiple contexts or topics are combined. This can be improved by reforming the queries.\n",
    "\n",
    "This notebook will demonstrate \"query decomposition\" strategy to improve the search quality against a knowledge base. \n",
    "\n",
    "![Query Decomposition](https://raw.githubusercontent.com/aws-samples/langgraph-agents-with-amazon-bedrock/refs/heads/main/assets/lab3_2.png \"https://github.com/aws-samples/langgraph-agents-with-amazon-bedrock/tree/main/Lab_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd964ae-e143-4ce6-b242-978c4d29bcdc",
   "metadata": {},
   "source": [
    "#### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1782f4-a89d-4044-bff6-05e038aeb7de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import advanced_rag_utils\n",
    "\n",
    "# Reload module\n",
    "importlib.reload(advanced_rag_utils)\n",
    "\n",
    "# Re-import all functions\n",
    "from advanced_rag_utils import *\n",
    "\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "notebook_start_time = datetime.now(UTC)\n",
    "suppress_warnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f773f-683c-4bc4-918b-15a086080bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load variables from the JSON file\n",
    "import json\n",
    "with open(\"../variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229c2a7-12f9-4965-aeec-8f869fd41cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get KB configuration\n",
    "kb_config = get_kb_config(\n",
    "    kb_id=variables[\"kbSemanticChunk\"],\n",
    "    account_number=variables['accountNumber'],\n",
    "    region_name=variables['regionName'],\n",
    "    number_of_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ebee40",
   "metadata": {},
   "source": [
    "### How Model Size Affects Table Interpretation  \n",
    "\n",
    "When querying Amazon's Operating Income for 2022, **smaller models (Nova Lite, Llama 3B)** tend to pick the **\"At Prior Year Rates\"** value (\\$11,387), while **larger models (Nova Pro)** correctly select the **\"As Reported\"** value (\\$12,248).\n",
    "\n",
    "#### Possible Reasons:\n",
    "- **Table Parsing Limitations:** Smaller models may not accurately align column headers to values.  \n",
    "- **Context Misinterpretation:** They might default to the last numerical column or fail to strongly associate **\"As Reported\"** with the correct column.  \n",
    "- **Stronger Reasoning in Larger Models:** Nova Pro better understands structured data, leading to more accurate retrieval.  \n",
    "\n",
    "![Image](./operating_income.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5130cdb-5d9f-4c5c-9a68-2352026616fb",
   "metadata": {},
   "source": [
    "### Basic RAG query\n",
    "The query retrieves only one of the topics mentioned. It is because of the mix of two queries dilluted the second topic, which is called \"semantic dillution.\"\n",
    "In real world scenarios, it is required to pull multiple chunks with different contexts, for example:\n",
    "* How Amazon's net income increased from 2018 to 2024?\n",
    "* What is difference between RAG and text-to-SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60064755-7215-4b10-9246-30b53697e677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WITHOUT QUERY DECOMPOSITION\n",
    "\n",
    "# Query example\n",
    "query = \"What was Amazon's Operating Income as reported for the fiscal year ending December 31, 2022? What is text-to-SQL? How did text-to-SQL contribute to Amazons earnings, if any?\"\n",
    "\n",
    "# Perform basic RAG without query decomposition\n",
    "response = retrieve_and_generate_basic(\n",
    "    query=query, \n",
    "    kb_id=kb_config[\"kb_id\"], \n",
    "    model_id=kb_config[\"model_id\"], \n",
    "    generation_configuration=kb_config[\"generation_configuration\"],\n",
    "    number_of_results=kb_config[\"number_of_results\"],\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display_rag_results(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c25c30-3314-4790-a9bc-dac071ebde6b",
   "metadata": {},
   "source": [
    "### Use Amazon Bedrock API feature to decompose a query.\n",
    "ReteriveAndGenerate API support built-in query decompose feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b21ca6-e1e7-4878-b9ff-0c5727f101cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WITH QUERY DECOMPOSITION\n",
    "\n",
    "# Use Nova Pro model for better table interpretation\n",
    "nova_pro_model_id = f\"arn:aws:bedrock:us-west-2:{variables['accountNumber']}:inference-profile/us.amazon.nova-pro-v1:0\"\n",
    "\n",
    "# Query example (same as before)\n",
    "query = \"What was Amazon's Operating Income as reported for the fiscal year ending December 31, 2022? What is text-to-SQL? How did text-to-SQL contribute to Amazons earnings, if any?\"\n",
    "\n",
    "# Perform RAG with query decomposition\n",
    "response = retrieve_and_generate_with_decomposition(\n",
    "    query=query, \n",
    "    kb_id=kb_config[\"kb_id\"], \n",
    "    model_id=nova_pro_model_id, \n",
    "    generation_configuration=kb_config[\"generation_configuration\"],\n",
    "    number_of_results=kb_config[\"number_of_results\"],\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display_rag_results(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807e57b-016b-48cd-a53d-cd0314b13d82",
   "metadata": {},
   "source": [
    "## Query Decomposition with Agentic RAG using SageMaker and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbf82a-c1c2-4637-941d-3909211043bb",
   "metadata": {},
   "source": [
    "#### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65baa6fd-8797-4265-879e-65b9523789a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up LangChain components\n",
    "llm, retriever = setup_langchain_components(\n",
    "    endpoint_name=variables[\"sagemakerLLMEndpoint\"],\n",
    "    kb_id=variables[\"kbSemanticChunk\"],\n",
    "    region_name=variables[\"regionName\"],\n",
    "    number_of_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca334e-6d0e-4763-8c1d-ef5e5199be6c",
   "metadata": {},
   "source": [
    "#### Test a complex query with plain Q&A chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22e3a7-4d3a-4fb4-9350-2d66474b4736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a simple QA chain\n",
    "qa_chain = create_qa_chain(retriever, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be0f15-b378-482c-844c-0e5e6fdb2e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query example\n",
    "query = \"What was the Operating Income of Amazon As Reported for the Year Ending December 31, 2022? What is text-to-SQL? How did text-to-SQL contribute to Amazons earnings, if any?\"\n",
    "\n",
    "# Invoke the QA chain\n",
    "answer = qa_chain.invoke(query)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceddc3b-4ca6-4309-ba9a-6a2e5fc4a064",
   "metadata": {},
   "source": [
    "### Query Decomposition using Agentic RAG with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35323e79-5336-4e1d-a5b4-fc274a977ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a custom output parser\n",
    "custom_parser = create_output_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf9355-e0db-4f00-b8c3-4522ba7f55d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up agentic RAG with query decomposition\n",
    "agent = setup_agentic_rag(retriever, llm)\n",
    "\n",
    "# Query example\n",
    "query = \"What was Amazon's Operating Income as reported for the fiscal year ending December 31, 2022? What is text-to-SQL? How did text-to-SQL contribute to Amazons earnings, if any?\"\n",
    "\n",
    "# Run the agent\n",
    "result = agent.run(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
