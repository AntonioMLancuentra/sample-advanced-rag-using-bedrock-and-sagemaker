{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fe8a71-6170-4caf-a3b9-e578c1c5f201",
   "metadata": {},
   "source": [
    "# Retrieval and Generation with Bedrock Foundational Models\n",
    "\n",
    "### Overview  \n",
    "This notebook demonstrates how to perform retrieval-augmented generation (RAG) using Amazon Bedrock's foundational models. It covers retrieving relevant documents from a knowledge base and generating responses based on the retrieved context.\n",
    "\n",
    "### Build your own Retrieval Augmented Generation (RAG) system\n",
    "When constructing your own retrieval augmented generation (RAG) system, you can leverage a retriever system and a generator system. The retriever can be an embedding model that identifies the relevant chunks from the vector database based on similarity scores. The generator can be a Large Language Model (LLM) that utilizes the model's capability to answer questions based on the retrieved results (also known as chunks). In the following sections, we will provide additional tips on how to optimize the prompts for your RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66330105-e1f4-46f3-9b36-9f7560407522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accountNumber': '989679345636',\n",
       " 'regionName': 'us-west-2',\n",
       " 'collectionArn': 'arn:aws:aoss:us-west-2:989679345636:collection/ny2d41n7rmju74rh4ue2',\n",
       " 'collectionId': 'ny2d41n7rmju74rh4ue2',\n",
       " 'vectorIndexName': 'ws-index-',\n",
       " 'bedrockExecutionRoleArn': 'arn:aws:iam::989679345636:role/advanced-rag-workshop-bedrock_execution_role-us-west-2',\n",
       " 's3Bucket': '989679345636-us-west-2-advanced-rag-workshop',\n",
       " 'kbFixedChunk': 'TYG3IXCHCX',\n",
       " 'kbSemanticChunk': 'N7ZHYZVLOX',\n",
       " 'kbHierarchicalChunk': 'UDPUVOULM1',\n",
       " 'kbCustomChunk': 'AD07GOEBQ2'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import advanced_rag_utils\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "# Reload module\n",
    "importlib.reload(advanced_rag_utils)\n",
    "\n",
    "# Re-import all functions\n",
    "from advanced_rag_utils import *\n",
    "\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "notebook_start_time = datetime.now(UTC)\n",
    "# Load variables from JSON file\n",
    "with open(\"../variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015ff66d-d470-42fe-aed1-fc3f238b64e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing file: /home/sagemaker-user/brsk-GTM/Advanced_RAG_Workshop/simplified_labs/embed_algo_costs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_algo</th>\n",
       "      <th>embedding_seconds</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>invocation_count</th>\n",
       "      <th>total_token_costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed</td>\n",
       "      <td>54.113933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semantic</td>\n",
       "      <td>122.857522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hierarchical</td>\n",
       "      <td>56.829955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunking_algo  embedding_seconds  input_tokens  invocation_count  \\\n",
       "0         fixed          54.113933             0                 0   \n",
       "1      semantic         122.857522             0                 0   \n",
       "2  hierarchical          56.829955             0                 0   \n",
       "\n",
       "   total_token_costs  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_costs = load_df_from_csv()\n",
    "df_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03249f43",
   "metadata": {},
   "source": [
    "## RAG with a simple question\n",
    "\n",
    "##### We will ask the question \"In text-to-sql, what are the stages in data generation process?\" <br/>\n",
    "##### We should expect a response from a PDF shown below that includes the three stages shown in picture below.\n",
    "![Image](./image01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12750c99",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4199b3bd-3f66-4a29-9929-83cb9efa5723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Knowledge Base ID - Choose from different chunking strategies (Fixed, Hierarchical, or Semantic)\n",
    "kb_id = variables[\"kbFixedChunk\"] \n",
    "\n",
    "# Get the Bedrock Model ARN\n",
    "model_id = get_model_arn(\n",
    "    base_model_id=\"us.amazon.nova-lite-v1:0\",\n",
    "    account_number=variables['accountNumber'],\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Number of relevant documents to retrieve for RAG\n",
    "number_of_results = 5\n",
    "\n",
    "# Create default generation configuration\n",
    "generation_config = get_default_generation_config(\n",
    "    max_tokens=4096,\n",
    "    temperature=0.2,\n",
    "    top_p=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29db82",
   "metadata": {},
   "source": [
    "### Retrieve and Generate with a simple query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de00f7db-57bc-4a91-b9dc-6ba3fef14917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Answer ---------------------\n",
      "Answer: The data generation process in text-to-SQL involves three main stages:\n",
      "\n",
      "1. Database modification: This stage involves modifying the databases to create ambiguous or unanswerable examples corresponding to the designed categories.\n",
      "2. SQL modification and clarification response generation: In this stage, an LLM is used to convert the data into conversations between the user and a text-to-SQL assistant. The assistant's final SQL response is generated by modifying the original SQL programmatically, and the LLM is prompted to fill in the user's clarification response based on the conversation context.\n",
      "3. Refining the conversation and quality control: This stage involves using an LLM to improve the naturalness and coherence of the conversation and add a natural language explanation of the final SQL execution results. Additionally, a separate evaluation step is employed after each generation step to control the data quality.\n",
      "\n",
      "----------------- Citations ------------------\n",
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"fd688519-a0ad-4cef-864d-8430e8103bf6\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Wed, 30 Apr 2025 04:29:30 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"17303\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"fd688519-a0ad-4cef-864d-8430e8103bf6\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 235,\n",
      "            \"start\": 0\n",
      "          },\n",
      "          \"text\": \"Answer: The data generation process in text-to-SQL involves three main stages:\\n\\n1. Database modification: This stage involves modifying the databases to create ambiguous or unanswerable examples corresponding to the designed categories\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"27.Stage 3 - Refine     Conversation     Modified Schema     SQL Engine     LLM     LLM     Figure 1: An example of our conversational dataset construction consists of three stages: database modification, SQL modification along with clarification response generation, and refining the conversation. The top box depicts our data construction for an ambiguous question that requires clarification questions, while the bottom box illustrates an ambiguous question with direct helpful SQL responses. Here \\u2018U\\u2019 refers to a user and \\u2018A\\u2019 refers to a text-to-SQL assistant.     ous and unanswerable examples corresponding to these categories by parsing the SQLs and modify- ing the databases (Spider 3 is used in the current work, but the framework can be easily adapted to other text-to-SQL datasets). We then leverage an LLM to convert the data into conversations be- tween the user and a text-to-SQL assistant that in- cludes user initial questions, assistant clarification questions, user clarification responses, assistant SQL responses, SQL execution results, and natural language explanations of the execution results (as shown in Figure 1). In addition to having conver- sations where the assistant asks for clarification questions, we also generated more helpful SQL responses that included the results of all possible responses for some ambiguous question categories.\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 2.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"science\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3ApvyDg5YB_Wl5InOvy9qN\",\n",
      "            \"authors\": [\n",
      "              \"Marvin Dong\",\n",
      "              \"Nischal Ashok Kumar\",\n",
      "              \"Yiqun Hu\",\n",
      "              \"Anuj Chauhan\",\n",
      "              \"Chung-Wei Hang\",\n",
      "              \"Shuaichen Chang\",\n",
      "              \"Lin Pan\",\n",
      "              \"Wuwei Lan\",\n",
      "              \"Henry Zhu\",\n",
      "              \"Jiarong Jiang\",\n",
      "              \"Patrick Ng\",\n",
      "              \"Zhiguo Wang\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 410,\n",
      "            \"start\": 237\n",
      "          },\n",
      "          \"text\": \"2. SQL modification and clarification response generation: In this stage, an LLM is used to convert the data into conversations between the user and a text-to-SQL assistant\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"27.Stage 3 - Refine     Conversation     Modified Schema     SQL Engine     LLM     LLM     Figure 1: An example of our conversational dataset construction consists of three stages: database modification, SQL modification along with clarification response generation, and refining the conversation. The top box depicts our data construction for an ambiguous question that requires clarification questions, while the bottom box illustrates an ambiguous question with direct helpful SQL responses. Here \\u2018U\\u2019 refers to a user and \\u2018A\\u2019 refers to a text-to-SQL assistant.     ous and unanswerable examples corresponding to these categories by parsing the SQLs and modify- ing the databases (Spider 3 is used in the current work, but the framework can be easily adapted to other text-to-SQL datasets). We then leverage an LLM to convert the data into conversations be- tween the user and a text-to-SQL assistant that in- cludes user initial questions, assistant clarification questions, user clarification responses, assistant SQL responses, SQL execution results, and natural language explanations of the execution results (as shown in Figure 1). In addition to having conver- sations where the assistant asks for clarification questions, we also generated more helpful SQL responses that included the results of all possible responses for some ambiguous question categories.\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 2.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"science\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3ApvyDg5YB_Wl5InOvy9qN\",\n",
      "            \"authors\": [\n",
      "              \"Marvin Dong\",\n",
      "              \"Nischal Ashok Kumar\",\n",
      "              \"Yiqun Hu\",\n",
      "              \"Anuj Chauhan\",\n",
      "              \"Chung-Wei Hang\",\n",
      "              \"Shuaichen Chang\",\n",
      "              \"Lin Pan\",\n",
      "              \"Wuwei Lan\",\n",
      "              \"Henry Zhu\",\n",
      "              \"Jiarong Jiang\",\n",
      "              \"Patrick Ng\",\n",
      "              \"Zhiguo Wang\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 611,\n",
      "            \"start\": 412\n",
      "          },\n",
      "          \"text\": \"The assistant's final SQL response is generated by modifying the original SQL programmatically, and the LLM is prompted to fill in the user's clarification response based on the conversation context\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"Next, we follow a reverse-generation process (Hu et al., 2023) to first generate the assistant\\u2019s final SQL response and then generate the user\\u2019s clarification question. The assistant\\u2019s final SQL response is generated by modifying the original SQL programmatically. Then, we prompt the LLM to fill in the user\\u2019s clarification response based on the conversation context (initial user question, as- sistant\\u2019s clarification question, and final SQL re- sponses). For example, for the Ambiguous SE- LECT Column question, we generate the assis- tant\\u2019s clarified SQL by replacing the column in the SELECT clause of the original SQL with one of the ambiguous SELECT columns generated in the above stage. Then, given the user\\u2019s ini- tial question, the assistant\\u2019s clarification question, \\\"empty_user_clarification_response\\\", and the assis- tant\\u2019s final SQL response, we prompt the LLM to fill in the \\\"empty_user_clarification_response\\\" so that the user clarification response matches the as- sistant\\u2019s SQL response and rest of the conversation (see Prompt 5 for details). This process ensures that the assistant\\u2019s clarified SQL is more accurate and executable, as we are not prompting the LLM     to generate it, which could lead to incorrect SQL. Finally, we execute the constructed clarification SQLs against the modified databases and discard examples that are not executable. After the reverse generation and filtering, each sample includes the user\\u2019s initial question, the assistant\\u2019s clarification question, the user\\u2019s clarification response, the as- sistant\\u2019s SQL response, and its corresponding exe- cution results.     3.2.1 Generating helpful SQL for ambiguous questions     Because it is not always helpful for the assistant to ask clarification questions for ambiguous/unan- swerable queries, we also generate helpful SQL responses to the Ambiguous SELECT Column and Ambiguous WHERE Column queries and reversely generate the corresponding assistant\\u2019s explanation of why the SQL response is helpful. For Am- biguous SELECT Column queries, we sometimes can simply return all valid interpretations of the columns in the SQL. For example, suppose the question \\\"What is the maximum capacity of all sta- diums?\\\" is ambiguous because capacity can map to either \\\"Standing Capacity\\\" or \\\"Seating Capacity\\\". In that case, we can return both capacity columns, reducing the number of turns for the user to get the information they need. We only generate such help- ful SQL responses for the Ambiguous SELECT Column and Ambiguous WHERE Column cate- gories, but this can be extended to other categories in the future.     3.3 Stage 3: Refining the conversation & Quality Control     Leveraging an LLM, as a post-processing step (Wang et al., 2023b), we use a 3-shot prompt to improve the naturalness and coherence of the con- versation and add a natural language explanation of the final SQL execution results (see Prompt 6 & 7 for details). We randomly select 3 examples of the original conversation (as obtained from Stage 2), rewrite it more naturally and coherently, and add a natural language explanation of the execution results.     In addition to the main steps for generating the data, we employ a separate evaluation step after each generation step to control the data quality besides optimizing the generation prompt. The fil- tering step uses both LLM and execution checks. The LLM is often used to evaluate the quality of the data generated from the previous step or rankdifferent candidates if multiple candidates have been generated. For example, for an ambiguous SELECT column question, suppose we have gener- ated \\\"Standing Capacity\\\" or \\\"Seating Capacity\\\" as alternative columns for the question \\\"What is the maximum capacity of all stadiums?\\\". We will have a separate prompt and a few-shot examples for the LLM to evaluate whether these two columns are good candidates and make the question ambigu- ous. For execution checks, whenever we make a database change or generate modified SQLs, we execute these SQLs against the modified database to ensure the SQLs are executable.     Lastly, after generating data for each category, we prompted a LLM to perform binary classifica- tion on whether the provided question and modified database pair belonged to the designed category or not. This classification was based on the definition of the category and several human-curated exam- ples (see Prompt 8 for details). We only retained the examples that passed this binary classification, ensuring that the generated data accurately repre- sented the intended ambiguous or unanswerable category.     3.4 Dataset Statistics Table 3 shows the statistics of the dataset generated using the Spider dev set with Claude 3 sonnet. Note that the employed methodology can be seamlessly adapted to other text-to-SQL datasets like BIRD, WikiSQL, or any other synthetically generated an- swerable text-to-SQL corpora combined with any LLM (e.g., Llama3.1 or mixtral).\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 5.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"science\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"KSN1TIE8W5\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AFU0-r5UBZuowdich4RL1\",\n",
      "            \"authors\": [\n",
      "              \"Marvin Dong\",\n",
      "              \"Nischal Ashok Kumar\",\n",
      "              \"Yiqun Hu\",\n",
      "              \"Anuj Chauhan\",\n",
      "              \"Chung-Wei Hang\",\n",
      "              \"Shuaichen Chang\",\n",
      "              \"Lin Pan\",\n",
      "              \"Wuwei Lan\",\n",
      "              \"Henry Zhu\",\n",
      "              \"Jiarong Jiang\",\n",
      "              \"Patrick Ng\",\n",
      "              \"Zhiguo Wang\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 831,\n",
      "            \"start\": 613\n",
      "          },\n",
      "          \"text\": \"3. Refining the conversation and quality control: This stage involves using an LLM to improve the naturalness and coherence of the conversation and add a natural language explanation of the final SQL execution results\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"27.Stage 3 - Refine     Conversation     Modified Schema     SQL Engine     LLM     LLM     Figure 1: An example of our conversational dataset construction consists of three stages: database modification, SQL modification along with clarification response generation, and refining the conversation. The top box depicts our data construction for an ambiguous question that requires clarification questions, while the bottom box illustrates an ambiguous question with direct helpful SQL responses. Here \\u2018U\\u2019 refers to a user and \\u2018A\\u2019 refers to a text-to-SQL assistant.     ous and unanswerable examples corresponding to these categories by parsing the SQLs and modify- ing the databases (Spider 3 is used in the current work, but the framework can be easily adapted to other text-to-SQL datasets). We then leverage an LLM to convert the data into conversations be- tween the user and a text-to-SQL assistant that in- cludes user initial questions, assistant clarification questions, user clarification responses, assistant SQL responses, SQL execution results, and natural language explanations of the execution results (as shown in Figure 1). In addition to having conver- sations where the assistant asks for clarification questions, we also generated more helpful SQL responses that included the results of all possible responses for some ambiguous question categories.\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 2.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"science\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3ApvyDg5YB_Wl5InOvy9qN\",\n",
      "            \"authors\": [\n",
      "              \"Marvin Dong\",\n",
      "              \"Nischal Ashok Kumar\",\n",
      "              \"Yiqun Hu\",\n",
      "              \"Anuj Chauhan\",\n",
      "              \"Chung-Wei Hang\",\n",
      "              \"Shuaichen Chang\",\n",
      "              \"Lin Pan\",\n",
      "              \"Wuwei Lan\",\n",
      "              \"Henry Zhu\",\n",
      "              \"Jiarong Jiang\",\n",
      "              \"Patrick Ng\",\n",
      "              \"Zhiguo Wang\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 941,\n",
      "            \"start\": 833\n",
      "          },\n",
      "          \"text\": \"Additionally, a separate evaluation step is employed after each generation step to control the data quality\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"27.Stage 3 - Refine     Conversation     Modified Schema     SQL Engine     LLM     LLM     Figure 1: An example of our conversational dataset construction consists of three stages: database modification, SQL modification along with clarification response generation, and refining the conversation. The top box depicts our data construction for an ambiguous question that requires clarification questions, while the bottom box illustrates an ambiguous question with direct helpful SQL responses. Here \\u2018U\\u2019 refers to a user and \\u2018A\\u2019 refers to a text-to-SQL assistant.     ous and unanswerable examples corresponding to these categories by parsing the SQLs and modify- ing the databases (Spider 3 is used in the current work, but the framework can be easily adapted to other text-to-SQL datasets). We then leverage an LLM to convert the data into conversations be- tween the user and a text-to-SQL assistant that in- cludes user initial questions, assistant clarification questions, user clarification responses, assistant SQL responses, SQL execution results, and natural language explanations of the execution results (as shown in Figure 1). In addition to having conver- sations where the assistant asks for clarification questions, we also generated more helpful SQL responses that included the results of all possible responses for some ambiguous question categories.\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/practiq-a-practical-conversational-text-to-sql-dataset-with-ambiguous-and-unanswerable-queries.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 2.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"science\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3ApvyDg5YB_Wl5InOvy9qN\",\n",
      "            \"authors\": [\n",
      "              \"Marvin Dong\",\n",
      "              \"Nischal Ashok Kumar\",\n",
      "              \"Yiqun Hu\",\n",
      "              \"Anuj Chauhan\",\n",
      "              \"Chung-Wei Hang\",\n",
      "              \"Shuaichen Chang\",\n",
      "              \"Lin Pan\",\n",
      "              \"Wuwei Lan\",\n",
      "              \"Henry Zhu\",\n",
      "              \"Jiarong Jiang\",\n",
      "              \"Patrick Ng\",\n",
      "              \"Zhiguo Wang\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"output\": {\n",
      "    \"text\": \"Answer: The data generation process in text-to-SQL involves three main stages:\\n\\n1. Database modification: This stage involves modifying the databases to create ambiguous or unanswerable examples corresponding to the designed categories.\\n2. SQL modification and clarification response generation: In this stage, an LLM is used to convert the data into conversations between the user and a text-to-SQL assistant. The assistant's final SQL response is generated by modifying the original SQL programmatically, and the LLM is prompted to fill in the user's clarification response based on the conversation context.\\n3. Refining the conversation and quality control: This stage involves using an LLM to improve the naturalness and coherence of the conversation and add a natural language explanation of the final SQL execution results. Additionally, a separate evaluation step is employed after each generation step to control the data quality.\"\n",
      "  },\n",
      "  \"sessionId\": \"2828a847-3164-4739-8262-60ca0b65c3a6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = \"In text-to-sql, what are the stages in data generation process?\"\n",
    "\n",
    "# Perform retrieval-augmented generation (RAG)\n",
    "response = retrieve_and_generate(\n",
    "    query=query,\n",
    "    kb_id=kb_id,\n",
    "    model_id=model_id,\n",
    "    number_of_results=number_of_results,\n",
    "    generation_config=generation_config,\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Display the results with citations\n",
    "display_rag_results(response, show_citations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7e3a8-5b2f-42de-83dd-e85344ffcdcd",
   "metadata": {},
   "source": [
    "### Comparison between chunking strategies: Fixed vs Semantic\n",
    "\n",
    "##### Now, Let's ask a more nuanced question that needs to extract information from a table in the PDF. Also, let's ask it to do some analysis. <br/>\n",
    "##### We will also compare the response quality when you use fixed size chunking vs Semantic chunking.\n",
    "![image02](image02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e88b9-613a-42cc-ac54-f827902f572f",
   "metadata": {},
   "source": [
    "#### A nuanced query with a Fixed-sized chunking strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb27652-e52e-4dcf-a0e1-6c29f473b52c",
   "metadata": {},
   "source": [
    "##### We will ask question that should answer how net income changed rom 2022 to 2023 to 20234.\n",
    "![image03](image03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bd4f32-234b-4719-abd5-f50d91206aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuration for fixed chunking strategy\n",
    "kb_id_fixed = variables[\"kbFixedChunk\"]\n",
    "\n",
    "# Model ID remains the same\n",
    "model_id = get_model_arn(\n",
    "    base_model_id=\"us.amazon.nova-lite-v1:0\",\n",
    "    account_number=variables['accountNumber'],\n",
    "    region_name=variables['regionName']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acba9900-a4ea-4f40-95f0-e8ad7b8b621f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Answer ---------------------\n",
      "Answer: The net income for the years 2022, 2023, and 2024 was -$2,722 million, $33,364 million, and $30,425 million, respectively. The net income increased by $33,087 million from 2022 to 2023 and decreased by $2,941 million from 2023 to 2024.\n",
      "\n",
      "----------------- Citations ------------------\n",
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"4963b1f1-d5ca-4d65-b8e4-b0695fd82c87\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Wed, 30 Apr 2025 04:29:32 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"6723\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"4963b1f1-d5ca-4d65-b8e4-b0695fd82c87\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 129,\n",
      "            \"start\": 0\n",
      "          },\n",
      "          \"text\": \"Answer: The net income for the years 2022, 2023, and 2024 was -$2,722 million, $33,364 million, and $30,425 million, respectively\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \": Net income (loss) 33,364 (2,722) 30,425 Adjustments to reconcile net income (loss) to net cash from operating activities:     Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 34,433 41,921 48,663 Stock-based compensation 12,757 19,621 24,023 Non-operating expense (income), net (14,306) 16,966 (748) Deferred income taxes (310) (8,148) (5,876)     Changes in operating assets and liabilities: Inventories (9,487) (2,592) 1,449 Accounts receivable, net and other (9,145) (8,622) (8,348) Other assets (9,018) (13,275) (12,265) Accounts payable 3,602 2,945 5,473 Accrued expenses and other 2,123 (1,558) (2,428) Unearned revenue 2,314 2,216 4,578     Net cash provided by (used in) operating activities 46,327 46,752 84,946 INVESTING ACTIVITIES: Purchases of property and equipment (61,053) (63,645) (52,729) Proceeds from property and equipment sales and incentives 5,657\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2024.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2024.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 37.0,\n",
      "            \"year\": 2024.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AgPyEg5YB_Wl5InOvBdwe\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \": Net income (loss) (2,722) 30,425 59,248 Adjustments to reconcile net income (loss) to net cash from operating activities:     Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 41,921 48,663 52,795 Stock-based compensation 19,621 24,023 22,011 Non-operating expense (income), net 16,966 (748) 2,012 Deferred income taxes (8,148) (5,876) (4,648)     Changes in operating assets and liabilities: Inventories (2,592) 1,449 (1,884) Accounts receivable, net and other (8,622) (8,348) (3,249) Other assets (13,275) (12,265) (14,483) Accounts payable 2,945 5,473 2,972 Accrued expenses and other (1,558) (2,428) (2,904) Unearned revenue 2,216 4,578 4,007     Net cash provided by (used in) operating activities 46,752 84,946 115,877 INVESTING ACTIVITIES: Purchases of property and equipment (63,645) (52,729) (82,999) Proceeds from property and equipment sales and incentives 5,324\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AE_yDg5YB_Wl5InOv6dv9\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 243,\n",
      "            \"start\": 131\n",
      "          },\n",
      "          \"text\": \"The net income increased by $33,087 million from 2022 to 2023 and decreased by $2,941 million from 2023 to 2024.\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \": Net income (loss) 33,364 (2,722) 30,425 Adjustments to reconcile net income (loss) to net cash from operating activities:     Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 34,433 41,921 48,663 Stock-based compensation 12,757 19,621 24,023 Non-operating expense (income), net (14,306) 16,966 (748) Deferred income taxes (310) (8,148) (5,876)     Changes in operating assets and liabilities: Inventories (9,487) (2,592) 1,449 Accounts receivable, net and other (9,145) (8,622) (8,348) Other assets (9,018) (13,275) (12,265) Accounts payable 3,602 2,945 5,473 Accrued expenses and other 2,123 (1,558) (2,428) Unearned revenue 2,314 2,216 4,578     Net cash provided by (used in) operating activities 46,327 46,752 84,946 INVESTING ACTIVITIES: Purchases of property and equipment (61,053) (63,645) (52,729) Proceeds from property and equipment sales and incentives 5,657\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2024.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2024.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 37.0,\n",
      "            \"year\": 2024.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AgPyEg5YB_Wl5InOvBdwe\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \": Net income (loss) (2,722) 30,425 59,248 Adjustments to reconcile net income (loss) to net cash from operating activities:     Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 41,921 48,663 52,795 Stock-based compensation 19,621 24,023 22,011 Non-operating expense (income), net 16,966 (748) 2,012 Deferred income taxes (8,148) (5,876) (4,648)     Changes in operating assets and liabilities: Inventories (2,592) 1,449 (1,884) Accounts receivable, net and other (8,622) (8,348) (3,249) Other assets (13,275) (12,265) (14,483) Accounts payable 2,945 5,473 2,972 Accrued expenses and other (1,558) (2,428) (2,904) Unearned revenue 2,216 4,578 4,007     Net cash provided by (used in) operating activities 46,752 84,946 115,877 INVESTING ACTIVITIES: Purchases of property and equipment (63,645) (52,729) (82,999) Proceeds from property and equipment sales and incentives 5,324\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AE_yDg5YB_Wl5InOv6dv9\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"output\": {\n",
      "    \"text\": \"Answer: The net income for the years 2022, 2023, and 2024 was -$2,722 million, $33,364 million, and $30,425 million, respectively. The net income increased by $33,087 million from 2022 to 2023 and decreased by $2,941 million from 2023 to 2024.\"\n",
      "  },\n",
      "  \"sessionId\": \"06d05cfe-f787-4419-a7c7-cd9ca8001b6b\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the query for comparing net income changes\n",
    "query = \"In CONSOLIDATED STATEMENTS OF CASH FLOWS, How much did net income change in years 2022, 2023, 2024?\"\n",
    "\n",
    "# Perform RAG with fixed chunking strategy\n",
    "response_fixed = retrieve_and_generate(\n",
    "    query=query,\n",
    "    kb_id=kb_id_fixed,\n",
    "    model_id=model_id,\n",
    "    number_of_results=number_of_results,\n",
    "    generation_config=generation_config,\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display_rag_results(response_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51bc3d-39ee-4791-a763-f8285f130e29",
   "metadata": {},
   "source": [
    "#### The response above might not be accurate with what it should be.The accurate response should be:\n",
    "\n",
    "> Year 2022 to Year 2023: \\\\$33,147 increase<br/>\n",
    "Year 2023 to Year 2024: \\\\$28,823 increase \n",
    "\n",
    "#### Now Let's execute the same question while using the KB with Semantic Chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc31f91-f6b0-4b7f-9b20-1732db0c2b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuration for semantic chunking strategy\n",
    "kb_id_semantic = variables[\"kbSemanticChunk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab14a1f-ea0c-4361-80b7-5d315beaad88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Answer ---------------------\n",
      "Answer: Here is the change in net income for each year:\n",
      "\n",
      "- 2022: Net income decreased by $36,086 million (from $33,364 million in 2021 to $-2,722 million in 2022) - 2023: Net income increased by $33,147 million (from $-2,722 million in 2022 to $30,425 million in 2023) - 2024: Net income increased by $28,823 million (from $30,425 million in 2023 to $59,248 million in 2024) Calculations:\n",
      "\n",
      "- 2022: $33,364 million (2021) - $-2,722 million (2022) = $36,086 million\n",
      "- 2023: $-2,722 million (2022) + $30,425 million (2023) = $33,147 million\n",
      "- 2024: $30,425 million (2023) + $59,248 million (2024) = $28,823 million\n",
      "\n",
      "----------------- Citations ------------------\n",
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"1b16f9db-5838-4172-907f-45039d88fb8d\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Wed, 30 Apr 2025 04:29:34 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"13457\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"1b16f9db-5838-4172-907f-45039d88fb8d\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 162,\n",
      "            \"start\": 0\n",
      "          },\n",
      "          \"text\": \"Answer: Here is the change in net income for each year:\\n\\n- 2022: Net income decreased by $36,086 million (from $33,364 million in 2021 to $-2,722 million in 2022)\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2021 2022 2023 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 42,377 $ 36,477 $ 54,253 OPERATING ACTIVITIES: Net income (loss) 33,364 (2,722) 30,425 Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 34,433 41,921 48,663 Stock-based compensation 12,757 19,621 24,023 Non-operating expense (income), net (14,306) 16,966 (748) Deferred income taxes (310) (8,148) (5,876) \\n \\n Changes in operating assets and liabilities: Inventories (9,487) (2,592) 1,449 Accounts receivable, net and other (9,145) (8,622) (8,348) Other assets (9,018) (13,275) (12,265) Accounts payable 3,602 2,945 5,473 Accrued expenses and other 2,123 (1,558) (2,428) Unearned revenue 2,314\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2024.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2024.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 37.0,\n",
      "            \"year\": 2024.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3Abk1Er5UBZuowdich6RXS\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2020 2021 2022 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 36,410 $ 42,377 $ 36,477 OPERATING ACTIVITIES: Net income (loss) 21,331 33,364 (2,722) Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 25,180 34,433 41,921 Stock-based compensation 9,208 12,757 19,621 Other expense (income), net (2,582) (14,306) 16,966 Deferred income taxes (554) (310) (8,148) \\n \\n Changes in operating assets and liabilities: Inventories (2,849) (9,487) (2,592) Accounts receivable, net and other (8,169) (18,163) (21,897) Accounts payable 17,480 3,602 2,945 Accrued expenses and other 5,754 2,123 (1,558) Unearned revenue 1,265 2,314 2,216 \\n \\n Net cash provided by (used in) operating activities\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2023.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2023.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3A4k1Er5UBZuowdich8xXo\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 270,\n",
      "            \"start\": 164\n",
      "          },\n",
      "          \"text\": \"- 2023: Net income increased by $33,147 million (from $-2,722 million in 2022 to $30,425 million in 2023)\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2021 2022 2023 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 42,377 $ 36,477 $ 54,253 OPERATING ACTIVITIES: Net income (loss) 33,364 (2,722) 30,425 Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 34,433 41,921 48,663 Stock-based compensation 12,757 19,621 24,023 Non-operating expense (income), net (14,306) 16,966 (748) Deferred income taxes (310) (8,148) (5,876) \\n \\n Changes in operating assets and liabilities: Inventories (9,487) (2,592) 1,449 Accounts receivable, net and other (9,145) (8,622) (8,348) Other assets (9,018) (13,275) (12,265) Accounts payable 3,602 2,945 5,473 Accrued expenses and other 2,123 (1,558) (2,428) Unearned revenue 2,314\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2024.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2024.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 37.0,\n",
      "            \"year\": 2024.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3Abk1Er5UBZuowdich6RXS\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2020 2021 2022 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 36,410 $ 42,377 $ 36,477 OPERATING ACTIVITIES: Net income (loss) 21,331 33,364 (2,722) Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 25,180 34,433 41,921 Stock-based compensation 9,208 12,757 19,621 Other expense (income), net (2,582) (14,306) 16,966 Deferred income taxes (554) (310) (8,148) \\n \\n Changes in operating assets and liabilities: Inventories (2,849) (9,487) (2,592) Accounts receivable, net and other (8,169) (18,163) (21,897) Accounts payable 17,480 3,602 2,945 Accrued expenses and other 5,754 2,123 (1,558) Unearned revenue 1,265 2,314 2,216 \\n \\n Net cash provided by (used in) operating activities\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2023.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2023.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3A4k1Er5UBZuowdich8xXo\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 378,\n",
      "            \"start\": 272\n",
      "          },\n",
      "          \"text\": \"- 2024: Net income increased by $28,823 million (from $30,425 million in 2023 to $59,248 million in 2024)\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2022 2023 2024 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 36,477 $ 54,253 $ 73,890 OPERATING ACTIVITIES: Net income (loss) (2,722) 30,425 59,248 Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 41,921 48,663 52,795 Stock-based compensation 19,621 24,023 22,011 Non-operating expense (income), net 16,966 (748) 2,012 Deferred income taxes (8,148) (5,876) (4,648) \\n \\n Changes in operating assets and liabilities: Inventories (2,592) 1,449 (1,884) Accounts receivable, net and other (8,622) (8,348) (3,249) Other assets (13,275) (12,265) (14,483) Accounts payable 2,945 5,473 2,972 Accrued expenses and other (1,558) (2,428) (2,904) Unearned revenue\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"8JWHIAELKL\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AvvyHg5YB_Wl5InOvhd2W\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2022 2023 2024 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 36,477 $ 54,253 $ 73,890 OPERATING ACTIVITIES: Net income (loss) (2,722) 30,425 59,248 Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 41,921 48,663 52,795 Stock-based compensation 19,621 24,023 22,011 Non-operating expense (income), net 16,966 (748) 2,012 Deferred income taxes (8,148) (5,876) (4,648) \\n \\n Changes in operating assets and liabilities: Inventories (2,592) 1,449 (1,884) Accounts receivable, net and other (8,622) (8,348) (3,249) Other assets (13,275) (12,265) (14,483) Accounts payable 2,945 5,473 2,972 Accrued expenses and other (1,558) (2,428) (2,904) Unearned revenue\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2025.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2025.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2025.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3ARfBEr5UBOAugvTnq256n\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 617,\n",
      "            \"start\": 380\n",
      "          },\n",
      "          \"text\": \"Calculations:\\n\\n- 2022: $33,364 million (2021) - $-2,722 million (2022) = $36,086 million\\n- 2023: $-2,722 million (2022) + $30,425 million (2023) = $33,147 million\\n- 2024: $30,425 million (2023) + $59,248 million (2024) = $28,823 million\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2021 2022 2023 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 42,377 $ 36,477 $ 54,253 OPERATING ACTIVITIES: Net income (loss) 33,364 (2,722) 30,425 Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 34,433 41,921 48,663 Stock-based compensation 12,757 19,621 24,023 Non-operating expense (income), net (14,306) 16,966 (748) Deferred income taxes (310) (8,148) (5,876) \\n \\n Changes in operating assets and liabilities: Inventories (9,487) (2,592) 1,449 Accounts receivable, net and other (9,145) (8,622) (8,348) Other assets (9,018) (13,275) (12,265) Accounts payable 3,602 2,945 5,473 Accrued expenses and other 2,123 (1,558) (2,428) Unearned revenue 2,314\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2024.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2024.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 37.0,\n",
      "            \"year\": 2024.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3Abk1Er5UBZuowdich6RXS\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"CONSOLIDATED STATEMENTS OF CASH FLOWS \\n \\n (in millions) Year Ended December 31, 2020 2021 2022 \\n \\n CASH, CASH EQUIVALENTS, AND RESTRICTED CASH, BEGINNING OF PERIOD $ 36,410 $ 42,377 $ 36,477 OPERATING ACTIVITIES: Net income (loss) 21,331 33,364 (2,722) Adjustments to reconcile net income (loss) to net cash from operating activities: \\n \\n Depreciation and amortization of property and equipment and capitalized content costs, operating lease assets, and other 25,180 34,433 41,921 Stock-based compensation 9,208 12,757 19,621 Other expense (income), net (2,582) (14,306) 16,966 Deferred income taxes (554) (310) (8,148) \\n \\n Changes in operating assets and liabilities: Inventories (2,849) (9,487) (2,592) Accounts receivable, net and other (8,169) (18,163) (21,897) Accounts payable 17,480 3,602 2,945 Accrued expenses and other 5,754 2,123 (1,558) Unearned revenue 1,265 2,314 2,216 \\n \\n Net cash provided by (used in) operating activities\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2023.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 36.0,\n",
      "            \"year\": 2023.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"CAK2UZC83T\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3A4k1Er5UBZuowdich8xXo\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"output\": {\n",
      "    \"text\": \"Answer: Here is the change in net income for each year:\\n\\n- 2022: Net income decreased by $36,086 million (from $33,364 million in 2021 to $-2,722 million in 2022) - 2023: Net income increased by $33,147 million (from $-2,722 million in 2022 to $30,425 million in 2023) - 2024: Net income increased by $28,823 million (from $30,425 million in 2023 to $59,248 million in 2024) Calculations:\\n\\n- 2022: $33,364 million (2021) - $-2,722 million (2022) = $36,086 million\\n- 2023: $-2,722 million (2022) + $30,425 million (2023) = $33,147 million\\n- 2024: $30,425 million (2023) + $59,248 million (2024) = $28,823 million\"\n",
      "  },\n",
      "  \"sessionId\": \"fda9f674-8185-4afe-9ff7-c9c62fc371f2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Enhance the query to request explanation of the calculation\n",
    "query_with_explanation = \"In CONSOLIDATED STATEMENTS OF CASH FLOWS, How much did net income change in years 2022, 2023, 2024? Show me how you did the math.\"\n",
    "\n",
    "# Perform RAG with semantic chunking strategy\n",
    "response_semantic = retrieve_and_generate(\n",
    "    query=query_with_explanation,\n",
    "    kb_id=kb_id_semantic,\n",
    "    model_id=model_id,\n",
    "    number_of_results=number_of_results,\n",
    "    generation_config=generation_config,\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display_rag_results(response_semantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd5820-1e42-463d-8da3-0e59cebf3d27",
   "metadata": {},
   "source": [
    "Compare the above results with the accurate response that should be:\n",
    "> Year 2022 to Year 2023: \\\\$33,147 increase <br/>\n",
    "> Year 2023 to Year 2024: \\\\$28,823 increase\n",
    "\n",
    "As you can see here, Semantic Chunking was able to deliver accurate response as compared to Fixed Size chunking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c92234",
   "metadata": {},
   "source": [
    "## Improve RAG quality with Enhanced Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab045f5",
   "metadata": {},
   "source": [
    "### Importance of Prompt Engineering\n",
    "Prompt engineering refers to the practice of optimizing textual input to a large language model (LLM) to improve output and receive the responses you want. Prompting helps an LLM perform a wide variety of tasks, including classification, question answering, code generation, creative writing, and more. The quality of prompts that you provide to a LLM can impact the quality of the model's responses. <br/>\n",
    " \n",
    "\n",
    "### Useful techniques to improve prompts for Amazon Nova models\n",
    "Please refer [link](https://docs.aws.amazon.com/nova/latest/userguide/prompting.html) for the best practice of prompt engineering with Amazon Nova models. Fllowings are a few highlights:\n",
    "* Create precise prompts. Provide contextual information, speficy the output format and style, and provide clear prompt sections.\n",
    "* Use system propmts to define how the model will repond.\n",
    "* Give Amazon Nova time to think. For example, add ```\"Think step-by-step.\"``` at the end of your query.\n",
    "* Provide examples.\n",
    "\n",
    "### Tips for using prompts in RAG\n",
    "* Provide Prompt Template: As with other functionalities, enhancing the system prompt can be beneficial. You can define the RAG Systems description in the system prompt, outlining the desired persona and behavior for the model.\n",
    "* Use Model Instructions: Additionally, you can include a dedicated ```\"Model Instructions:\"``` section within the system prompt, where you can provide specific guidelines for the model to follow. For instance, you can list instructions such as: ```In this example session, the model has access to search results and a user's question, its job is to answer the user's question using only information from the search results.```\n",
    "* Avoid Hallucination by restricting the instructions: Bring more focus to instructions by clearly mentioning \"DO NOT USE INFORMATION THAT IS NOT IN SEARCH RESULTS!\" as a model instruction so the answers are grounded in the provided context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa9d55-474d-403d-ac4f-ecf6a5914886",
   "metadata": {},
   "source": [
    "#### Without a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676924ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Answer ---------------------\n",
      "According to the search results, Amazon's net sales for the first quarter of 2023 were between $121.0 billion and $126.0 billion, with an operating income of between $0 and $4.0 billion.\n",
      "\n",
      "----------------- Citations ------------------\n",
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"63f4928d-9e11-4b9c-baca-363ea89eb0c9\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Wed, 30 Apr 2025 04:29:35 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"2409\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"63f4928d-9e11-4b9c-baca-363ea89eb0c9\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"generatedResponsePart\": {\n",
      "        \"textResponsePart\": {\n",
      "          \"span\": {\n",
      "            \"end\": 185,\n",
      "            \"start\": 0\n",
      "          },\n",
      "          \"text\": \"According to the search results, Amazon's net sales for the first quarter of 2023 were between $121.0 billion and $126.0 billion, with an operating income of between $0 and $4.0 billion\"\n",
      "        }\n",
      "      },\n",
      "      \"retrievedReferences\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"text\": \"These forward-looking statements reflect     Amazon.com\\u2019s expectations as of February 2, 2023, and are subject to substantial uncertainty. Our results are inherently unpredictable and may be materially affected by many factors, such as uncertainty regarding the impacts of the COVID-19 pandemic, fluctuations in foreign exchange rates, changes in global economic and geopolitical conditions and customer demand and spending (including the impact of recessionary fears), inflation, interest rates, regional labor market and global supply chain constraints, world events, the rate of growth of the Internet, online commerce, and cloud services, as well as those outlined in Item 1A of Part I, \\u201cRisk Factors.\\u201d     First Quarter 2023 Guidance     \\u2022 Net sales are expected to be between $121.0 billion and $126.0 billion, or to grow between 4% and 8% compared with first quarter 2022. This guidance anticipates an unfavorable impact of approximately 210 basis points from foreign exchange rates.     \\u2022 Operating income is expected to be between $0 and $4.0 billion, compared with $3.7 billion in first quarter 2022.     \\u2022 This guidance assumes, among other things, that no additional business acquisitions, restructurings, or legal settlements are concluded.     30Table of Contents     Item 7A.\",\n",
      "            \"type\": \"TEXT\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"s3Location\": {\n",
      "              \"uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2023.pdf\"\n",
      "            },\n",
      "            \"type\": \"S3\"\n",
      "          },\n",
      "          \"metadata\": {\n",
      "            \"x-amz-bedrock-kb-source-uri\": \"s3://989679345636-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "            \"x-amz-bedrock-kb-document-page-number\": 30.0,\n",
      "            \"year\": 2023.0,\n",
      "            \"docType\": \"10K Report\",\n",
      "            \"x-amz-bedrock-kb-data-source-id\": \"RKZYF7BRQM\",\n",
      "            \"company\": \"Amazon\",\n",
      "            \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AxQqDg5YBDm_VVXpU9_2D\",\n",
      "            \"authors\": [\n",
      "              \"Amazon\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"output\": {\n",
      "    \"text\": \"According to the search results, Amazon's net sales for the first quarter of 2023 were between $121.0 billion and $126.0 billion, with an operating income of between $0 and $4.0 billion.\"\n",
      "  },\n",
      "  \"sessionId\": \"d15142be-b902-40d0-8fdd-f3ea7a9007ff\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the query about Amazon's financial results\n",
    "query = \"Show me the amazon financial results for 2023\"\n",
    "\n",
    "# Perform RAG without prompt template\n",
    "response_no_template = retrieve_and_generate(\n",
    "    query=query,\n",
    "    kb_id=kb_id,\n",
    "    model_id=model_id,\n",
    "    number_of_results=number_of_results,\n",
    "    generation_config=generation_config,\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "display_rag_results(response_no_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d97251-3560-48c0-ad95-13f9ea4ca40a",
   "metadata": {},
   "source": [
    "#### Using a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772c4a54-54bc-4aa4-aba2-695d29da0ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Answer ---------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Answer: The data generation process in text-to-SQL involves three main stages:\n",
       "\n",
       "1. Database modification: This stage involves modifying the databases to create ambiguous or unanswerable examples corresponding to the designed categories.\n",
       "2. SQL modification and clarification response generation: In this stage, an LLM is used to convert the data into conversations between the user and a text-to-SQL assistant. The assistant's final SQL response is generated by modifying the original SQL programmatically, and the LLM is prompted to fill in the user's clarification response based on the conversation context.\n",
       "3. Refining the conversation and quality control: This stage involves using an LLM to improve the naturalness and coherence of the conversation and add a natural language explanation of the final SQL execution results. Additionally, a separate evaluation step is employed after each generation step to control the data quality."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a prompt template for financial analysis\n",
    "prompt_template = \"\"\"\n",
    "You are a professional financial analyst. \n",
    "Based on the retrieved content from Amazon's 10-K filings, provide clear, concise, and insightful answers to user questions. \n",
    "When summarizing financial results, respond in bullet points highlighting key metrics, trends, and takeaways. \n",
    "Ensure your answers are accurate, data-driven, and easy to understand.\n",
    "Format the output as Markdown document.\n",
    "\n",
    "$Query$\n",
    "Resource: $search_results$\n",
    "\"\"\"\n",
    "\n",
    "# Perform RAG with the prompt template\n",
    "response_with_template = retrieve_and_generate(\n",
    "    query=query,\n",
    "    kb_id=kb_id,\n",
    "    model_id=model_id,\n",
    "    number_of_results=number_of_results,\n",
    "    generation_config=generation_config,\n",
    "    prompt_template=prompt_template,\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Display the results as Markdown\n",
    "# display_rag_results(response_with_template, format_as_markdown=True)\n",
    "print('----------------- Answer ---------------------')\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response['output']['text'].replace(\"$\", \"USD \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f0bce-e2b8-41cc-8d72-fdba7a3ffa14",
   "metadata": {},
   "source": [
    "#### Change the prompt to produce JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02be6e6-b01b-4288-ac8f-93516a60fcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Answer ---------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"Amazon_Financial_Results_2023\": {\n",
       "    \"First_Quarter_2023_Guidance\": {\n",
       "      \"Net_Sales\": {\n",
       "        \"Expected_Range\": \"\\$121.0 billion to \\$126.0 billion\",\n",
       "        \"Growth_Range\": \"4% to 8% compared with first quarter 2022\",\n",
       "        \"Foreign_Exchange_Impact\": \"Unfavorable impact of approximately 210 basis points\"\n",
       "      },\n",
       "      \"Operating_Income\": {\n",
       "        \"Expected_Range\": \"\\$0 to \\$4.0 billion\",\n",
       "        \"Comparison_to_2022\": \"\\$3.7 billion in first quarter 2022\"\n",
       "      },\n",
       "      \"Assumptions\": [\n",
       "        \"No additional business acquisitions, restructurings, or legal settlements are concluded\"\n",
       "      ]\n",
       "    },\n",
       "    \"First_Quarter_2024_Guidance\": {\n",
       "      \"Net_Sales\": {\n",
       "        \"Expected_Range\": \"\\$138.0 billion to \\$143.5 billion\",\n",
       "        \"Growth_Range\": \"8% to 13% compared with first quarter 2023\",\n",
       "        \"Foreign_Exchange_Impact\": \"Favorable impact of approximately 40 basis points\"\n",
       "      },\n",
       "      \"Operating_Income\": {\n",
       "        \"Expected_Range\": \"\\$8.0 billion to \\$12.0 billion\",\n",
       "        \"Comparison_to_2023\": \"\\$4.8 billion in first quarter 2023\",\n",
       "        \"Depreciation_Expense_Impact\": \"Approximately \\$0.9 billion lower due to an increase in the estimated useful life of servers\"\n",
       "      },\n",
       "      \"Assumptions\": [\n",
       "        \"No additional business acquisitions, restructurings, or legal settlements are concluded\"\n",
       "      ]\n",
       "    },\n",
       "    \"First_Quarter_2025_Guidance\": {\n",
       "      \"Net_Sales\": {\n",
       "        \"Expected_Range\": \"\\$151.0 billion to \\$155.5 billion\",\n",
       "        \"Growth_Range\": \"5% to 9% compared with first quarter 2024\",\n",
       "        \"Foreign_Exchange_Impact\": \"Unusually large, unfavorable impact of approximately \\$2.1 billion, or 150 basis points\"\n",
       "      },\n",
       "      \"Operating_Income\": {\n",
       "        \"Expected_Range\": \"\\$14.0 billion to \\$18.0 billion\",\n",
       "        \"Comparison_to_2024\": \"\\$15.3 billion in first quarter 2024\"\n",
       "      },\n",
       "      \"Assumptions\": [\n",
       "        \"No additional business acquisitions, restructurings, or legal settlements are concluded\"\n",
       "      ]\n",
       "    }\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify the prompt template to request JSON output\n",
    "json_prompt_template = \"\"\"\n",
    "You are a professional financial analyst. \n",
    "Based on the retrieved content from Amazon's 10-K filings, provide clear, concise, and insightful answers to user questions. \n",
    "When summarizing financial results, respond in bullet points highlighting key metrics, trends, and takeaways. \n",
    "Ensure your answers are accurate, data-driven, and easy to understand.\n",
    "Format the output as JSON document.\n",
    "\n",
    "$Query$\n",
    "Resource: $search_results$\n",
    "\"\"\"\n",
    "\n",
    "# Perform RAG with JSON prompt template\n",
    "response = retrieve_and_generate(\n",
    "    query=query,\n",
    "    kb_id=kb_id,\n",
    "    model_id=model_id,\n",
    "    number_of_results=number_of_results,\n",
    "    generation_config=generation_config,\n",
    "    prompt_template=json_prompt_template,\n",
    "    region_name=variables['regionName']\n",
    ")\n",
    "\n",
    "# Display the results as Markdown to properly format the JSON\n",
    "print('----------------- Answer ---------------------')\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response['output']['text'].replace(\"$\", \"\\\\$\")))\n",
    "#display_rag_results(response_json, format_as_markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ada9fd-75f0-42ff-9d10-d6a10580305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"WARNING\": \"These costs are approximate and directional as of April 2025. They will vary as per region and may change in future. The costs are for Bedrock On-Demand model. If you see zero costs, chances are high that the LLM was not considered in cost calculations when the notebook was prepared. Please use AWS calculator for more accurate cost calculations.\",\n",
      "    \"model_id\": \"arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0\",\n",
      "    \"start_time\": \"2025-04-30T04:29:28.354771+00:00\",\n",
      "    \"end_time\": \"2025-04-30T04:29:42.434768+00:00\",\n",
      "    \"duration in minutes\": 0.2346666166666667,\n",
      "    \"input_tokens\": 0,\n",
      "    \"output_tokens\": 0,\n",
      "    \"invocation_count\": 0,\n",
      "    \"per million input token costs\": 0.0,\n",
      "    \"per million output token costs\": 0.0,\n",
      "    \"input token costs\": 0.0,\n",
      "    \"output token costs\": 0.0,\n",
      "    \"total token costs\": 0.0,\n",
      "    \"average token costs per invocation\": 0,\n",
      "    \"token costs per MILLION such invocations\": 0\n",
      "}\n",
      "Cost of running this notebook is approximately $0.0\n",
      "Cost of million such tokens approximately $0\n"
     ]
    }
   ],
   "source": [
    "model_id = 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0'\n",
    "foundational_model_id = 'arn:aws:bedrock:us-west-2:989679345636:inference-profile/us.amazon.nova-lite-v1:0'\n",
    "notebook_end_time = datetime.now(UTC)\n",
    "embedding_tokens = get_bedrock_tokens(model_id, notebook_start_time, notebook_end_time, 5)\n",
    "inference_tokens = get_bedrock_tokens(foundational_model_id, notebook_start_time, notebook_end_time, 5)\n",
    "print(json.dumps(embedding_tokens, indent=4))\n",
    "total_cost =embedding_tokens['total token costs'] + inference_tokens['total token costs']\n",
    "total_cost_per_million=embedding_tokens['token costs per MILLION such invocations'] + inference_tokens['token costs per MILLION such invocations']\n",
    "print(f\"Cost of running this notebook is approximately ${total_cost}\")\n",
    "print(f\"Cost of million such tokens approximately ${total_cost_per_million}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8faa6a0-9faa-49a4-af98-600ab013a271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
