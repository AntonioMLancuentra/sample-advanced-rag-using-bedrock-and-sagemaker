{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd35c145-e59c-4c6f-8ce2-3662b5d36151",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base with Custom chunking strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c7ebc-5152-4564-bac5-14cb7261aa44",
   "metadata": {},
   "source": [
    "#### Custom Chunking Logic with Lambda Functions in Amazon Bedrock\n",
    "\n",
    "When creating a Knowledge Base (KB) for Amazon Bedrock, you can connect a Lambda function to specify your custom chunking logic. During the ingestion process, if a Lambda function is provided, the Knowledge Base will execute the Lambda function and store the input and output values in the specified intermediate S3 bucket.\n",
    "\n",
    "#### Use Cases for Lambda Functions in KBs\n",
    "\n",
    "- **Custom Chunking Logic:** Lambda functions can be used to implement custom logic for chunking documents during ingestion, enabling more control over how documents are divided into meaningful chunks.\n",
    "- **Chunk-level Metadata Processing:** Lambda functions can also process chunked data, for example, by adding custom metadata at the chunk level, enriching the data for more advanced retrieval or analysis.\n",
    "\n",
    "This allows for more flexibility and tailored handling of document data within the Knowledge Base, making it possible to apply unique chunking strategies and augment the data with specific metadata for improved search and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0b6f2e-3e64-4bb0-8f70-d7be425a4a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accountNumber': '270597685972',\n",
       " 'regionName': 'us-west-2',\n",
       " 'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg',\n",
       " 'collectionId': '3ethft3xms9as2092ulg',\n",
       " 'vectorIndexName': 'ws-index-',\n",
       " 'bedrockExecutionRoleArn': 'arn:aws:iam::270597685972:role/advanced-rag-workshop-bedrock_execution_role-us-west-2',\n",
       " 's3Bucket': '270597685972-us-west-2-advanced-rag-workshop',\n",
       " 'kbFixedChunk': 'SN9KSOQPOV',\n",
       " 'kbSemanticChunk': 'KMZYCTNSWW',\n",
       " 'kbHierarchicalChunk': 'V8EJKFPYTK',\n",
       " 'kbCustomChunk': 'G8P2D7M28S',\n",
       " 'sagemakerLLMEndpoint': 'endpoint-llama-3-2-3b-instruct-2025-05-02-18-22-06'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the advanced_rag_utils module\n",
    "import advanced_rag_utils\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "# Reload module\n",
    "importlib.reload(advanced_rag_utils)\n",
    "\n",
    "# Re-import all functions\n",
    "from advanced_rag_utils import *\n",
    "\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "notebook_start_time = datetime.now(UTC)\n",
    "\n",
    "# Load the variables from the JSON file\n",
    "with open(\"../variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e319173-e2ae-4821-8a46-ba6781a71b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "kb_chunking_strategy = \"custom\" # [\"fixed\", \"hierarchical\", \"semantic\", \"custom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5319b75a-152d-4d8c-9816-417b7f318c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing file: /home/sagemaker-user/sample-advanced-rag-using-bedrock-and-sagemaker/embed_algo_costs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_algo</th>\n",
       "      <th>embedding_seconds</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>invocation_count</th>\n",
       "      <th>total_token_costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed</td>\n",
       "      <td>41.132119</td>\n",
       "      <td>243046</td>\n",
       "      <td>906</td>\n",
       "      <td>0.004861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hierarchical</td>\n",
       "      <td>56.287275</td>\n",
       "      <td>295358</td>\n",
       "      <td>1157</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semantic</td>\n",
       "      <td>131.845039</td>\n",
       "      <td>680599</td>\n",
       "      <td>4178</td>\n",
       "      <td>0.013612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunking_algo  embedding_seconds  input_tokens  invocation_count  \\\n",
       "0         fixed          41.132119        243046               906   \n",
       "1  hierarchical          56.287275        295358              1157   \n",
       "2      semantic         131.845039        680599              4178   \n",
       "\n",
       "   total_token_costs  \n",
       "0           0.004861  \n",
       "1           0.005907  \n",
       "2           0.013612  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_costs = load_df_from_csv()\n",
    "df_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b3661-448e-4717-90cd-e7b56ddf15da",
   "metadata": {},
   "source": [
    "### 0. Create a Lambda function with custom chunking logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da24d0d2-ec77-4ef5-b73f-a8877dc21d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM role 'advanced-rag-custom-chunk-us-west-2-role' already exists. Using the existing role.\n",
      "Lambda function 'advanced-rag-custom-chunk' already exists. Updating code...\n",
      "Lambda function code updated successfully\n"
     ]
    }
   ],
   "source": [
    "# Create or update the Lambda function with custom chunking logic\n",
    "role_arn, function_arn = create_or_update_custom_chunking_lambda(\n",
    "    region_name=variables[\"regionName\"],\n",
    "    account_number=variables[\"accountNumber\"],\n",
    "    role_name=f\"advanced-rag-custom-chunk-{variables['regionName']}-role\",\n",
    "    function_name=\"advanced-rag-custom-chunk\",\n",
    "    s3_bucket=variables['s3Bucket']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325eb5bd-f3a6-4144-835d-5b6db60fd516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket '270597685972-us-west-2-advanced-rag-workshop-custom-chunk' already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'270597685972-us-west-2-advanced-rag-workshop-custom-chunk'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an S3 bucket for custom chunking if it doesn't exist\n",
    "create_custom_chunk_s3_bucket(\n",
    "    s3_bucket=variables[\"s3Bucket\"],\n",
    "    region_name=variables[\"regionName\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446f270-acf7-4278-a664-643169ee2646",
   "metadata": {},
   "source": [
    "### 1. Create a Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd376c8-682e-4f0e-8184-6cb521ab435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "kb_chunking_strategy = \"custom\" # [\"fixed\", \"hierarchical\", \"semantic\", \"custom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe36ef26-2058-454e-b4ba-1804e086fcd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg', 'vectorIndexName': 'ws-index-custom', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "{'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg', 'vectorIndexName': 'ws-index-custom', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "{'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg', 'vectorIndexName': 'ws-index-custom', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "Knowledge Base already exists. Retrieving its ID...\n",
      "Found existing knowledge base with Name: advanced-rag-workshop-custom-chunking and ID: G8P2D7M28S\n",
      "OpenSearch Knowledge Response: {\n",
      "    \"createdAt\": \"2025-05-02 18:06:18.640912+00:00\",\n",
      "    \"description\": \"Knowledge base using Amazon OpenSearch Service as a vector store\",\n",
      "    \"knowledgeBaseArn\": \"arn:aws:bedrock:us-west-2:270597685972:knowledge-base/G8P2D7M28S\",\n",
      "    \"knowledgeBaseConfiguration\": {\n",
      "        \"type\": \"VECTOR\",\n",
      "        \"vectorKnowledgeBaseConfiguration\": {\n",
      "            \"embeddingModelArn\": \"arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0\"\n",
      "        }\n",
      "    },\n",
      "    \"knowledgeBaseId\": \"G8P2D7M28S\",\n",
      "    \"name\": \"advanced-rag-workshop-custom-chunking\",\n",
      "    \"roleArn\": \"arn:aws:iam::270597685972:role/advanced-rag-workshop-bedrock_execution_role-us-west-2\",\n",
      "    \"status\": \"ACTIVE\",\n",
      "    \"storageConfiguration\": {\n",
      "        \"opensearchServerlessConfiguration\": {\n",
      "            \"collectionArn\": \"arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg\",\n",
      "            \"fieldMapping\": {\n",
      "                \"metadataField\": \"text-metadata\",\n",
      "                \"textField\": \"text\",\n",
      "                \"vectorField\": \"vector\"\n",
      "            },\n",
      "            \"vectorIndexName\": \"ws-index-custom\"\n",
      "        },\n",
      "        \"type\": \"OPENSEARCH_SERVERLESS\"\n",
      "    },\n",
      "    \"updatedAt\": \"2025-05-02 18:06:18.640912+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "kb_name = f\"advanced-rag-workshop-{kb_chunking_strategy}-chunking\"\n",
    "\n",
    "kb_description = \"Knowledge base using Amazon OpenSearch Service as a vector store\"\n",
    "\n",
    "kb = create_kb(kb_name, kb_description, kb_chunking_strategy, variables, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684676c-0c32-47aa-9d48-d2c38b5a6206",
   "metadata": {},
   "source": [
    "### 2. Create Datasources for Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e081015d-a84e-4481-a6fd-381d86417450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for existing data sources in knowledge base G8P2D7M28S...\n",
      "Found existing data source 'advanced-rag-example'. Deleting it...\n",
      "Waiting for data source deletion to complete...\n",
      "Data source deleted.\n",
      "Creating new data source 'advanced-rag-example' with custom chunking...\n",
      "Custom chunking data source created successfully with ID: OHPOWTAXS5\n"
     ]
    }
   ],
   "source": [
    "# Create the data source with custom transformation configuration\n",
    "ds_object = create_custom_data_source_for_kb(\n",
    "    kb=kb,\n",
    "    variables=variables,\n",
    "    data_source_name=\"advanced-rag-example\",\n",
    "    function_arn=function_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee4ce6-10ee-4c4b-ae9a-8d16be4ed48b",
   "metadata": {},
   "source": [
    "### 3. Start Ingestion Job for Amazon Bedrock Knowledge base pointing to Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769885e3",
   "metadata": {},
   "source": [
    "> **Note**: The ingestion process will take approximately 2-3 minutes to complete. During this time, the system is processing your documents by:\n",
    "> 1. Extracting text from the source files\n",
    "> 2. Chunking the content according to the defined strategy (Fixed / Semantic / Hierachical / Custom)\n",
    "> 3. Generating embeddings for each chunk\n",
    "> 4. Storing the embeddings and associated metadata in the OpenSearch vector database\n",
    ">\n",
    "> You'll see status updates as the process progresses. Please wait for the \"Ingestion job completed successfully\" message before proceeding to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d003980-60ba-4b7e-94c2-1bc99c0b63ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion job started successfully for kb_name = advanced-rag-workshop-custom-chunking and kb_id = G8P2D7M28S\n",
      "\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "Job completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "ingestion_start_time = datetime.now(UTC)\n",
    "sleep(3)\n",
    "create_ingestion_job(kb, ds_object, variables)\n",
    "sleep(3)\n",
    "ingestion_end_time = datetime.now(UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75bf04f0-5ca5-411f-97c7-f7abc6819079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to ingest into KB = 77.42 seconds\n"
     ]
    }
   ],
   "source": [
    "time_taken = (ingestion_end_time-ingestion_start_time).total_seconds()\n",
    "print(f\"time taken to ingest into KB = {fmt_n(time_taken)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4aa90b2-1fa3-4517-b9a6-651352800cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"WARNING\": \"These costs are approximate and directional as of April 2025. They will vary as per region and may change in future. The costs are for Bedrock On-Demand model. If you see zero costs, chances are high that the LLM was not considered in cost calculations when the notebook was prepared. Please use AWS calculator for more accurate cost calculations.\",\n",
      "    \"model_id\": \"amazon.titan-embed-text-v2:0\",\n",
      "    \"start_time\": \"2025-05-02T23:40:22.212813+00:00\",\n",
      "    \"end_time\": \"2025-05-02T23:41:39.629905+00:00\",\n",
      "    \"duration in minutes\": 1.2902848666666666,\n",
      "    \"input_tokens\": 99307,\n",
      "    \"output_tokens\": 0,\n",
      "    \"invocation_count\": 638,\n",
      "    \"per million input token costs\": 0.02,\n",
      "    \"per million output token costs\": 0.0,\n",
      "    \"input token costs\": 0.00198614,\n",
      "    \"output token costs\": 0.0,\n",
      "    \"total token costs\": 0.00198614,\n",
      "    \"average token costs per invocation\": 3.1130721003134796e-06,\n",
      "    \"token costs per MILLION such invocations\": 3.1130721003134796\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "vector_store_embedding_cost = get_bedrock_token_based_cost(model_id, ingestion_start_time, ingestion_end_time)\n",
    "print(json.dumps(vector_store_embedding_cost, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debd6e05-f821-4d61-91ae-4c2f3a38f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added new row for: custom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_algo</th>\n",
       "      <th>embedding_seconds</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>invocation_count</th>\n",
       "      <th>total_token_costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed</td>\n",
       "      <td>41.132119</td>\n",
       "      <td>243046</td>\n",
       "      <td>906</td>\n",
       "      <td>0.004861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hierarchical</td>\n",
       "      <td>56.287275</td>\n",
       "      <td>295358</td>\n",
       "      <td>1157</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semantic</td>\n",
       "      <td>131.845039</td>\n",
       "      <td>680599</td>\n",
       "      <td>4178</td>\n",
       "      <td>0.013612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>custom</td>\n",
       "      <td>77.417092</td>\n",
       "      <td>99307</td>\n",
       "      <td>638</td>\n",
       "      <td>0.001986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunking_algo  embedding_seconds  input_tokens  invocation_count  \\\n",
       "0         fixed          41.132119        243046               906   \n",
       "1  hierarchical          56.287275        295358              1157   \n",
       "2      semantic         131.845039        680599              4178   \n",
       "3        custom          77.417092         99307               638   \n",
       "\n",
       "   total_token_costs  \n",
       "0           0.004861  \n",
       "1           0.005907  \n",
       "2           0.013612  \n",
       "3           0.001986  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add or update the cost binfo to dataframe. \n",
    "# This will help us compare the costs from various chunking strategies visually.\n",
    "new_row = {\n",
    "    'chunking_algo': kb_chunking_strategy,\n",
    "    'embedding_seconds': vector_store_embedding_cost['duration in minutes']*60,\n",
    "    'input_tokens': vector_store_embedding_cost['input_tokens'],\n",
    "    'invocation_count': vector_store_embedding_cost['invocation_count'],\n",
    "    'total_token_costs': vector_store_embedding_cost['total token costs']\n",
    "}\n",
    "df_costs = update_or_add_row(df_costs, new_row)\n",
    "df_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1edb27-a7f5-4ab4-8770-2de83134b430",
   "metadata": {},
   "source": [
    "### 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f7fad3-3114-4010-9870-5f52e5fb5e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Define the query for retrieving relevant documents\n",
    "query = \"What were net incomes of Amazon in 2022, 2023 and 2024?\"\n",
    "\n",
    "# Get the knowledge base ID from the variables\n",
    "kb_id = variables.get(\"kbCustomChunk\")\n",
    "\n",
    "# Retrieve results from the knowledge base\n",
    "chunks_from_kb = retrieve_from_kb(\n",
    "    query=query,\n",
    "    kb={\"knowledgeBaseId\": kb_id},\n",
    "    n_chunks=3,\n",
    "    variables=variables\n",
    ")\n",
    "\n",
    "\n",
    "#Let's specify a minimum similarity score. We should see less chunks retrieved as compared to the previous invocation.\n",
    "min_score = 0.50\n",
    "\n",
    "# # get chunks from KB\n",
    "# chunks_from_kb = retrieve_from_kb(query, kb, n_chunks, variables, min_score)\n",
    "\n",
    "print(json.dumps(chunks_from_kb, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e804b",
   "metadata": {},
   "source": [
    "> **Note**: After creating the knowledge base, you can explore its details and settings in the Amazon Bedrock console. This gives you a more visual interface to understand how the knowledge base is structured.\n",
    "> \n",
    "> **[➡️ View your Knowledge Bases in the AWS Console](https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/knowledge-bases)**\n",
    ">\n",
    "> In the console, you can:\n",
    "> - See all your knowledge bases in one place\n",
    "> - View ingestion status and statistics\n",
    "> - Test queries through the built-in chat interface\n",
    "> - Modify settings and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "186f619b-d141-40bd-8670-68103006a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"total_chunks\": 0,\n",
      "    \"min_score\": 0,\n",
      "    \"max_score\": 0,\n",
      "    \"avg_score\": 0,\n",
      "    \"count_above_threshold\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's summarize with total chunks, minimum score, maximum score, average score, \n",
    "# and lastly the number of chunks with a score more than a specified threshold.\n",
    "score_threshold = 0.40\n",
    "score_structure = analyze_chunk_scores_above_threshold(chunks_from_kb, score_threshold)\n",
    "print(json.dumps(score_structure, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fd0ae-5c67-4e31-b377-259631aef1fa",
   "metadata": {},
   "source": [
    "### Cost Summary for Running This Notebook\n",
    "In this notebook, we have used an embedding LLM for two purposes. \n",
    "1. Populate a vector store for six PDF files and one CSV file. (7 documents in total)\n",
    "2. Generate a query embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52490791-74e7-4293-9d29-05166265517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### Scenario\n",
       "* Number of documents to ingest: 100000\n",
       "* Number of queries: 5000000\n",
       "\n",
       "#### Cost Estimation based on the Scenario (USD)\n",
       "|-| Notebook Cost | Scenario Cost |\n",
       "|-|-|-|\n",
       "|VectorStore|0.001986|28.373429|\n",
       "|Queries|0.006605460000000001|19.37085|\n",
       "|**TOTAL**|0.008592|47.744279000000006|\n",
       "\n",
       "#### The cost estimation is based on a scenario that the similar documents and queries are multiplied.\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from advanced_rag_utils import embedding_cost_report\n",
    "# Marking notebook endtime\n",
    "notebook_end_time = datetime.now(UTC)\n",
    "\n",
    "cost_for_notebook = get_bedrock_token_based_cost(model_id, notebook_start_time, notebook_end_time)\n",
    "\n",
    "# Your assumptions for your use case:\n",
    "scenario_number_of_documents = 100000\n",
    "scenario_number_of_queries =   5000000 \n",
    "display(Markdown(embedding_cost_report(vector_store_embedding_cost, cost_for_notebook, scenario_number_of_documents, scenario_number_of_queries)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
