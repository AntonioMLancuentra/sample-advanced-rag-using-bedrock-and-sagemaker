{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c01279f-f6b3-46a2-9c76-ecf34f9dc275",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base with Semantic Chunking Strategy\n",
    "#### What will we do in this workshop?\n",
    "1. Create a Knowledgebase (KB) in the vector database.\n",
    "2. We will create a data source for the KB. The data source will be the Amazon Science and 10K documents stored in S3.\n",
    "3. We will ingest the data from S3, use Semantic Chunking to chunk the data, generate vector embeddings, and store the chunks and their corresponding vector embeddings in the KB.\n",
    "4. We will then ask some questions and query the KB to return some chunks and inspect relevancy score.\n",
    "<br>Note: We are not sending the query and its chunks to a LLM in this notebook. We will do that in other notebooks.\n",
    "![We are generating vector embeddings and storing them in a KB in Vector Database](./Semantic_Chunking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0a202-87f1-4a0f-9d2f-e697e6b98bee",
   "metadata": {},
   "source": [
    "## Concept\n",
    "\n",
    "Semantic chunking analyzes the relationships within a text (using vector embeddings) and creates chunks based on the semantic similarity calculated by the embedding model. Please note that this will result in chunks with varying sizes. This approach preserves the information’s integrity during retrieval, helping to ensure accurate and contextually appropriate results. <br>\n",
    "<br>![How Semantic Chunking Works](./Semantic_how_it_works.png)\n",
    "\n",
    "## Benefits\n",
    "\n",
    "* By focusing on the text’s meaning and context, semantic chunking significantly improves the quality of retrieval. It should be used in scenarios where maintaining the semantic integrity of the text is crucial.\n",
    "\n",
    "* Although this method is more computationally intensive than fixed-size chunking, it can be beneficial for chunking documents where contextual boundaries aren’t clear—for example, legal documents, technical manuals, documents with too many tables.\n",
    "\n",
    "## Cost Considerations\n",
    "\n",
    "* Since Semantic chunking process generates vector embeddings to find chunk boundaries, this will result in increase API calls to an embedding LLM. Thus, expect relatively higher costs than fixed size chunking.\n",
    "* However, the bulk of these operations happen the first time the documents are processed. In a steady state situation these costs will be incurred only for new documents or changes documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c67e01c-6f6a-4b11-bb8f-256fb15ef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a module with few helper functions. \n",
    "# These functions will help us create knowledge base (KB), create data source for KB, and ingest data using semantic chunking to KB.\n",
    "\n",
    "import importlib\n",
    "import advanced_rag_utils\n",
    "\n",
    "# Reload module\n",
    "importlib.reload(advanced_rag_utils)\n",
    "\n",
    "# Re-import all functions\n",
    "from advanced_rag_utils import *\n",
    "\n",
    "from datetime import datetime, timedelta, UTC\n",
    "\n",
    "notebook_start_time = datetime.now(UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b874664-bd21-4929-8fe0-165da697e11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accountNumber': '270597685972',\n",
       " 'regionName': 'us-west-2',\n",
       " 'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg',\n",
       " 'collectionId': '3ethft3xms9as2092ulg',\n",
       " 'vectorIndexName': 'ws-index-',\n",
       " 'bedrockExecutionRoleArn': 'arn:aws:iam::270597685972:role/advanced-rag-workshop-bedrock_execution_role-us-west-2',\n",
       " 's3Bucket': '270597685972-us-west-2-advanced-rag-workshop',\n",
       " 'kbFixedChunk': 'SN9KSOQPOV',\n",
       " 'kbSemanticChunk': 'KMZYCTNSWW',\n",
       " 'kbHierarchicalChunk': 'V8EJKFPYTK',\n",
       " 'kbCustomChunk': 'G8P2D7M28S',\n",
       " 'sagemakerLLMEndpoint': 'endpoint-llama-3-2-3b-instruct-2025-05-02-18-22-06'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the variables we saved in the first notebook. We will use these variables\n",
    "import json\n",
    "with open(\"../variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfc4268-af67-46e1-8237-f818583a868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing file: /home/sagemaker-user/sample-advanced-rag-using-bedrock-and-sagemaker/embed_algo_costs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_algo</th>\n",
       "      <th>embedding_seconds</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>invocation_count</th>\n",
       "      <th>total_token_costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed</td>\n",
       "      <td>41.168348</td>\n",
       "      <td>88179</td>\n",
       "      <td>329</td>\n",
       "      <td>0.001764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hierarchical</td>\n",
       "      <td>56.287275</td>\n",
       "      <td>295358</td>\n",
       "      <td>1157</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semantic</td>\n",
       "      <td>137.789455</td>\n",
       "      <td>994947</td>\n",
       "      <td>6676</td>\n",
       "      <td>0.019899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunking_algo  embedding_seconds  input_tokens  invocation_count  \\\n",
       "0         fixed          41.168348         88179               329   \n",
       "1  hierarchical          56.287275        295358              1157   \n",
       "2      semantic         137.789455        994947              6676   \n",
       "\n",
       "   total_token_costs  \n",
       "0           0.001764  \n",
       "1           0.005907  \n",
       "2           0.019899  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataframe related to costs from a csv file (if it already exists)\n",
    "df_costs = load_df_from_csv()\n",
    "df_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805c37f-2e62-4945-b0e3-05af7db0e60d",
   "metadata": {},
   "source": [
    "### 1. Create a Knowledge Base\n",
    "Let's specify  chunking strategy, name and descripotion for Knowledge Base (KB) and create a KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1ac212-083b-4bd0-abf1-e73919a054f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "kb_chunking_strategy = \"semantic\" # [\"fixed\", \"hierarchical\", \"semantic\", \"custom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415c4796-f812-49c1-8188-962cadd6eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg', 'vectorIndexName': 'ws-index-semantic', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "{'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg', 'vectorIndexName': 'ws-index-semantic', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "{'collectionArn': 'arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg', 'vectorIndexName': 'ws-index-semantic', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "Knowledge Base already exists. Retrieving its ID...\n",
      "Found existing knowledge base with Name: advanced-rag-workshop-semantic-chunking and ID: KMZYCTNSWW\n",
      "OpenSearch Knowledge Response: {\n",
      "    \"createdAt\": \"2025-05-02 17:54:28.070008+00:00\",\n",
      "    \"description\": \"Knowledge base using Amazon OpenSearch Service as a vector store\",\n",
      "    \"knowledgeBaseArn\": \"arn:aws:bedrock:us-west-2:270597685972:knowledge-base/KMZYCTNSWW\",\n",
      "    \"knowledgeBaseConfiguration\": {\n",
      "        \"type\": \"VECTOR\",\n",
      "        \"vectorKnowledgeBaseConfiguration\": {\n",
      "            \"embeddingModelArn\": \"arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0\"\n",
      "        }\n",
      "    },\n",
      "    \"knowledgeBaseId\": \"KMZYCTNSWW\",\n",
      "    \"name\": \"advanced-rag-workshop-semantic-chunking\",\n",
      "    \"roleArn\": \"arn:aws:iam::270597685972:role/advanced-rag-workshop-bedrock_execution_role-us-west-2\",\n",
      "    \"status\": \"ACTIVE\",\n",
      "    \"storageConfiguration\": {\n",
      "        \"opensearchServerlessConfiguration\": {\n",
      "            \"collectionArn\": \"arn:aws:aoss:us-west-2:270597685972:collection/3ethft3xms9as2092ulg\",\n",
      "            \"fieldMapping\": {\n",
      "                \"metadataField\": \"text-metadata\",\n",
      "                \"textField\": \"text\",\n",
      "                \"vectorField\": \"vector\"\n",
      "            },\n",
      "            \"vectorIndexName\": \"ws-index-semantic\"\n",
      "        },\n",
      "        \"type\": \"OPENSEARCH_SERVERLESS\"\n",
      "    },\n",
      "    \"updatedAt\": \"2025-05-02 17:54:28.070008+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "kb_name = f\"advanced-rag-workshop-{kb_chunking_strategy}-chunking\"\n",
    "\n",
    "kb_description = \"Knowledge base using Amazon OpenSearch Service as a vector store\"\n",
    "\n",
    "kb = create_kb(kb_name, kb_description, kb_chunking_strategy, variables, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfebc0-bdeb-4f43-a0a0-921d34be6aba",
   "metadata": {},
   "source": [
    "### 2. Create Datasource for Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cc990e-b0da-4853-a48a-071219d1461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data source 'advanced-rag-example-semantic'. Deleting it...\n",
      "Waiting for data source deletion to complete...\n",
      "Data source deleted successfully.\n",
      "Creating new data source 'advanced-rag-example-semantic' with {'chunkingStrategy': 'SEMANTIC', 'semanticChunkingConfiguration': {'maxTokens': 300, 'bufferSize': 1, 'breakpointPercentileThreshold': 95}} chunking...\n",
      "semantic chunking data source created successfully.\n"
     ]
    }
   ],
   "source": [
    "data_source_name = f\"advanced-rag-example-{kb_chunking_strategy}\"\n",
    "\n",
    "ds_object = create_data_source_for_kb(kb_chunking_strategy, data_source_name, kb, variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d415f-d61f-49ae-9d9a-1ea3063a1452",
   "metadata": {},
   "source": [
    "### 3. Start Ingestion Job for Amazon Bedrock Knowledge base pointing to Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cc69d",
   "metadata": {},
   "source": [
    "> **Note**: The ingestion process will take approximately 2-3 minutes to complete. During this time, the system is processing your documents by:\n",
    "> 1. Extracting text from the source files\n",
    "> 2. Chunking the content according to the defined strategy (Fixed / Semantic / Hierachical / Custom)\n",
    "> 3. Generating embeddings for each chunk\n",
    "> 4. Storing the embeddings and associated metadata in a Knowledge Base (KB) in OpenSearch vector database\n",
    ">\n",
    "> You'll see status updates as the process progresses. Please wait for the \"Ingestion job completed successfully\" message before proceeding to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e084b1-9c83-45b2-a08f-36b8d2bf0bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion job started successfully for kb_name = advanced-rag-workshop-semantic-chunking and kb_id = KMZYCTNSWW\n",
      "\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "Job completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "ingestion_start_time = datetime.now(UTC)\n",
    "create_ingestion_job(kb, ds_object, variables)\n",
    "ingestion_end_time = datetime.now(UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014a5d31-22fa-4a23-be51-b479d02da181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to ingest into KB = 131.79 seconds\n"
     ]
    }
   ],
   "source": [
    "time_taken = (ingestion_end_time-ingestion_start_time).total_seconds()\n",
    "print(f\"time taken to ingest into KB = {fmt_n(time_taken)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db1388-55e0-4db9-a05d-b7c2f2cf5379",
   "metadata": {},
   "source": [
    "## Embedding LLM Costs\n",
    "1. Specify model id\n",
    "2. Specify start and end time\n",
    "3. Invoke a helper function to query cloud watch\n",
    "5. Calculate costs (please note that pricing is subject to change per region and over time)\n",
    "\n",
    "<br>![Embedding LLM Input Token Costs](./Input_token_embedding_llm_costs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbc155e-d7c2-4979-a09d-997af630e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"WARNING\": \"These costs are approximate and directional as of April 2025. They will vary as per region and may change in future. The costs are for Bedrock On-Demand model. If you see zero costs, chances are high that the LLM was not considered in cost calculations when the notebook was prepared. Please use AWS calculator for more accurate cost calculations.\",\n",
      "    \"model_id\": \"amazon.titan-embed-text-v2:0\",\n",
      "    \"start_time\": \"2025-05-03T01:32:28.534299+00:00\",\n",
      "    \"end_time\": \"2025-05-03T01:34:40.321784+00:00\",\n",
      "    \"duration in minutes\": 2.1964580833333334,\n",
      "    \"input_tokens\": 743617,\n",
      "    \"output_tokens\": 0,\n",
      "    \"invocation_count\": 4827,\n",
      "    \"per million input token costs\": 0.02,\n",
      "    \"per million output token costs\": 0.0,\n",
      "    \"input token costs\": 0.01487234,\n",
      "    \"output token costs\": 0.0,\n",
      "    \"total token costs\": 0.01487234,\n",
      "    \"average token costs per invocation\": 3.08107313030868e-06,\n",
      "    \"token costs per MILLION such invocations\": 3.0810731303086802\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "vector_store_embedding_cost = get_bedrock_token_based_cost(model_id, ingestion_start_time, ingestion_end_time)\n",
    "print(json.dumps(vector_store_embedding_cost, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1865a0-f52e-4348-8119-61676c18ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated existing row for: semantic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_algo</th>\n",
       "      <th>embedding_seconds</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>invocation_count</th>\n",
       "      <th>total_token_costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed</td>\n",
       "      <td>41.168348</td>\n",
       "      <td>88179</td>\n",
       "      <td>329</td>\n",
       "      <td>0.001764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hierarchical</td>\n",
       "      <td>56.287275</td>\n",
       "      <td>295358</td>\n",
       "      <td>1157</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semantic</td>\n",
       "      <td>131.787485</td>\n",
       "      <td>743617</td>\n",
       "      <td>4827</td>\n",
       "      <td>0.014872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunking_algo  embedding_seconds  input_tokens  invocation_count  \\\n",
       "0         fixed          41.168348         88179               329   \n",
       "1  hierarchical          56.287275        295358              1157   \n",
       "2      semantic         131.787485        743617              4827   \n",
       "\n",
       "   total_token_costs  \n",
       "0           0.001764  \n",
       "1           0.005907  \n",
       "2           0.014872  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add or update the cost binfo to dataframe. \n",
    "# This will help us compare the costs from various chunking strategies visually.\n",
    "new_row = {\n",
    "    'chunking_algo': kb_chunking_strategy,\n",
    "    'embedding_seconds': vector_store_embedding_cost['duration in minutes']*60,\n",
    "    'input_tokens': vector_store_embedding_cost['input_tokens'],\n",
    "    'invocation_count': vector_store_embedding_cost['invocation_count'],\n",
    "    'total_token_costs': vector_store_embedding_cost['total token costs']\n",
    "}\n",
    "df_costs = update_or_add_row(df_costs, new_row)\n",
    "df_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b1d336-ff62-4844-991c-46cde76a00f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved DataFrame to: /home/sagemaker-user/sample-advanced-rag-using-bedrock-and-sagemaker/embed_algo_costs.csv\n"
     ]
    }
   ],
   "source": [
    "# Let's save the df\n",
    "save_df_to_csv(df_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988051f4-2741-4180-af71-d445f2eaf37d",
   "metadata": {},
   "source": [
    "### 4. Retrieve: Use input query to RETRIEVE chunks from Vector Database\n",
    "We will use a helper function where you can specify the number of chunks to extract.<br>\n",
    "The helper function will 1/ generate a vector embedding for the query, 2/ search the vector embedding in the Knowledge Base (KB) vector database, 3/ get the number of chunks specified, 4/ Optionally, you can also specify minimum score for similarity in which case the helper function will get chunks with at least the minimum relevancy.\n",
    "\n",
    "<b>Warning: After data is ingested into a KB, when you query immediately, the results might be empty because of eventual consistency. If that happens, please wait for a few seconds and then retry.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f992ba-d37d-4c3f-89d3-128f3a8920ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"content\": \"We promptly make available on this website, free of charge, the reports that we file or furnish with the Securities and Exchange Commission (\\u201cSEC\\u201d), corporate governance information (including our Code of Business Conduct and Ethics), and select press releases. \\n \\n Executive Officers and Directors The following tables set forth certain information regarding our Executive Officers and Directors as of January 24, 2024: \\n \\n Information About Our Executive Officers Name Age Position \\n \\n Jeffrey P. Bezos 60 Executive Chair Andrew R. Jassy 56 President and Chief Executive Officer Douglas J. Herrington 57 CEO Worldwide Amazon Stores Brian T. Olsavsky 60 Senior Vice President and Chief Financial Officer Shelley L. Reynolds 59 Vice President, Worldwide Controller, and Principal Accounting Officer Adam N. Selipsky 57 CEO Amazon Web Services David A. Zapolsky 60 Senior Vice President, Global Public Policy and General Counsel \\n \\n Jeffrey P. Bezos.\",\n",
      "    \"metadata\": {\n",
      "      \"x-amz-bedrock-kb-source-uri\": \"s3://270597685972-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2024.pdf\",\n",
      "      \"x-amz-bedrock-kb-document-page-number\": 5.0,\n",
      "      \"year\": 2024.0,\n",
      "      \"docType\": \"10K Report\",\n",
      "      \"x-amz-bedrock-kb-data-source-id\": \"ADMUSQWSD1\",\n",
      "      \"company\": \"Amazon\",\n",
      "      \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AO07Hk5YBxqKOsYV71bUV\",\n",
      "      \"authors\": [\n",
      "        \"Amazon\"\n",
      "      ]\n",
      "    },\n",
      "    \"score\": 0.6486264\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"We promptly make available on this website, free of charge, the reports that we file or furnish with the Securities and Exchange Commission (\\u201cSEC\\u201d), corporate governance information (including our Code of Business Conduct and Ethics), and select press releases. \\n \\n Executive Officers and Directors \\n \\n The following tables set forth certain information regarding our Executive Officers and Directors as of January 25, 2023: \\n \\n Information About Our Executive Officers Name Age Position \\n \\n Jeffrey P. Bezos 59 Executive Chair Andrew R. Jassy 55 President and Chief Executive Officer Douglas J. Herrington 56 CEO Worldwide Amazon Stores Brian T. Olsavsky 59 Senior Vice President and Chief Financial Officer Shelley L. Reynolds 58 Vice President, Worldwide Controller, and Principal Accounting Officer Adam N. Selipsky 56 CEO Amazon Web Services David A. Zapolsky 59 Senior Vice President, General Counsel, and Secretary \\n \\n Jeffrey P. Bezos. Mr. Bezos founded Amazon.com in 1994 and has served as Executive Chair since July 2021. He has served as Chair of the Board since 1994 and served as Chief Executive Officer from May 1996 until July 2021, and as President from 1994 until June 1999 and again from October 2000 to July 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"x-amz-bedrock-kb-source-uri\": \"s3://270597685972-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "      \"x-amz-bedrock-kb-document-page-number\": 5.0,\n",
      "      \"year\": 2023.0,\n",
      "      \"docType\": \"10K Report\",\n",
      "      \"x-amz-bedrock-kb-data-source-id\": \"ADMUSQWSD1\",\n",
      "      \"company\": \"Amazon\",\n",
      "      \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AvPvHk5YBIk6Sd2CHu8_n\",\n",
      "      \"authors\": [\n",
      "        \"Amazon\"\n",
      "      ]\n",
      "    },\n",
      "    \"score\": 0.6485769\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"Reynolds 60 Vice President, Worldwide Controller, and Principal Accounting Officer David A. Zapolsky 61 Senior Vice President, Global Public Policy and General Counsel \\n \\n Jeffrey P. Bezos. Mr. Bezos founded Amazon.com in 1994 and has served as Executive Chair since July 2021. He has served as Chair of the Board since 1994 and served as Chief Executive Officer from May 1996 until July 2021, and as President from 1994 until June 1999 and again from October 2000 to July 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"x-amz-bedrock-kb-source-uri\": \"s3://270597685972-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2025.pdf\",\n",
      "      \"x-amz-bedrock-kb-document-page-number\": 5.0,\n",
      "      \"year\": 2025.0,\n",
      "      \"docType\": \"10K Report\",\n",
      "      \"x-amz-bedrock-kb-data-source-id\": \"ADMUSQWSD1\",\n",
      "      \"company\": \"Amazon\",\n",
      "      \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AkfvHk5YBIk6Sd2CHxtBo\",\n",
      "      \"authors\": [\n",
      "        \"Amazon\"\n",
      "      ]\n",
      "    },\n",
      "    \"score\": 0.63588125\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"Olsavsky, Senior Vice President and Chief Financial Officer of Amazon.com, Inc., pursuant to Rule 13a-14(a) under the Securities Exchange Act of 1934. \\n \\n 73\\n \\n \\n \\n \\n  https://content.edgar-online.com/ExternalLink/EDGAR/0001193125-20-159531.html?hash=16ec42e2def9d676c243dade97430c0b550cbfa2eb40b5ecf51e8fa227b36a1a&dest=d933420dex41_htm\\n \\n \\n \\n  https://content.edgar-online.com/ExternalLink/EDGAR/0001193125-20-159531.html?\",\n",
      "    \"metadata\": {\n",
      "      \"x-amz-bedrock-kb-source-uri\": \"s3://270597685972-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "      \"x-amz-bedrock-kb-document-page-number\": 73.0,\n",
      "      \"year\": 2023.0,\n",
      "      \"docType\": \"10K Report\",\n",
      "      \"x-amz-bedrock-kb-data-source-id\": \"ADMUSQWSD1\",\n",
      "      \"company\": \"Amazon\",\n",
      "      \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3ARvvHk5YBIk6Sd2CHv9Dh\",\n",
      "      \"authors\": [\n",
      "        \"Amazon\"\n",
      "      ]\n",
      "    },\n",
      "    \"score\": 0.5968849\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"hash=2b307f494bc4d9e11a79af2491599072f05b1f7a27e926f9f48242ab784bee46&dest=d429499dex101_htm\\n \\n \\n \\n  https://content.edgar-online.com/ExternalLink/EDGAR/0001193125-23-000849.html?hash=2b307f494bc4d9e11a79af2491599072f05b1f7a27e926f9f48242ab784bee46&dest=d429499dex101_htmTable of Contents \\n \\n 32.1 Certification of Andrew R. Jassy, President and Chief Executive Officer of Amazon.com, Inc., pursuant to 18 U.S.C. Section 1350. \\n \\n 32.2 Certification of Brian T. Olsavsky, Senior Vice President and Chief Financial Officer of Amazon.com, Inc., pursuant to 18 U.S.C.\",\n",
      "    \"metadata\": {\n",
      "      \"x-amz-bedrock-kb-source-uri\": \"s3://270597685972-us-west-2-advanced-rag-workshop/data/pdf_documents/Amazon-10k-2023.pdf\",\n",
      "      \"x-amz-bedrock-kb-document-page-number\": 73.0,\n",
      "      \"year\": 2023.0,\n",
      "      \"docType\": \"10K Report\",\n",
      "      \"x-amz-bedrock-kb-data-source-id\": \"ADMUSQWSD1\",\n",
      "      \"company\": \"Amazon\",\n",
      "      \"x-amz-bedrock-kb-chunk-id\": \"1%3A0%3AUPvHk5YBIk6Sd2CHv9Dh\",\n",
      "      \"authors\": [\n",
      "        \"Amazon\"\n",
      "      ]\n",
      "    },\n",
      "    \"score\": 0.5839397\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Now let's pick the chunks with some minimum relevance score for the same question.\n",
    "query = \"Who is the CEO, CFO, and CTO of Amazon?\"\n",
    "\n",
    "#specify the number of chunks\n",
    "n_chunks = 5\n",
    "\n",
    "#Let's specify a minimum similarity score. We should see less chunks retrieved as compared to the previous invocation.\n",
    "min_score = 0.30\n",
    "\n",
    "# get chunks from KB\n",
    "chunks_from_kb = retrieve_from_kb(query, kb, n_chunks, variables, min_score)\n",
    "\n",
    "print(json.dumps(chunks_from_kb, indent=2))\n",
    "\n",
    "# You should see less number of chunks retrieved as compared to the previous cell \n",
    "# because of the minimum relevance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b48b2372-8932-4df2-8c73-b5960655752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"total_chunks\": 5,\n",
      "    \"min_score\": 0.5839397,\n",
      "    \"max_score\": 0.6486264,\n",
      "    \"avg_score\": 0.62278183,\n",
      "    \"count_above_threshold\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's summarize with total chunks, minimum score, maximum score, average score, \n",
    "# and lastly the number of chunks with a score more than a specified threshold.\n",
    "score_threshold = 0.30\n",
    "score_structure = analyze_chunk_scores_above_threshold(chunks_from_kb, score_threshold)\n",
    "print(json.dumps(score_structure, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6c818-e550-4c65-bbca-278c58fab5f4",
   "metadata": {},
   "source": [
    "### Cost Summary for Running This Notebook\n",
    "In this notebook, we have used an embedding LLM for two purposes. \n",
    "1. Populate a vector store for six PDF files and one CSV file. (7 documents in total)\n",
    "2. Generate a query embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca84a126-5ee7-42b7-b891-100010e2d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# Marking notebook endtime\n",
    "notebook_end_time = datetime.now(UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c434aba2-ccef-4531-a50d-9734777d1280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### Scenario\n",
       "* Number of documents to ingest: 100000\n",
       "* Number of queries: 5000000\n",
       "\n",
       "#### Cost Estimation based on the Scenario (USD)\n",
       "|-| Notebook Cost | Scenario Cost |\n",
       "|-|-|-|\n",
       "|VectorStore|0.014872|212.462|\n",
       "|Queries|0.005026879999999999|13.586162|\n",
       "|**TOTAL**|0.019899|226.048162|\n",
       "\n",
       "#### The cost estimation is based on a scenario that the similar documents and queries are multiplied.\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from advanced_rag_utils import embedding_cost_report\n",
    "\n",
    "cost_for_notebook = get_bedrock_token_based_cost(model_id, notebook_start_time, notebook_end_time)\n",
    "\n",
    "# Your assumptions for your use case:\n",
    "scenario_number_of_documents = 100000\n",
    "scenario_number_of_queries =   5000000\n",
    " \n",
    "display(Markdown(embedding_cost_report(vector_store_embedding_cost, cost_for_notebook, scenario_number_of_documents, scenario_number_of_queries)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
