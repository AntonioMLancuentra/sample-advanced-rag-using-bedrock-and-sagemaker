{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c01279f-f6b3-46a2-9c76-ecf34f9dc275",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base with Semantic chunking strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0a202-87f1-4a0f-9d2f-e697e6b98bee",
   "metadata": {},
   "source": [
    "#### Concept\n",
    "\n",
    "Semantic chunking analyzes the relationships within a text and divides it into meaningful and complete chunks, which are derived based on the semantic similarity calculated by the embedding model. This approach preserves the information’s integrity during retrieval, helping to ensure accurate and contextually appropriate results. Knowledge Bases for Amazon Bedrock first divides documents into chunks based on the specified token size. Embeddings are created for each chunk, and similar chunks in the embedding space are combined based on the similarity threshold and buffer size, forming new chunks. Consequently, the chunk size can vary across chunks.\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "* By focusing on the text’s meaning and context, semantic chunking significantly improves the quality of retrieval. It should be used in scenarios where maintaining the semantic integrity of the text is crucial.\n",
    "\n",
    "* Although this method is more computationally intensive than fixed-size chunking, it can be beneficial for chunking documents where contextual boundaries aren’t clear—for example, legal documents or technical manuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e7a2e-6062-4171-85ae-e78c06f2c50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805c37f-2e62-4945-b0e3-05af7db0e60d",
   "metadata": {},
   "source": [
    "### 1. Create a Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e876a-6043-40f6-8ba1-31f39b474409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function definition\n",
    "from retrying import retry\n",
    "import boto3\n",
    "\n",
    "# Initialize the Bedrock agent client with the specified region\n",
    "bedrock_agent = boto3.client(\"bedrock-agent\", region_name=variables[\"regionName\"])\n",
    "\n",
    "@retry(wait_random_min=1000, wait_random_max=2000, stop_max_attempt_number=3)\n",
    "def create_knowledge_base_func(name, description, chunking_type):\n",
    "    # The embedding model used by Bedrock to embed ingested documents and real-time prompts\n",
    "    embedding_model_arn = f\"arn:aws:bedrock:{variables['regionName']}::foundation-model/amazon.titan-embed-text-v2:0\"\n",
    "    \n",
    "    # Configuration for OpenSearch Serverless to store vectors and associated metadata\n",
    "    opensearch_serverless_configuration = {\n",
    "            \"collectionArn\": variables[\"collectionArn\"],  # ARN for the OpenSearch collection\n",
    "            \"vectorIndexName\": variables[\"vectorIndexName\"] + chunking_type,  # Vector index name appended with chunking type\n",
    "            \"fieldMapping\": {  # Mapping the fields for vector, text, and metadata\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Printing the configuration to verify before creating the Knowledge Base\n",
    "    print(opensearch_serverless_configuration)\n",
    "    \n",
    "    # Create the Knowledge Base using Bedrock Agent's API\n",
    "    create_kb_response = bedrock_agent.create_knowledge_base(\n",
    "        name=name,  # Knowledge base name\n",
    "        description=description,  # Knowledge base description\n",
    "        roleArn=variables[\"bedrockExecutionRoleArn\"],  # IAM role ARN for Bedrock to assume\n",
    "        knowledgeBaseConfiguration={  # Configuration for the knowledge base\n",
    "            \"type\": \"VECTOR\",  # Type of Knowledge Base: VECTOR for vectorized data\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embedding_model_arn  # ARN for the embedding model\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration={  # Storage configuration for the knowledge base\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",  # Using OpenSearch Serverless as the storage option\n",
    "            \"opensearchServerlessConfiguration\": opensearch_serverless_configuration  # OpenSearch configuration details\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Return the created knowledge base details\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811c00f-1c67-4cb9-8a91-13a3690d54ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Create a knowledge base using the predefined function\n",
    "    kb = create_knowledge_base_func(\n",
    "        name=\"advanced-rag-workshop-semantic-chunking\",\n",
    "        description=\"Knowledge base using Amazon OpenSearch Service as a vector store\",\n",
    "        chunking_type=\"semantic\"\n",
    "    )\n",
    "\n",
    "    # Retrieve details of the newly created knowledge base\n",
    "    get_kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb['knowledgeBaseId'])\n",
    "\n",
    "    # Update the variables dictionary with the new knowledge base ID\n",
    "    variables[\"kbSemanticChunk\"] = kb['knowledgeBaseId']\n",
    "\n",
    "    # Save updated variables to a JSON file, handling datetime serialization\n",
    "    with open(\"variables.json\", \"w\") as f:\n",
    "        json.dump(variables, f, indent=4, default=str)  # Convert datetime to string\n",
    "\n",
    "    # Print the retrieved knowledge base response in a readable format\n",
    "    print(f'OpenSearch Knowledge Response: {json.dumps(get_kb_response, indent=4, default=str)}')\n",
    "    \n",
    "except Exception as e:\n",
    "    # Check if error message indicates the knowledge base already exists\n",
    "    error_message = str(e).lower()\n",
    "    if any(phrase in error_message for phrase in [\"already exist\", \"duplicate\", \"already been created\"]):\n",
    "        print(\"Knowledge Base already exists. Retrieving its ID...\")\n",
    "        \n",
    "        # List all knowledge bases to find the one that already exists\n",
    "        list_kb_response = bedrock_agent.list_knowledge_bases()\n",
    "        \n",
    "        # Look for a knowledge base with the desired name\n",
    "        for kb in list_kb_response.get('knowledgeBaseSummaries', []):\n",
    "            if kb['name'] == \"advanced-rag-workshop-semantic-chunking\":\n",
    "                kb_id = kb['knowledgeBaseId']\n",
    "                print(f\"Found existing knowledge base with ID: {kb_id}\")\n",
    "                \n",
    "                # Get the details of the existing knowledge base\n",
    "                get_kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb_id)\n",
    "                \n",
    "                # With this code that reads existing values first:\n",
    "                try:\n",
    "                    # Read existing variables\n",
    "                    with open(\"variables.json\", \"r\") as f:\n",
    "                        existing_variables = json.load(f)\n",
    "                except (FileNotFoundError, json.JSONDecodeError):\n",
    "                    # If file doesn't exist or is invalid JSON\n",
    "                    existing_variables = {}\n",
    "                \n",
    "                # Update only the semantic chunking value\n",
    "                existing_variables[\"kbSemanticChunk\"] = kb_id\n",
    "                                \n",
    "                # Write back all variables\n",
    "                with open(\"variables.json\", \"w\") as f:\n",
    "                    json.dump(existing_variables, f, indent=4, default=str)\n",
    "                \n",
    "                # Print the retrieved knowledge base response\n",
    "                print(f'OpenSearch Knowledge Response: {json.dumps(get_kb_response, indent=4, default=str)}')\n",
    "                break        \n",
    "        else:\n",
    "            print(\"Could not find a knowledge base with the specified name.\")\n",
    "    else:\n",
    "        # If it's a different error, re-raise it\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfebc0-bdeb-4f43-a0a0-921d34be6aba",
   "metadata": {},
   "source": [
    "### 2. Create Datasources for Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52912279-14aa-4817-8b33-f8e8786a9a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define the chunking strategy configuration for semantic chunking\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"SEMANTIC\",  # Using semantic chunking strategy\n",
    "    \"semanticChunkingConfiguration\": {\n",
    "        \"maxTokens\": 300,  # Maximum token length per chunk\n",
    "        \"bufferSize\": 1,   # Buffer size to handle context overlap between chunks\n",
    "        \"breakpointPercentileThreshold\": 95  # Percentile threshold for breaking chunks\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configuration for the data source, here it is an S3 bucket where documents will be ingested from\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{variables['s3Bucket']}\",  # S3 bucket ARN\n",
    "    # \"inclusionPrefixes\": [\"shareholder_letters\"] # Optional: can be used to filter specific files in S3\n",
    "}\n",
    "\n",
    "# If a data source already exists with the ID 'ds_semantic_chunk', attempt to delete it\n",
    "if 'ds_semantic_chunk' in locals():\n",
    "    try:\n",
    "        # Deleting the existing data source\n",
    "        bedrock_agent.delete_data_source(\n",
    "            knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "            dataSourceId = ds_semantic_chunk[\"dataSourceId\"],\n",
    "        )\n",
    "        time.sleep(10)  # Wait for a while before creating a new one\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions during deletion (e.g., if the data source doesn't exist)\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "# Create a new data source for ingestion into the knowledge base\n",
    "create_ds_response = bedrock_agent.create_data_source(\n",
    "    name = f'advanced-rag-example',  # Data source name\n",
    "    description = \"A data source for Advanced RAG workshop\",  # Description for the data source\n",
    "    knowledgeBaseId = kb['knowledgeBaseId'],  # Reference to the knowledge base\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",  # Data source type is S3\n",
    "        \"s3Configuration\": s3Configuration  # S3 configuration for the data source\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration  # Apply the defined chunking strategy\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the created data source in a variable for later use\n",
    "ds_semantic_chunk = create_ds_response[\"dataSource\"]\n",
    "\n",
    "# Return the created data source object\n",
    "ds_semantic_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d415f-d61f-49ae-9d9a-1ea3063a1452",
   "metadata": {},
   "source": [
    "### 3. Start Ingestion Job for Amazon Bedrock Knowledge base pointing to Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cc69d",
   "metadata": {},
   "source": [
    "> **Note**: The ingestion process will take approximately 2-3 minutes to complete. During this time, the system is processing your documents by:\n",
    "> 1. Extracting text from the source files\n",
    "> 2. Chunking the content according to the defined strategy (Fixed / Semantic / Hierachical / Custom)\n",
    "> 3. Generating embeddings for each chunk\n",
    "> 4. Storing the embeddings and associated metadata in the OpenSearch vector database\n",
    ">\n",
    "> You'll see status updates as the process progresses. Please wait for the \"Ingestion job completed successfully\" message before proceeding to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c945b5-f64b-4e8a-a290-f9ab2d603304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# List to store ingestion jobs\n",
    "ingest_jobs=[]\n",
    "\n",
    "# Start an ingestion job for the given data source and knowledge base\n",
    "try:\n",
    "    # Initiate the ingestion job and capture the response\n",
    "    start_job_response = bedrock_agent.start_ingestion_job(\n",
    "        knowledgeBaseId = kb['knowledgeBaseId'],  # Knowledge base ID\n",
    "        dataSourceId = ds_semantic_chunk[\"dataSourceId\"]  # Data source ID\n",
    "    )\n",
    "    job = start_job_response[\"ingestionJob\"]  # Retrieve the ingestion job details\n",
    "    print(f\"Ingestion job started successfully\\n\")\n",
    "\n",
    "    # Monitor the ingestion job status until it completes\n",
    "    while(job['status'] != 'COMPLETE'):\n",
    "        # Sleep for a brief period to ensure the job is fully completed\n",
    "        print(\"running...\")\n",
    "        time.sleep(10)\n",
    "        # Check the status of the ingestion job\n",
    "        get_job_response = bedrock_agent.get_ingestion_job(\n",
    "            knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "            dataSourceId = ds_semantic_chunk[\"dataSourceId\"],\n",
    "            ingestionJobId = job[\"ingestionJobId\"]  # Use the ingestion job ID to fetch the status\n",
    "        )\n",
    "        job = get_job_response[\"ingestionJob\"]  # Update the job status\n",
    "\n",
    "    print(f\"Job completed successfully\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors that occur during the job start process\n",
    "    print(f\"Couldn't start job.\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988051f4-2741-4180-af71-d445f2eaf37d",
   "metadata": {},
   "source": [
    "### 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daeb341-cfa4-4c90-9f0d-162e047962e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Bedrock agent runtime client to interact with the Bedrock service\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Define the query to retrieve relevant documents from the knowledge base\n",
    "query = \"What were net incomes of Amazon in 2022, 2023 and 2024?\" \n",
    "\n",
    "# Use the Bedrock agent runtime to retrieve relevant documents from the knowledge base\n",
    "relevant_documents_os = bedrock_agent_runtime.retrieve(\n",
    "    retrievalQuery= {\n",
    "        'text': query  # The text query for retrieving documents\n",
    "    },\n",
    "    knowledgeBaseId=kb['knowledgeBaseId'],  # The knowledge base ID to search within\n",
    "    retrievalConfiguration= {\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 3  # Fetch the top 3 documents that closely match the query\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Return the relevant documents found for the query\n",
    "print(json.dumps([i[\"content\"][\"text\"] for i in relevant_documents_os[\"retrievalResults\"]], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea0327",
   "metadata": {},
   "source": [
    "> **Note**: After creating the knowledge base, you can explore its details and settings in the Amazon Bedrock console. This gives you a more visual interface to understand how the knowledge base is structured.\n",
    "> \n",
    "> **[➡️ View your Knowledge Bases in the AWS Console](https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/knowledge-bases)**\n",
    ">\n",
    "> In the console, you can:\n",
    "> - See all your knowledge bases in one place\n",
    "> - View ingestion status and statistics\n",
    "> - Test queries through the built-in chat interface\n",
    "> - Modify settings and configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
