{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8617ba3-d126-49f3-a772-1a0ef066b3cf",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base with Hierarchical chunking strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88904b8a-3666-4f82-9801-712e9397b681",
   "metadata": {},
   "source": [
    "#### Concept\n",
    "\n",
    "**Hierarchical Chunking**: Organizes your data into a hierarchical structure, allowing for more granular and efficient retrieval based on the inherent relationships within your data. \n",
    "\n",
    "Organizing your data into a hierarchical structure enables your **RAG (Retrieval-Augmented Generation)** workflow to efficiently navigate and retrieve information from complex, nested datasets. After documents are parsed, the first step is to **chunk** them based on the **parent** and **child chunking size**. \n",
    "\n",
    "- **Parent chunks (higher level)** represent larger segments, such as entire documents or sections.\n",
    "- **Child chunks (lower level)** represent smaller segments, such as paragraphs or sentences.\n",
    "\n",
    "The relationship between parent and child chunks is maintained, allowing for **efficient retrieval and navigation** of the corpus.\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "- **Efficient Retrieval**: The hierarchical structure enables faster and more targeted retrieval of relevant information by first performing a **semantic search** on child chunks and then returning the parent chunk. By replacing child chunks with parent chunks, we provide **larger and more comprehensive context** to the foundation model (FM).\n",
    "- **Context Preservation**: Organizing the corpus hierarchically helps maintain contextual relationships between chunks, ensuring more **coherent and contextually relevant** text generation.\n",
    "\n",
    "> **Note:** In hierarchical chunking, **parent chunks** are returned while **search is performed on child chunks**. As a result, you may see **fewer search results**, since one parent can have multiple child chunks.\n",
    "\n",
    "### **Best Use Cases**\n",
    "Hierarchical chunking is best suited for **complex documents** with a nested or hierarchical structure, such as:\n",
    "- **Technical manuals**\n",
    "- **Legal documents**\n",
    "- **Academic papers** with complex formatting and nested tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee600b-1630-416e-acaa-d9de5630cb3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e5afe-e197-458a-af71-6b5fc004d491",
   "metadata": {},
   "source": [
    "### 1. Create a Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05bdd0f-806c-44f8-9840-ba955e5c43ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from retrying import retry\n",
    "import boto3\n",
    "\n",
    "# Initialize the Bedrock agent client with the appropriate region\n",
    "bedrock_agent = boto3.client(\"bedrock-agent\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Helper function to create a knowledge base with retry mechanism\n",
    "@retry(wait_random_min=1000, wait_random_max=2000, stop_max_attempt_number=3)\n",
    "def create_knowledge_base_func(name, description, chunking_type):\n",
    "    \"\"\"\n",
    "    Creates a knowledge base in Amazon Bedrock with OpenSearch Serverless storage configuration.\n",
    "    \n",
    "    Args:\n",
    "    - name (str): The name of the knowledge base.\n",
    "    - description (str): A brief description of the knowledge base.\n",
    "    - chunking_type (str): The type of chunking to be used (e.g., 'fixed', 'hierarchical').\n",
    "    \n",
    "    Returns:\n",
    "    - dict: The knowledge base details returned by the API call.\n",
    "    \"\"\"\n",
    "    # Define the embedding model ARN used by Bedrock for document embedding\n",
    "    embedding_model_arn = f\"arn:aws:bedrock:{variables['regionName']}::foundation-model/amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "    # Define OpenSearch Serverless configuration\n",
    "    opensearch_serverless_configuration = {\n",
    "        \"collectionArn\": variables[\"collectionArn\"],  # ARN of the OpenSearch collection\n",
    "        \"vectorIndexName\": variables[\"vectorIndexName\"] + chunking_type,  # Vector index name based on chunking type\n",
    "        \"fieldMapping\": {  # Field mapping for the OpenSearch index\n",
    "            \"vectorField\": \"vector\",\n",
    "            \"textField\": \"text\",\n",
    "            \"metadataField\": \"text-metadata\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print the OpenSearch configuration for debugging purposes\n",
    "    print(opensearch_serverless_configuration)\n",
    "    \n",
    "    try:\n",
    "        # Call the Bedrock agent's create_knowledge_base API to create the knowledge base\n",
    "        create_kb_response = bedrock_agent.create_knowledge_base(\n",
    "            name=name,\n",
    "            description=description,\n",
    "            roleArn=variables[\"bedrockExecutionRoleArn\"],  # ARN of the execution role\n",
    "            knowledgeBaseConfiguration={\n",
    "                \"type\": \"VECTOR\",  # Define the knowledge base as a vector knowledge base\n",
    "                \"vectorKnowledgeBaseConfiguration\": {\n",
    "                    \"embeddingModelArn\": embedding_model_arn  # Define the embedding model ARN\n",
    "                }\n",
    "            },\n",
    "            storageConfiguration={\n",
    "                \"type\": \"OPENSEARCH_SERVERLESS\",  # Using OpenSearch Serverless for storage\n",
    "                \"opensearchServerlessConfiguration\": opensearch_serverless_configuration\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Return the knowledge base details from the response\n",
    "        return create_kb_response[\"knowledgeBase\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions (e.g., API failures) and print the error message\n",
    "        print(f\"Error creating knowledge base: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dcd35-6fa9-4d06-a436-78b2136e269f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Try to create a knowledge base, but handle the case where it returns None\n",
    "kb = create_knowledge_base_func(\n",
    "    name=\"advanced-rag-workshop-hierarchical-chunking\",\n",
    "    description=\"Knowledge base using Amazon OpenSearch Service as a vector store\",\n",
    "    chunking_type=\"hierarchical\"\n",
    ")\n",
    "\n",
    "# Check if kb is None (meaning creation failed)\n",
    "if kb is None:\n",
    "    print(\"Knowledge Base creation returned None. Checking if it already exists...\")\n",
    "    \n",
    "    # List all knowledge bases to find the one that already exists\n",
    "    list_kb_response = bedrock_agent.list_knowledge_bases()\n",
    "    \n",
    "    # Look for a knowledge base with the desired name\n",
    "    for existing_kb in list_kb_response.get('knowledgeBaseSummaries', []):\n",
    "        if existing_kb['name'] == \"advanced-rag-workshop-hierarchical-chunking\":\n",
    "            kb_id = existing_kb['knowledgeBaseId']\n",
    "            print(f\"Found existing knowledge base with ID: {kb_id}\")\n",
    "            \n",
    "            # Get the details of the existing knowledge base\n",
    "            get_kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb_id)\n",
    "            \n",
    "            # Read existing variables to preserve other fields\n",
    "            try:\n",
    "                # Read existing variables\n",
    "                with open(\"variables.json\", \"r\") as f:\n",
    "                    existing_variables = json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                # If file doesn't exist or is invalid JSON\n",
    "                existing_variables = {}\n",
    "            \n",
    "            # Update only the hierarchical chunking value\n",
    "            existing_variables[\"kbHierarchicalChunk\"] = kb_id\n",
    "                            \n",
    "            # Write back all variables\n",
    "            with open(\"variables.json\", \"w\") as f:\n",
    "                json.dump(existing_variables, f, indent=4, default=str)\n",
    "            \n",
    "            # Print the retrieved knowledge base response\n",
    "            print(f'OpenSearch Knowledge Response: {json.dumps(get_kb_response, indent=4, default=str)}')\n",
    "            break        \n",
    "    else:\n",
    "        print(\"Could not find a knowledge base with the specified name.\")\n",
    "else:\n",
    "    # KB was created successfully, proceed with original flow\n",
    "    try:\n",
    "        # Retrieve details of the newly created knowledge base\n",
    "        get_kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb['knowledgeBaseId'])\n",
    "\n",
    "        # Read existing variables to preserve other fields\n",
    "        try:\n",
    "            with open(\"variables.json\", \"r\") as f:\n",
    "                variables = json.load(f)\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            pass  # Use existing variables dict\n",
    "\n",
    "        # Update the variables dictionary with the new knowledge base ID\n",
    "        variables[\"kbHierarchicalChunk\"] = kb['knowledgeBaseId']\n",
    "\n",
    "        # Save updated variables to a JSON file, handling datetime serialization\n",
    "        with open(\"variables.json\", \"w\") as f:\n",
    "            json.dump(variables, f, indent=4, default=str)\n",
    "\n",
    "        # Print the retrieved knowledge base response in a readable format\n",
    "        print(f'OpenSearch Knowledge Response: {json.dumps(get_kb_response, indent=4, default=str)}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing newly created knowledge base: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ec04a-b09a-40dc-8309-88dee13051a3",
   "metadata": {},
   "source": [
    "### 2. Create Datasources for Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878b51c-6295-484c-a8d0-7be85c23d3f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# First, retrieve the knowledge base ID by listing all KBs and finding the hierarchical one\n",
    "print(\"Retrieving knowledge base ID for hierarchical chunking...\")\n",
    "list_kb_response = bedrock_agent.list_knowledge_bases()\n",
    "kb_id = None\n",
    "\n",
    "# Look for the hierarchical chunking knowledge base by name\n",
    "for existing_kb in list_kb_response.get('knowledgeBaseSummaries', []):\n",
    "    if existing_kb['name'] == \"advanced-rag-workshop-hierarchical-chunking\":\n",
    "        kb_id = existing_kb['knowledgeBaseId']\n",
    "        print(f\"Found existing knowledge base with ID: {kb_id}\")\n",
    "        \n",
    "        # Read existing variables to preserve other fields\n",
    "        try:\n",
    "            with open(\"variables.json\", \"r\") as f:\n",
    "                variables = json.load(f)\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            pass\n",
    "            \n",
    "        # Update variables with the hierarchical KB ID (if needed)\n",
    "        variables[\"kbHierarchicalChunk\"] = kb_id\n",
    "        \n",
    "        # Save updated variables\n",
    "        with open(\"variables.json\", \"w\") as f:\n",
    "            json.dump(variables, f, indent=4, default=str)\n",
    "            \n",
    "        break\n",
    "else:\n",
    "    print(\"Could not find the hierarchical chunking knowledge base.\")\n",
    "\n",
    "# Proceed only if we found the knowledge base ID\n",
    "if kb_id:\n",
    "    # Define the chunking strategy for ingestion using a hierarchical approach\n",
    "    chunking_strategy_configuration = {\n",
    "        \"chunkingStrategy\": \"HIERARCHICAL\",\n",
    "        \"hierarchicalChunkingConfiguration\": {\n",
    "            \"levelConfigurations\": [\n",
    "                {\"maxTokens\": 1500},\n",
    "                {\"maxTokens\": 300}\n",
    "            ],\n",
    "            \"overlapTokens\": 60\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # The data source to ingest documents from, with the data prefix\n",
    "    s3_configuration = {\n",
    "        \"bucketArn\": f\"arn:aws:s3:::{variables['s3Bucket']}\",\n",
    "        \"inclusionPrefixes\": [\"data\"]  # Only include objects with the \"data\" prefix\n",
    "    }\n",
    "\n",
    "    data_source_name = \"advanced-rag-example\"\n",
    "\n",
    "    # First, check if a data source with this name already exists in Bedrock\n",
    "    try:\n",
    "        # List all data sources for the knowledge base\n",
    "        list_ds_response = bedrock_agent.list_data_sources(\n",
    "            knowledgeBaseId=kb_id\n",
    "        )\n",
    "        \n",
    "        # Check if our named data source exists\n",
    "        existing_ds = None\n",
    "        for ds in list_ds_response.get('dataSourceSummaries', []):\n",
    "            if ds['name'] == data_source_name:\n",
    "                existing_ds = ds\n",
    "                break\n",
    "        \n",
    "        # If it exists, delete it\n",
    "        if existing_ds:\n",
    "            print(f\"Found existing data source '{data_source_name}'. Deleting it...\")\n",
    "            bedrock_agent.delete_data_source(\n",
    "                knowledgeBaseId=kb_id,\n",
    "                dataSourceId=existing_ds[\"dataSourceId\"]\n",
    "            )\n",
    "            print(\"Waiting for data source deletion to complete...\")\n",
    "            time.sleep(10)\n",
    "            print(\"Data source deleted successfully.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error while checking or deleting data source: {e}\")\n",
    "\n",
    "    # Now create a new data source\n",
    "    try:\n",
    "        print(f\"Creating new data source '{data_source_name}' with hierarchical chunking...\")\n",
    "        create_ds_response = bedrock_agent.create_data_source(\n",
    "            name=data_source_name,\n",
    "            description=\"A data source for Advanced RAG workshop\",\n",
    "            knowledgeBaseId=kb_id,\n",
    "            dataSourceConfiguration={\n",
    "                \"type\": \"S3\",\n",
    "                \"s3Configuration\": s3_configuration\n",
    "            },\n",
    "            vectorIngestionConfiguration={\n",
    "                \"chunkingConfiguration\": chunking_strategy_configuration\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Store the created data source object\n",
    "        ds_hierarchical_chunk = create_ds_response[\"dataSource\"]\n",
    "        print(f\"Hierarchical chunking data source created successfully.\")\n",
    "        \n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ConflictException':\n",
    "            print(f\"Data source '{data_source_name}' still exists. Retrieving it...\")\n",
    "            # Get the existing data source\n",
    "            list_ds_response = bedrock_agent.list_data_sources(\n",
    "                knowledgeBaseId=kb_id\n",
    "            )\n",
    "            for ds in list_ds_response.get('dataSourceSummaries', []):\n",
    "                if ds['name'] == data_source_name:\n",
    "                    ds_hierarchical_chunk = ds\n",
    "                    print(f\"Retrieved existing data source: {ds['dataSourceId']}\")\n",
    "                    break\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Print the data source information\n",
    "    print(ds_hierarchical_chunk)\n",
    "else:\n",
    "    print(\"Cannot proceed without a valid knowledge base ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946a50d-0255-41d0-bb9f-89dc4d4f9ead",
   "metadata": {},
   "source": [
    "### 3. Start Ingestion Job for Amazon Bedrock Knowledge base pointing to Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c50da",
   "metadata": {},
   "source": [
    "> **Note**: The ingestion process will take approximately 2-3 minutes to complete. During this time, the system is processing your documents by:\n",
    "> 1. Extracting text from the source files\n",
    "> 2. Chunking the content according to the defined strategy (Fixed / Semantic / Hierachical / Custom)\n",
    "> 3. Generating embeddings for each chunk\n",
    "> 4. Storing the embeddings and associated metadata in the OpenSearch vector database\n",
    ">\n",
    "> You'll see status updates as the process progresses. Please wait for the \"Ingestion job completed successfully\" message before proceeding to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353d724-c272-4787-a487-80c2b1fa3a4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Get the knowledge base ID from variables.json\n",
    "try:\n",
    "    with open(\"variables.json\", \"r\") as f:\n",
    "        variables = json.load(f)\n",
    "    kb_id = variables.get(\"kbHierarchicalChunk\")\n",
    "    \n",
    "    if not kb_id:\n",
    "        print(\"Knowledge base ID not found in variables.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading knowledge base ID: {e}\")\n",
    "    kb_id = None\n",
    "\n",
    "# Start an ingestion job for the given data source and knowledge base\n",
    "try:\n",
    "    # Initiate the ingestion job and capture the response\n",
    "    start_job_response = bedrock_agent.start_ingestion_job(\n",
    "        knowledgeBaseId=kb_id,  # Use the retrieved knowledge base ID instead of kb['knowledgeBaseId']\n",
    "        dataSourceId=ds_hierarchical_chunk[\"dataSourceId\"]\n",
    "    )\n",
    "    job = start_job_response[\"ingestionJob\"]\n",
    "    print(f\"Ingestion job started successfully\\n\")\n",
    "\n",
    "    # Monitor the ingestion job status until it completes\n",
    "    while job['status'] != 'COMPLETE':\n",
    "        print(\"running...\")\n",
    "        time.sleep(10)\n",
    "        # Check the status of the ingestion job\n",
    "        get_job_response = bedrock_agent.get_ingestion_job(\n",
    "            knowledgeBaseId=kb_id,  # Use the retrieved knowledge base ID here too\n",
    "            dataSourceId=ds_hierarchical_chunk[\"dataSourceId\"],\n",
    "            ingestionJobId=job[\"ingestionJobId\"]\n",
    "        )\n",
    "        job = get_job_response[\"ingestionJob\"]\n",
    "\n",
    "    print(f\"Job completed successfully\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't start job.\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fd3ab-cc8b-4a24-9696-4ac1190ca0bd",
   "metadata": {},
   "source": [
    "### 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc7a7f-773b-47b2-aa47-bbbe22a2e2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Load the knowledge base ID from variables.json\n",
    "try:\n",
    "    with open(\"variables.json\", \"r\") as f:\n",
    "        variables = json.load(f)\n",
    "    kb_id = variables.get(\"kbHierarchicalChunk\")  # Get the hierarchical kb ID\n",
    "    \n",
    "    if not kb_id:\n",
    "        print(\"Knowledge base ID not found in variables.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading knowledge base ID: {e}\")\n",
    "    kb_id = None\n",
    "\n",
    "# Initialize the Bedrock Agent Runtime client\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Define the query for document retrieval\n",
    "query = \"What were net incomes of Amazon in 2022, 2023 and 2024?\" \n",
    "\n",
    "# Retrieve relevant documents from the knowledge base\n",
    "relevant_documents_os = bedrock_agent_runtime.retrieve(\n",
    "    retrievalQuery={\n",
    "        'text': query  # Search query\n",
    "    },\n",
    "    knowledgeBaseId=kb_id,  # Use the retrieved knowledge base ID instead of kb['knowledgeBaseId']\n",
    "    retrievalConfiguration={\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 3  # Limit to top 3 results\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the retrieved documents\n",
    "print(json.dumps([i[\"content\"][\"text\"] for i in relevant_documents_os[\"retrievalResults\"]], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55a037",
   "metadata": {},
   "source": [
    "> **Note**: After creating the knowledge base, you can explore its details and settings in the Amazon Bedrock console. This gives you a more visual interface to understand how the knowledge base is structured.\n",
    "> \n",
    "> **[➡️ View your Knowledge Bases in the AWS Console](https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/knowledge-bases)**\n",
    ">\n",
    "> In the console, you can:\n",
    "> - See all your knowledge bases in one place\n",
    "> - View ingestion status and statistics\n",
    "> - Test queries through the built-in chat interface\n",
    "> - Modify settings and configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
