{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64457169-0b6e-411e-a1da-02c8a7d4ac8d",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with Reranking\n",
    "\n",
    "The Rerank API in Amazon Bedrock is a new feature that improves the accuracy and relevance of responses in Retrieval-Augmented Generation (RAG) applications. It supports reranker models that rank a set of retrieved documents based on their relevance to a user's query, helping to prioritize the most relevant content for response generation.\n",
    "\n",
    "## Key features and use cases:\n",
    "\n",
    "1. **Enhancing RAG applications**: The Rerank API addresses challenges in semantic search, particularly with complex or ambiguous queries. For example, it can help a customer service chatbot focus on return policies rather than shipping guidelines when asked about returning an online purchase.\n",
    "\n",
    "2. **Improving search relevance**: It enables developers to significantly enhance their search relevance and content ranking capabilities, making enterprise-grade search technology more accessible.\n",
    "\n",
    "3. **Optimizing context window usage**: By ensuring the most useful information is sent to the foundation model, it potentially reduces costs and improves response accuracy.\n",
    "\n",
    "4. **Flexible integration**: The Rerank API can be used independently to rerank documents even if you're not using Amazon Bedrock Knowledge Bases.\n",
    "\n",
    "5. **Multiple model support**: At launch, it supports Amazon Rerank 1.0 and Cohere Rerank 3.5 models.\n",
    "\n",
    "6. **Customizable configurations**: Developers can specify additional model configurations as key-value pairs for more tailored reranking.\n",
    "\n",
    "The Rerank API is available in select AWS Regions, including US West (Oregon), Canada (Central), Europe (Frankfurt), and Asia Pacific (Tokyo). It can be integrated into existing systems at scale, whether keyword-based or semantic, through a single API call in Amazon Bedrock.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3958d",
   "metadata": {},
   "source": [
    "![Reranking](./reranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ecae6-7c0a-4490-857c-c41e5c8d445e",
   "metadata": {},
   "source": [
    "## 1: Import and Load Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a1a59-a87c-4953-9b79-1194f7fcce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the configuration variables from a JSON file\n",
    "with open(\"../Lab 1/variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c78a0f-b980-4753-b2e0-5dcd0b0f44cb",
   "metadata": {},
   "source": [
    "## 2: Define ARN and Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85280494-5d51-4c3b-939c-b4f482e422c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up configuration for Bedrock\n",
    "regionName=variables['regionName'] \n",
    "accountNumber = variables['accountNumber']\n",
    "knowledge_base_id = variables['kbFixedChunk']   \n",
    "model_id = 'us.amazon.nova-pro-v1:0' \n",
    "\n",
    "# Define ARNs (Amazon Resource Names) for the model\n",
    "model_arn = f\"arn:aws:bedrock:us-west-2:{accountNumber}:inference-profile/{model_id}\"\n",
    "rerank_model_arn=f\"arn:aws:bedrock:us-west-2::foundation-model/cohere.rerank-v3-5:0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b99bb-d6c8-4283-bdac-51919d025d45",
   "metadata": {},
   "source": [
    "## 3: Set Up Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80f441-1cd3-4ea0-8d04-5043c2a8ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "# Configure the Bedrock client\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=\"us-west-2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e7d3c-18f5-42f4-af0b-819ed8ee891c",
   "metadata": {},
   "source": [
    "## 4: Define Function for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64568e-579d-4362-9753-e3d9e52eece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def search_kb_with_optional_rerank(query, kb_id, model_arn=None, use_reranking=False):\n",
    "    \"\"\"Search KB and optionally rerank results\"\"\"\n",
    "    client = boto3.client(\"bedrock-agent-runtime\", region_name=regionName)\n",
    "    \n",
    "    # 1. Retrieve from knowledge base\n",
    "    kb_response = client.retrieve(\n",
    "        knowledgeBaseId=kb_id,\n",
    "        retrievalQuery={\"text\": query},\n",
    "        retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": 10}}\n",
    "    )\n",
    "    \n",
    "    # Extract documents\n",
    "    documents = []\n",
    "    original_results = []\n",
    "    \n",
    "    for i, result in enumerate(kb_response.get(\"retrievalResults\", [])):\n",
    "        # Extract text from result\n",
    "        text = \"\"\n",
    "        if \"content\" in result and \"text\" in result[\"content\"]:\n",
    "            text = \"\".join([item.get(\"span\", \"\") if isinstance(item, dict) else str(item) \n",
    "                           for item in result[\"content\"][\"text\"]])\n",
    "            \n",
    "        # Store original result\n",
    "        original_results.append({\n",
    "            \"position\": i + 1,\n",
    "            \"score\": result.get(\"scoreValue\", 0),\n",
    "            \"text\": text[:300] + \"...\" if len(text) > 300 else text\n",
    "        })\n",
    "        documents.append(text)\n",
    "    \n",
    "    # 2. Rerank if enabled\n",
    "    if use_reranking and model_arn and documents:\n",
    "        reranked = client.rerank(\n",
    "            queries=[{\"textQuery\": {\"text\": query}, \"type\": \"TEXT\"}],\n",
    "            rerankingConfiguration={\n",
    "                \"bedrockRerankingConfiguration\": {\n",
    "                    \"modelConfiguration\": {\"modelArn\": model_arn},\n",
    "                    \"numberOfResults\": 10\n",
    "                },\n",
    "                \"type\": \"BEDROCK_RERANKING_MODEL\"\n",
    "            },\n",
    "            sources=[{\n",
    "                \"inlineDocumentSource\": {\"textDocument\": {\"text\": doc}, \"type\": \"TEXT\"},\n",
    "                \"type\": \"INLINE\"\n",
    "            } for doc in documents]\n",
    "        )\n",
    "        \n",
    "        # Process reranked results\n",
    "        reranked_results = []\n",
    "        for result in reranked.get(\"results\", []):\n",
    "            idx = result.get(\"index\", 0)\n",
    "            reranked_results.append({\n",
    "                \"original_position\": idx + 1,\n",
    "                \"new_position\": len(reranked_results) + 1,\n",
    "                \"relevance_score\": result.get(\"relevanceScore\", 0),  # Full precision score\n",
    "                \"text\": documents[idx][:300] + \"...\"\n",
    "            })\n",
    "        return {\"original_results\": original_results, \"reranked_results\": reranked_results}\n",
    "        \n",
    "    return {\"original_results\": original_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c3501-3e47-4c73-be9d-2af97a495039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate(query, kb_id, model_arn, use_reranking=True):\n",
    "    \"\"\"Full RAG pipeline adapted for Amazon Nova Pro Model\"\"\"\n",
    "    import json\n",
    "    import boto3\n",
    "    from botocore.exceptions import ClientError\n",
    "\n",
    "    # 1. Search and get documents\n",
    "    results = search_kb_with_optional_rerank(query, kb_id, model_arn, use_reranking)\n",
    "    \n",
    "    # 2. Prepare context\n",
    "    if use_reranking and \"reranked_results\" in results:\n",
    "        docs = [doc[\"text\"] for doc in results[\"reranked_results\"]]\n",
    "        source_type = \"reranked\"\n",
    "    else:\n",
    "        docs = [doc[\"text\"] for doc in results[\"original_results\"]]\n",
    "        source_type = \"vector search\"\n",
    "    \n",
    "    context = \"\\n\".join([f\"Document {i+1}: {doc[:300]}...\" for i, doc in enumerate(docs[:3])])\n",
    "    prompt_data = f\"Query: {query}\\n\\nContext from {source_type}:\\n{context}\\n\\nAnswer:\"\n",
    "\n",
    "    # 3. Format request body for Nova Pro Model\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": prompt_data}]}],\n",
    "            \"inferenceConfig\": {\n",
    "                \"max_new_tokens\": 2000,\n",
    "                \"top_p\": 0.9,\n",
    "                \"top_k\": 20,\n",
    "                \"temperature\": 0.1\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 4. Set up model invocation parameters\n",
    "    modelId = model_id  # Replace with the correct Nova Pro model ID\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=regionName)  # Update region as needed\n",
    "\n",
    "    try:\n",
    "        # Invoke the Nova Pro Model\n",
    "        response = client.invoke_model(\n",
    "            body=body,\n",
    "            modelId=modelId,\n",
    "            accept=accept,\n",
    "            contentType=contentType\n",
    "        )\n",
    "        \n",
    "        # Parse the response body\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        #print(response_body)\n",
    "        # Extract the generated text from the response\n",
    "        return response_body\n",
    "\n",
    "    except ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "            print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubleshoot this issue, please refer to the following resources:\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        else:\n",
    "            raise error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce463a2-c6ec-4868-820d-210478e87b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate_claude(query, kb_id, model_arn, use_reranking=True):\n",
    "    \"\"\"Full RAG pipeline adapted for Amazon Bedrock models\"\"\"\n",
    "    import json\n",
    "    import boto3\n",
    "    from botocore.exceptions import ClientError\n",
    "\n",
    "    # 1. Search and get documents\n",
    "    results = search_kb_with_optional_rerank(query, kb_id, rerank_model_arn, use_reranking)\n",
    "    \n",
    "    # 2. Prepare context\n",
    "    if use_reranking and \"reranked_results\" in results:\n",
    "        docs = [doc[\"text\"] for doc in results[\"reranked_results\"]]\n",
    "        source_type = \"reranked\"\n",
    "    else:\n",
    "        docs = [doc[\"text\"] for doc in results[\"original_results\"]]\n",
    "        source_type = \"vector search\"\n",
    "    \n",
    "    # Limit to top 3 documents\n",
    "    docs = docs[:3]\n",
    "    \n",
    "    # 3. Format request body based on model type\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=regionName)\n",
    "    \n",
    "    if \"claude\" in model_id.lower():\n",
    "        # Claude-specific formatting\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 2000,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 20,\n",
    "            \"temperature\": 0.1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \n",
    "                            \"text\": f\"Answer the following question based on the provided context.\\n\\nQuestion: {query}\\n\\nContext:\\n{' '.join(docs)}\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "    else:\n",
    "        # For document-query format API models (like the error suggests)\n",
    "        # Convert document objects to plain strings\n",
    "        formatted_docs = []\n",
    "        for doc in docs:\n",
    "            formatted_docs.append(doc)\n",
    "            \n",
    "        body = json.dumps({\n",
    "            \"query\": query,\n",
    "            \"documents\": formatted_docs,\n",
    "            \"api_version\": 1  # Integer instead of string\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        # Invoke the model\n",
    "        response = client.invoke_model(\n",
    "            body=body.encode(\"utf-8\"),  # Ensure body is encoded as bytes\n",
    "            modelId=model_id,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        \n",
    "        # Parse the response body\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        \n",
    "        return response_body\n",
    "\n",
    "    except ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "            print(f\"\\x1b[41m{error.response['Error']['Message']}\\n\\\n",
    "                \\nTo troubleshoot this issue, please refer to the following resources:\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        else:\n",
    "            raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f0626-18ca-4594-9034-7805bcc00ddd",
   "metadata": {},
   "source": [
    "## 5: Define Function for Retrieve and Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a97b19-c508-4861-862e-24c4e0d4a0fb",
   "metadata": {},
   "source": [
    "## 6: Compare the Retrieved results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d350c46-219d-449d-b475-197b218a9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "query = \"What was the margin percentage change in Amazon's international segment between year 2022 and 2023\"\n",
    "# Without reranking\n",
    "print(\"WITHOUT RERANKING:\")\n",
    "results_no_rerank = search_kb_with_optional_rerank(\n",
    "    query, knowledge_base_id, rerank_model_arn, use_reranking=False\n",
    ")\n",
    "\n",
    "# Display original results\n",
    "print(\"\\nTOP  DOCUMENTS WITHOUT RERANKING:\")\n",
    "for doc in results_no_rerank[\"original_results\"][:20]:\n",
    "    print(f\"Position {doc['position']} (Score: {doc['score']}):\")\n",
    "    print(f\"{doc['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa683f5-a4ce-424d-b4d3-100be0319c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With reranking\n",
    "print(\"\\nWITH RERANKING:\")\n",
    "results_with_rerank = search_kb_with_optional_rerank(\n",
    "    query, knowledge_base_id, rerank_model_arn, use_reranking=True\n",
    ")\n",
    "\n",
    "# Show reranked results with full precision scores\n",
    "print(\"\\nTOP  DOCUMENTS AFTER RERANKING:\")\n",
    "for doc in results_with_rerank[\"reranked_results\"][:10]:\n",
    "    print(f\"Moved from position {doc['original_position']} to {doc['new_position']}\")\n",
    "    print(f\"Relevance score: {doc['relevance_score']}\")  # Full precision\n",
    "    print(f\"{doc['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af57f6-502f-4765-9e67-1e060f793978",
   "metadata": {},
   "source": [
    "## 7: Compare the Generated results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d46554-9282-432c-b658-ed206c0c923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGENERATED ANSWER WITHOUT RERANKING:\")\n",
    "answer_no_rerank = retrieve_and_generate(query, knowledge_base_id, rerank_model_arn, use_reranking=False)\n",
    "#print(answer_no_rerank['content'][0]['text'])\n",
    "print(answer_no_rerank['output']['message']['content'][0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a82a24-0ee7-404e-bcd0-64b9c9d484ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nGENERATED ANSWER WITH RERANKING:\")\n",
    "answer_with_rerank = retrieve_and_generate(query, knowledge_base_id, rerank_model_arn, use_reranking=True)\n",
    "#print(answer_with_rerank['content'][0]['text'])\n",
    "print(answer_with_rerank['output']['message']['content'][0]['text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
