{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64457169-0b6e-411e-a1da-02c8a7d4ac8d",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with Reranking\n",
    "\n",
    "The Rerank API in Amazon Bedrock is a new feature that improves the accuracy and relevance of responses in Retrieval-Augmented Generation (RAG) applications. It supports reranker models that rank a set of retrieved documents based on their relevance to a user's query, helping to prioritize the most relevant content for response generation.\n",
    "\n",
    "## Key features and use cases:\n",
    "\n",
    "1. **Enhancing RAG applications**: The Rerank API addresses challenges in semantic search, particularly with complex or ambiguous queries. For example, it can help a customer service chatbot focus on return policies rather than shipping guidelines when asked about returning an online purchase.\n",
    "\n",
    "2. **Improving search relevance**: It enables developers to significantly enhance their search relevance and content ranking capabilities, making enterprise-grade search technology more accessible.\n",
    "\n",
    "3. **Optimizing context window usage**: By ensuring the most useful information is sent to the foundation model, it potentially reduces costs and improves response accuracy.\n",
    "\n",
    "4. **Flexible integration**: The Rerank API can be used independently to rerank documents even if you're not using Amazon Bedrock Knowledge Bases.\n",
    "\n",
    "5. **Multiple model support**: At launch, it supports Amazon Rerank 1.0 and Cohere Rerank 3.5 models.\n",
    "\n",
    "6. **Customizable configurations**: Developers can specify additional model configurations as key-value pairs for more tailored reranking.\n",
    "\n",
    "The Rerank API is available in select AWS Regions, including US West (Oregon), Canada (Central), Europe (Frankfurt), and Asia Pacific (Tokyo). It can be integrated into existing systems at scale, whether keyword-based or semantic, through a single API call in Amazon Bedrock.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ecae6-7c0a-4490-857c-c41e5c8d445e",
   "metadata": {},
   "source": [
    "## 1: Import and Load Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a1a59-a87c-4953-9b79-1194f7fcce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the configuration variables from a JSON file\n",
    "with open(\"../Lab 1/variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c78a0f-b980-4753-b2e0-5dcd0b0f44cb",
   "metadata": {},
   "source": [
    "## 2: Define ARN and Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85280494-5d51-4c3b-939c-b4f482e422c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up configuration for Bedrock\n",
    "regionName=variables['regionName'] \n",
    "accountNumber = variables['accountNumber']\n",
    "knowledge_base_id = variables['kbFixedChunk']   \n",
    "model_id = 'us.amazon.nova-pro-v1:0' \n",
    "\n",
    "# Define ARNs (Amazon Resource Names) for the model\n",
    "model_arn = f\"arn:aws:bedrock:us-west-2:{accountNumber}:inference-profile/{model_id}\"\n",
    "rerank_model_arn=f\"arn:aws:bedrock:us-west-2::foundation-model/cohere.rerank-v3-5:0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b99bb-d6c8-4283-bdac-51919d025d45",
   "metadata": {},
   "source": [
    "## 3: Set Up Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80f441-1cd3-4ea0-8d04-5043c2a8ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "# Configure the Bedrock client\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=\"us-west-2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e7d3c-18f5-42f4-af0b-819ed8ee891c",
   "metadata": {},
   "source": [
    "## 4: Define Function for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64568e-579d-4362-9753-e3d9e52eece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def search_kb_with_optional_rerank(query, kb_id, model_arn=None, use_reranking=False):\n",
    "    \"\"\"Search KB and optionally rerank results\"\"\"\n",
    "    client = boto3.client(\"bedrock-agent-runtime\", region_name=regionName)\n",
    "    \n",
    "    # 1. Retrieve from knowledge base\n",
    "    kb_response = client.retrieve(\n",
    "        knowledgeBaseId=kb_id,\n",
    "        retrievalQuery={\"text\": query},\n",
    "        retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": 5}}\n",
    "    )\n",
    "    \n",
    "    # Extract documents\n",
    "    documents = []\n",
    "    original_results = []\n",
    "    \n",
    "    for i, result in enumerate(kb_response.get(\"retrievalResults\", [])):\n",
    "        # Extract text from result\n",
    "        text = \"\"\n",
    "        if \"content\" in result and \"text\" in result[\"content\"]:\n",
    "            text = \" \".join([item.get(\"span\", \"\") if isinstance(item, dict) else str(item) \n",
    "                           for item in result[\"content\"][\"text\"]])\n",
    "            \n",
    "        # Store original result\n",
    "        original_results.append({\n",
    "            \"position\": i + 1,\n",
    "            \"score\": result.get(\"scoreValue\", 0),\n",
    "            \"text\": text[:300] + \"...\" if len(text) > 300 else text\n",
    "        })\n",
    "        documents.append(text)\n",
    "    \n",
    "    # 2. Rerank if enabled\n",
    "    if use_reranking and model_arn and documents:\n",
    "        reranked = client.rerank(\n",
    "            queries=[{\"textQuery\": {\"text\": query}, \"type\": \"TEXT\"}],\n",
    "            rerankingConfiguration={\n",
    "                \"bedrockRerankingConfiguration\": {\n",
    "                    \"modelConfiguration\": {\"modelArn\": model_arn},\n",
    "                    \"numberOfResults\": 5\n",
    "                },\n",
    "                \"type\": \"BEDROCK_RERANKING_MODEL\"\n",
    "            },\n",
    "            sources=[{\n",
    "                \"inlineDocumentSource\": {\"textDocument\": {\"text\": doc}, \"type\": \"TEXT\"},\n",
    "                \"type\": \"INLINE\"\n",
    "            } for doc in documents]\n",
    "        )\n",
    "        \n",
    "        # Process reranked results\n",
    "        reranked_results = []\n",
    "        for result in reranked.get(\"results\", []):\n",
    "            idx = result.get(\"index\", 0)\n",
    "            reranked_results.append({\n",
    "                \"original_position\": idx + 1,\n",
    "                \"new_position\": len(reranked_results) + 1,\n",
    "                \"relevance_score\": result.get(\"relevanceScore\", 0),  # Full precision score\n",
    "                \"text\": documents[idx][:300] + \"...\"\n",
    "            })\n",
    "        return {\"original_results\": original_results, \"reranked_results\": reranked_results}\n",
    "        \n",
    "    return {\"original_results\": original_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f0626-18ca-4594-9034-7805bcc00ddd",
   "metadata": {},
   "source": [
    "## 5: Define Function for Retrieve and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c3501-3e47-4c73-be9d-2af97a495039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate(query, kb_id, rerank_model_arn, use_reranking=True):\n",
    "    \"\"\"Full RAG pipeline with optional reranking\"\"\"\n",
    "    # 1. Search and get documents\n",
    "    results = search_kb_with_optional_rerank(\n",
    "        query, kb_id, rerank_model_arn, use_reranking\n",
    "    )\n",
    "    \n",
    "    # 2. Use the appropriate results\n",
    "    if use_reranking and \"reranked_results\" in results:\n",
    "        docs = [doc[\"text\"] for doc in results[\"reranked_results\"]]\n",
    "        source_type = \"reranked\"\n",
    "    else:\n",
    "        docs = [doc[\"text\"] for doc in results[\"original_results\"]]\n",
    "        source_type = \"vector search\"\n",
    "    \n",
    "    # 3. Generate answer with context from docs\n",
    "    context = \"\\n\\n\".join([f\"Document {i+1}: {doc[:300]}...\" for i, doc in enumerate(docs[:3])])\n",
    "    prompt = f\"Query: {query}\\n\\nContext from {source_type}:\\n{context}\\n\\nAnswer:\"\n",
    "    \n",
    "    # Call your LLM of choice (simplified here)\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=regionName)\n",
    "    response = client.invoke_model(\n",
    "        modelId=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "        body=json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 500,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "    return response_body[\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a97b19-c508-4861-862e-24c4e0d4a0fb",
   "metadata": {},
   "source": [
    "## 6: Compare the Retrieved results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d350c46-219d-449d-b475-197b218a9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"Compare the results between 2022 and 2023\"\n",
    "\n",
    "# Without reranking\n",
    "print(\"WITHOUT RERANKING:\")\n",
    "results_no_rerank = search_kb_with_optional_rerank(\n",
    "    query, knowledge_base_id, rerank_model_arn, use_reranking=False\n",
    ")\n",
    "\n",
    "# Display original results\n",
    "print(\"\\nTOP 3 DOCUMENTS WITHOUT RERANKING:\")\n",
    "for doc in results_no_rerank[\"original_results\"][:3]:\n",
    "    print(f\"Position {doc['position']} (Score: {doc['score']}):\")\n",
    "    print(f\"{doc['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa683f5-a4ce-424d-b4d3-100be0319c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With reranking\n",
    "print(\"\\nWITH RERANKING:\")\n",
    "results_with_rerank = search_kb_with_optional_rerank(\n",
    "    query, knowledge_base_id, rerank_model_arn, use_reranking=True\n",
    ")\n",
    "\n",
    "# Show reranked results with full precision scores\n",
    "print(\"\\nTOP 3 DOCUMENTS AFTER RERANKING:\")\n",
    "for doc in results_with_rerank[\"reranked_results\"][:3]:\n",
    "    print(f\"Moved from position {doc['original_position']} to {doc['new_position']}\")\n",
    "    print(f\"Relevance score: {doc['relevance_score']}\")  # Full precision\n",
    "    print(f\"{doc['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af57f6-502f-4765-9e67-1e060f793978",
   "metadata": {},
   "source": [
    "## 7: Compare the Generated results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d46554-9282-432c-b658-ed206c0c923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGENERATED ANSWER WITHOUT RERANKING:\")\n",
    "answer_no_rerank = retrieve_and_generate(query, knowledge_base_id, rerank_model_arn, use_reranking=False)\n",
    "print(answer_no_rerank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a82a24-0ee7-404e-bcd0-64b9c9d484ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGENERATED ANSWER WITH RERANKING:\")\n",
    "answer_with_rerank = retrieve_and_generate(query, knowledge_base_id, rerank_model_arn, use_reranking=True)\n",
    "print(answer_with_rerank)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
