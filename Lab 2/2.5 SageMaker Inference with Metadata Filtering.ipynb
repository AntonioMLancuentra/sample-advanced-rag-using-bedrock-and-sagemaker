{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e83cb40-0f1d-4915-8e54-48c78541d349",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with SageMaker Inference and Metadata Filtering  \n",
    "\n",
    "### Description:  \n",
    "This notebook showcases how to query and retrieve information from an Amazon Bedrock-powered knowledge base while leveraging SageMaker inference and metadata filtering. It covers key steps such as configuring queries, applying metadata filters, retrieving responses, and extracting citations used in the generated results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26505f4f-b74b-4e64-a63e-88fc6e71ee98",
   "metadata": {},
   "source": [
    "## 1. Load Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195aec4-6d01-4e2f-b5a8-134b20650ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration variables from a JSON file to access knowledge base ID, account number, and guardrail info.\n",
    "import json\n",
    "\n",
    "with open(\"../Lab 1/variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables  # Display the loaded variables for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d89542-cd78-4099-afcf-bcb0e29bec4e",
   "metadata": {},
   "source": [
    "## 2. Set Up Required IDs and Model ARNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8cbc3-56ae-4aae-9a4f-b19c04693574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Selection  \n",
    "kb_id = variables[\"kbFixedChunk\"]  # Options: \"kbFixedChunk\", \"kbHierarchicalChunk\", \"kbSemanticChunk\"\n",
    "\n",
    "# Retrieval-Augmented Generation (RAG) Configuration  \n",
    "number_of_results = 3  # Number of relevant documents to retrieve  \n",
    "generation_configuration = {\n",
    "    \"temperature\": 0,  # Lower temperature for more deterministic responses  \n",
    "    \"top_k\": 10,  # Consider top 10 tokens at each generation step  \n",
    "    \"max_new_tokens\": 5000,  # Maximum number of tokens to generate  \n",
    "    \"stop\": \"<|eot_id|>\"  # Stop sequence to end the response generation  \n",
    "}\n",
    "\n",
    "# User Query\n",
    "query = \"what was the % increase in sales?\"  # Sample query to retrieve data from the knowledge base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8eb99-8dbf-4c1b-a6a5-a7ad9a559177",
   "metadata": {},
   "source": [
    "## 3. Define Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e43968-c317-4571-afd7-41abe8ee7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a metadata filter for advanced filtering based on specific conditions\n",
    "one_group_filter= {\n",
    "    \"andAll\": [\n",
    "        {\n",
    "            \"equals\": {\n",
    "                \"key\": \"docType\",\n",
    "                \"value\": '10K Report'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"equals\": {\n",
    "                \"key\": \"year\",\n",
    "                \"value\": 2023\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccdb8b-226d-47f8-be02-f8059e6d482a",
   "metadata": {},
   "source": [
    "## 4. Define SageMaker & Bedrock helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4a1ea-6575-4a85-9b60-1c5f1524d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize Bedrock client to interact with the Bedrock Knowledge Base\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Constants for Knowledge Base ID, SageMaker endpoint, and number of results to retrieve\n",
    "KNOWLEDGE_BASE_ID = kb_id\n",
    "ENDPOINT_NAME = variables['sagemakerLLMEndpoint']\n",
    "NUM_RESULTS = number_of_results\n",
    "\n",
    "# Function to retrieve relevant context from the Bedrock Knowledge Base\n",
    "def retrieve_from_bedrock(query):\n",
    "    \"\"\"Retrieve relevant context from Bedrock Knowledge Base\"\"\"\n",
    "    try:\n",
    "        # Retrieve context based on the query using vector search configuration\n",
    "        response = bedrock_agent_runtime.retrieve(\n",
    "            knowledgeBaseId=KNOWLEDGE_BASE_ID,\n",
    "            retrievalQuery={\n",
    "                'text': query  # The query text to search in the knowledge base\n",
    "            },\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': NUM_RESULTS,  # Adjust based on needs\n",
    "                     \"filter\": one_group_filter\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        # Extract the 'text' from the retrieval results and return as a list\n",
    "        return [result['content']['text'] for result in response['retrievalResults']]\n",
    "    except Exception as e:\n",
    "        # Raise an error if the retrieval process fails\n",
    "        raise RuntimeError(f\"Bedrock retrieval failed: {str(e)}\")\n",
    "\n",
    "# Function to format the prompt for Llama 3 model using retrieved context\n",
    "def format_prompt(query, context):\n",
    "    \"\"\"Format prompt for Llama 3\"\"\"\n",
    "    # Create the system prompt that includes the context and the user's question\n",
    "    system_prompt = f\"\"\"Use the following context to answer the question. If you don't know the answer, say 'I don't know'.\n",
    "        Context:\n",
    "        {\" \".join(context)}\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Format the complete prompt including system and user instructions\n",
    "    return f\"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        {system_prompt}\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        Question: {query}\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\".strip()\n",
    "\n",
    "# Function to generate a response from the SageMaker endpoint based on the formatted prompt\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Generate response using SageMaker endpoint\"\"\"\n",
    "    # Initialize SageMaker runtime client\n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    \n",
    "    # Prepare the payload with prompt and generation parameters\n",
    "    payload = {\n",
    "        \"inputs\": prompt,  # The formatted prompt to pass to the model\n",
    "        \"parameters\": generation_configuration  # Additional parameters for the model (e.g., temperature, tokens)\n",
    "    }\n",
    "    try:\n",
    "        # Call the SageMaker endpoint to generate the response\n",
    "        response = runtime.invoke_endpoint(\n",
    "            EndpointName=ENDPOINT_NAME,  # SageMaker endpoint name\n",
    "            ContentType='application/json',  # Content type for the request\n",
    "            Body=json.dumps(payload)  # Send the payload as JSON\n",
    "        )\n",
    "\n",
    "        # Parse the response body\n",
    "        result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "        \n",
    "        # Handle different response formats (list or dictionary)\n",
    "        if isinstance(result, list):\n",
    "            # If the result is a list, extract the generated text from the first element\n",
    "            return result[0]['generated_text']\n",
    "        elif 'generated_text' in result:\n",
    "            # If the result is a dictionary with 'generated_text', return the generated text\n",
    "            return result['generated_text']\n",
    "        elif 'generation' in result:\n",
    "            # Alternative format with 'generation' key\n",
    "            return result['generation']\n",
    "        else:\n",
    "            # Raise an error if the response format is unexpected\n",
    "            raise RuntimeError(\"Unexpected response format\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Raise an error if the generation process fails\n",
    "        raise RuntimeError(f\"Generation failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a335d-e615-4885-823b-151d8a94c173",
   "metadata": {},
   "source": [
    "## 5. Generate Response with Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60755c-9a5e-4d9a-998e-0006f79eae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant context from the Bedrock Knowledge Base based on the query\n",
    "context = retrieve_from_bedrock(query)\n",
    "\n",
    "# Format the prompt by combining the user's query and the retrieved context\n",
    "prompt = format_prompt(query, context)\n",
    "\n",
    "# Generate the response using the formatted prompt by calling the SageMaker endpoint\n",
    "response = generate_response(prompt)\n",
    "\n",
    "# Print the user's query\n",
    "print(\"Question:\", {query})\n",
    "\n",
    "# Uncomment below line if you want to debug and see the retrieved context\n",
    "# print(f\"Context: {context}\")\n",
    "\n",
    "# Print the generated answer from the model based on the query and context\n",
    "print(\"Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68179733",
   "metadata": {},
   "source": [
    "## 6. Dynamic Metadata filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d12734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_filter(company=None, year=None, docType=None, min_page=None, max_page=None, s3_prefix=None):\n",
    "    \"\"\"\n",
    "    Creates a dynamic metadata filter for Amazon Bedrock Knowledge Base queries.\n",
    "    \n",
    "    Parameters:\n",
    "    - company (str): Filter by company name (e.g., 'Amazon')\n",
    "    - year (int or list): Filter by year or list of years\n",
    "    - docType (str): Filter by document type (e.g., '10K Report')\n",
    "    - min_page (int): Filter for pages greater than or equal to this number\n",
    "    - max_page (int): Filter for pages less than or equal to this number\n",
    "    - segment (str): Filter by business segment (e.g., 'AWS', 'North America', 'International','RISK')\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A metadata filter configuration\n",
    "    \"\"\"\n",
    "    filter_conditions = []\n",
    "    \n",
    "    # Add company filter if specified\n",
    "    if company:\n",
    "        filter_conditions.append({\n",
    "            \"equals\": {\n",
    "                \"key\": \"company\",\n",
    "                \"value\": company\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add year filter (single year or multiple years)\n",
    "    if year:\n",
    "        if isinstance(year, list):\n",
    "            year_conditions = []\n",
    "            for y in year:\n",
    "                year_conditions.append({\n",
    "                    \"equals\": {\n",
    "                        \"key\": \"year\",\n",
    "                        \"value\": y\n",
    "                    }\n",
    "                })\n",
    "            filter_conditions.append({\"orAll\": year_conditions})\n",
    "        else:\n",
    "            filter_conditions.append({\n",
    "                \"equals\": {\n",
    "                    \"key\": \"year\",\n",
    "                    \"value\": year\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Add document type filter if specified\n",
    "    if docType:\n",
    "        filter_conditions.append({\n",
    "            \"equals\": {\n",
    "                \"key\": \"docType\",\n",
    "                \"value\": docType\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add minimum page filter if specified\n",
    "    if min_page is not None:\n",
    "        filter_conditions.append({\n",
    "            \"greaterThanOrEquals\": {\n",
    "                \"key\": \"x-amz-bedrock-kb-document-page-number\",\n",
    "                \"value\": min_page\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add maximum page filter if specified\n",
    "    if max_page is not None:\n",
    "        filter_conditions.append({\n",
    "            \"lessThanOrEquals\": {\n",
    "                \"key\": \"x-amz-bedrock-kb-document-page-number\",\n",
    "                \"value\": max_page\n",
    "            }\n",
    "        })\n",
    "\n",
    "    if s3_prefix:\n",
    "        filter_conditions.append({\n",
    "            \"startsWith\": {\n",
    "                \"key\": \"x-amz-bedrock-kb-source-uri\",\n",
    "                \"value\": s3_prefix\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Return the complete filter\n",
    "    if len(filter_conditions) > 0:\n",
    "        return {\"andAll\": filter_conditions}\n",
    "    else:\n",
    "        return {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
