{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f684c8-b863-4dc7-86b5-2d6632d3d7df",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with SageMaker Inference and Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fef89-4586-4c15-a088-9b491fb7329b",
   "metadata": {},
   "source": [
    "## 1: Import and Load Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f2da5-8c58-4826-a216-fcd1c1c5cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the configuration variables from a JSON file\n",
    "with open(\"../Lab 1/variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c726e87-7ada-412e-9d61-60dd3a0066c8",
   "metadata": {},
   "source": [
    "## 2: Define ARN and Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec1a90-e111-4077-a35b-26d620aaa7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Selection  \n",
    "kb_id = variables[\"kbFixedChunk\"]  # Options: \"kbFixedChunk\", \"kbHierarchicalChunk\", \"kbSemanticChunk\"\n",
    "\n",
    "# Retrieval-Augmented Generation (RAG) Configuration  \n",
    "number_of_results = 3  # Number of relevant documents to retrieve  \n",
    "generation_configuration = {\n",
    "    \"temperature\": 0,  # Lower temperature for more deterministic responses  \n",
    "    \"top_k\": 10,  # Consider top 10 tokens at each generation step  \n",
    "    \"max_new_tokens\": 5000,  # Maximum number of tokens to generate  \n",
    "    \"stop\": \"<|eot_id|>\"  # Stop sequence to end the response generation  \n",
    "}\n",
    "\n",
    "# Define ARNs (Amazon Resource Names) for the model\n",
    "rerank_model_arn=f\"arn:aws:bedrock:us-west-2::foundation-model/cohere.rerank-v3-5:0\"\n",
    "\n",
    "# User Query\n",
    "query = \"what was the % increase in sales?\"  # Sample query to retrieve data from the knowledge base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a73e5-d254-4acc-9f88-78e1b2a0bd69",
   "metadata": {},
   "source": [
    "## 3: Set Up Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6293a-1467-436d-962b-743f9f6d8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "# Configure the Bedrock client\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=\"us-west-2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551de863-30ea-4831-860e-37ab4db0913d",
   "metadata": {},
   "source": [
    "## 4: Define Function for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cfc15-626b-4d02-b95a-ed87d975a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize Bedrock client to interact with the Bedrock Knowledge Base\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=variables[\"regionName\"])\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Constants for Knowledge Base ID, SageMaker endpoint, and number of results to retrieve\n",
    "KNOWLEDGE_BASE_ID = kb_id\n",
    "ENDPOINT_NAME = variables['sagemakerLLMEndpoint']\n",
    "NUM_RESULTS = number_of_results\n",
    "\n",
    "def search_knowledge_base(query, region_name, kb_id, num_results=5, use_reranking=False, model_arn=None):\n",
    "    \"\"\"\n",
    "    Search Bedrock Knowledge Base and optionally rerank results.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): Search query text\n",
    "        region_name (str): AWS region name (e.g. \"us-east-1\")\n",
    "        kb_id (str): Knowledge Base ID\n",
    "        num_results (int): Maximum number of results to return\n",
    "        use_reranking (bool): Whether to rerank results for better relevance\n",
    "        model_arn (str): Model ARN for reranking (required if use_reranking=True)\n",
    "    \n",
    "    Returns:\n",
    "        list: Retrieved document texts\n",
    "    \"\"\"\n",
    "    # Create client for Bedrock\n",
    "    client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "    \n",
    "    # Step 1: Search the knowledge base\n",
    "    try:\n",
    "        # Call the retrieve API\n",
    "        response = client.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={\"text\": query},\n",
    "            retrievalConfiguration={\n",
    "                \"vectorSearchConfiguration\": {\"numberOfResults\": num_results}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Get document texts from results\n",
    "        documents = [result['content']['text'] for result in response['retrievalResults']]\n",
    "        print(f\"Found {len(documents)} documents\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Step 2: Rerank results if requested\n",
    "    if use_reranking and model_arn and documents:\n",
    "        try:\n",
    "            # Format documents for reranking API\n",
    "            sources = [\n",
    "                {\n",
    "                    \"inlineDocumentSource\": {\"textDocument\": {\"text\": doc}, \"type\": \"TEXT\"},\n",
    "                    \"type\": \"INLINE\"\n",
    "                } \n",
    "                for doc in documents\n",
    "            ]\n",
    "            \n",
    "            # Call rerank API\n",
    "            rerank_response = client.rerank(\n",
    "                queries=[{\"textQuery\": {\"text\": query}, \"type\": \"TEXT\"}],\n",
    "                rerankingConfiguration={\n",
    "                    \"bedrockRerankingConfiguration\": {\n",
    "                        \"modelConfiguration\": {\"modelArn\": model_arn},\n",
    "                        \"numberOfResults\": num_results\n",
    "                    },\n",
    "                    \"type\": \"BEDROCK_RERANKING_MODEL\"\n",
    "                },\n",
    "                sources=sources\n",
    "            )\n",
    "            \n",
    "            # Get reordered documents\n",
    "            reranked_docs = []\n",
    "            for result in rerank_response.get(\"results\", []):\n",
    "                idx = result.get(\"index\", 0)\n",
    "                if 0 <= idx < len(documents):\n",
    "                    reranked_docs.append(documents[idx])\n",
    "            \n",
    "            print(f\"Reranked results: {len(reranked_docs)} documents\")\n",
    "            return reranked_docs\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Reranking failed: {e}\")\n",
    "            print(\"Using original search results instead\")\n",
    "    \n",
    "    # Return the documents\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f161f-582e-4a18-8203-a8c02b61139e",
   "metadata": {},
   "source": [
    "## 5. Define SageMaker & Bedrock helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfb585-3169-4622-9dac-97e730cae767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format the prompt for Llama 3 model using retrieved context\n",
    "def format_prompt(query, context):\n",
    "    \"\"\"Format prompt for Llama 3\"\"\"\n",
    "    # Create the system prompt that includes the context and the user's question\n",
    "    system_prompt = f\"\"\"Use the following context to answer the question. If you don't know the answer, say 'I don't know'.\n",
    "        Context:\n",
    "        {\" \".join(context)}\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Format the complete prompt including system and user instructions\n",
    "    return f\"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        {system_prompt}\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        Question: {query}\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\".strip()\n",
    "\n",
    "# Function to generate a response from the SageMaker endpoint based on the formatted prompt\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Generate response using SageMaker endpoint\"\"\"\n",
    "    # Initialize SageMaker runtime client\n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    \n",
    "    # Prepare the payload with prompt and generation parameters\n",
    "    payload = {\n",
    "        \"inputs\": prompt,  # The formatted prompt to pass to the model\n",
    "        \"parameters\": generation_configuration  # Additional parameters for the model (e.g., temperature, tokens)\n",
    "    }\n",
    "    try:\n",
    "        # Call the SageMaker endpoint to generate the response\n",
    "        response = runtime.invoke_endpoint(\n",
    "            EndpointName=ENDPOINT_NAME,  # SageMaker endpoint name\n",
    "            ContentType='application/json',  # Content type for the request\n",
    "            Body=json.dumps(payload)  # Send the payload as JSON\n",
    "        )\n",
    "\n",
    "        # Parse the response body\n",
    "        result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "        \n",
    "        # Handle different response formats (list or dictionary)\n",
    "        if isinstance(result, list):\n",
    "            # If the result is a list, extract the generated text from the first element\n",
    "            return result[0]['generated_text']\n",
    "        elif 'generated_text' in result:\n",
    "            # If the result is a dictionary with 'generated_text', return the generated text\n",
    "            return result['generated_text']\n",
    "        elif 'generation' in result:\n",
    "            # Alternative format with 'generation' key\n",
    "            return result['generation']\n",
    "        else:\n",
    "            # Raise an error if the response format is unexpected\n",
    "            raise RuntimeError(\"Unexpected response format\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Raise an error if the generation process fails\n",
    "        raise RuntimeError(f\"Generation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401c9d7-7208-4dc3-8ee7-54286ddd4fc0",
   "metadata": {},
   "source": [
    "## 6: Compare the Retrieved results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a79c9-544f-4c7f-8dd7-a4010aee605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"Compare the results between 2022 and 2023\"\n",
    "\n",
    "print(\"WITHOUT RERANKING:\")\n",
    "# Retrieve relevant context without reranking\n",
    "context_without_reranking = search_kb_with_optional_rerank(query, use_reranking=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4a196-fd0a-4403-8623-ad51e8518df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nWITH RERANKING:\")\n",
    "# Retrieve relevant context with reranking\n",
    "context_with_reranking = search_kb_with_optional_rerank(\n",
    "    query=query, \n",
    "    model_arn=rerank_model_arn, \n",
    "    use_reranking=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba6463-ed89-4d6a-9352-d4a88eccc4f0",
   "metadata": {},
   "source": [
    "## 7: Compare the Generated results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209784f-cb9d-4519-bda0-243f78fa5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WITHOUT RERANKING:\")\n",
    "\n",
    "# Format the prompt by combining the user's query and the retrieved context\n",
    "prompt_without_reranking = format_prompt(query, context_without_reranking)\n",
    "\n",
    "# Generate the response using the formatted prompt by calling the SageMaker endpoint\n",
    "response_without_reranking = generate_response(prompt_without_reranking)\n",
    "\n",
    "# Print the user's query and answer\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", response_without_reranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73a394-e973-4d5a-b1d8-933534be7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WITH RERANKING:\")\n",
    "\n",
    "# Format the prompt by combining the user's query and the retrieved context\n",
    "prompt_with_reranking = format_prompt(query, context_with_reranking)\n",
    "\n",
    "# Generate the response using the formatted prompt by calling the SageMaker endpoint\n",
    "response_with_reranking = generate_response(prompt_with_reranking)\n",
    "\n",
    "# Print the user's query and answer\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", response_with_reranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f56a7-cc15-4db4-b75a-12ae6612d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
