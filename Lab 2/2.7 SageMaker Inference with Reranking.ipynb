{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f684c8-b863-4dc7-86b5-2d6632d3d7df",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with SageMaker Inference and Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fef89-4586-4c15-a088-9b491fb7329b",
   "metadata": {},
   "source": [
    "## 1: Import and Load Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f2da5-8c58-4826-a216-fcd1c1c5cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the configuration variables from a JSON file\n",
    "with open(\"../Lab 1/variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c726e87-7ada-412e-9d61-60dd3a0066c8",
   "metadata": {},
   "source": [
    "## 2: Define ARN and Configuration Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec1a90-e111-4077-a35b-26d620aaa7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Selection  \n",
    "kb_id = variables[\"kbFixedChunk\"]  # Options: \"kbFixedChunk\", \"kbHierarchicalChunk\", \"kbSemanticChunk\"\n",
    "\n",
    "# Retrieval-Augmented Generation (RAG) Configuration  \n",
    "number_of_results = 3  # Number of relevant documents to retrieve  \n",
    "generation_configuration = {\n",
    "    \"temperature\": 0,  # Lower temperature for more deterministic responses  \n",
    "    \"top_k\": 10,  # Consider top 10 tokens at each generation step  \n",
    "    \"max_new_tokens\": 5000,  # Maximum number of tokens to generate  \n",
    "    \"stop\": \"<|eot_id|>\"  # Stop sequence to end the response generation  \n",
    "}\n",
    "\n",
    "# Define ARNs (Amazon Resource Names) for the model\n",
    "rerank_model_arn=f\"arn:aws:bedrock:us-west-2::foundation-model/cohere.rerank-v3-5:0\"\n",
    "\n",
    "# User Query\n",
    "query = \"what was the % increase in sales?\"  # Sample query to retrieve data from the knowledge base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a73e5-d254-4acc-9f88-78e1b2a0bd69",
   "metadata": {},
   "source": [
    "## 3: Set Up Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6293a-1467-436d-962b-743f9f6d8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "# Configure the Bedrock client\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=\"us-west-2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551de863-30ea-4831-860e-37ab4db0913d",
   "metadata": {},
   "source": [
    "## 4: Define Function for Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cfc15-626b-4d02-b95a-ed87d975a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize Bedrock client to interact with the Bedrock Knowledge Base\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=variables[\"regionName\"])\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Constants for Knowledge Base ID, SageMaker endpoint, and number of results to retrieve\n",
    "KNOWLEDGE_BASE_ID = kb_id\n",
    "ENDPOINT_NAME = variables['sagemakerLLMEndpoint']\n",
    "NUM_RESULTS = number_of_results\n",
    "\n",
    "def search_knowledge_base(query, region_name, kb_id, num_results=5, use_reranking=False, model_arn=None):\n",
    "    \"\"\"\n",
    "    Search Bedrock Knowledge Base and optionally rerank results.\n",
    "    Returns document texts and displays detailed metadata.\n",
    "    \"\"\"\n",
    "    client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "    \n",
    "    # 1. Retrieve from knowledge base\n",
    "    try:\n",
    "        kb_response = client.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={\"text\": query},\n",
    "            retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": num_results}}\n",
    "        )\n",
    "        \n",
    "        # Extract documents and metadata\n",
    "        documents = []\n",
    "        original_results = []\n",
    "        \n",
    "        for i, result in enumerate(kb_response.get(\"retrievalResults\", [])):\n",
    "            # Extract text from result\n",
    "            text = \"\"\n",
    "            if \"content\" in result and \"text\" in result[\"content\"]:\n",
    "                content_text = result[\"content\"][\"text\"]\n",
    "                if isinstance(content_text, list):\n",
    "                    text = \" \".join([item.get(\"span\", \"\") if isinstance(item, dict) else str(item) \n",
    "                                  for item in content_text])\n",
    "                else:\n",
    "                    text = str(content_text)\n",
    "                \n",
    "            # Store original result with metadata\n",
    "            original_results.append({\n",
    "                \"position\": i + 1,\n",
    "                \"score\": result.get(\"scoreValue\", 0),\n",
    "                \"text\": text[:300] + \"...\" if len(text) > 300 else text\n",
    "            })\n",
    "            documents.append(text)\n",
    "        \n",
    "        # Display original results\n",
    "        print(\"\\nTOP 3 DOCUMENTS WITHOUT RERANKING:\")\n",
    "        for doc in original_results[:min(3, len(original_results))]:\n",
    "            print(f\"Position {doc['position']} (Score: {doc['score']}):\")\n",
    "            print(f\"{doc['text']}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # 2. Rerank if enabled\n",
    "    if use_reranking and model_arn and documents:\n",
    "        try:\n",
    "            reranked = client.rerank(\n",
    "                queries=[{\"textQuery\": {\"text\": query}, \"type\": \"TEXT\"}],\n",
    "                rerankingConfiguration={\n",
    "                    \"bedrockRerankingConfiguration\": {\n",
    "                        \"modelConfiguration\": {\"modelArn\": model_arn},\n",
    "                        \"numberOfResults\": num_results\n",
    "                    },\n",
    "                    \"type\": \"BEDROCK_RERANKING_MODEL\"\n",
    "                },\n",
    "                sources=[{\n",
    "                    \"inlineDocumentSource\": {\"textDocument\": {\"text\": doc}, \"type\": \"TEXT\"},\n",
    "                    \"type\": \"INLINE\"\n",
    "                } for doc in documents]\n",
    "            )\n",
    "            \n",
    "            # Process reranked results\n",
    "            reranked_results = []\n",
    "            reranked_documents = []\n",
    "            \n",
    "            for new_pos, result in enumerate(reranked.get(\"results\", [])):\n",
    "                idx = result.get(\"index\", 0)\n",
    "                if 0 <= idx < len(documents):\n",
    "                    reranked_results.append({\n",
    "                        \"original_position\": idx + 1,\n",
    "                        \"new_position\": new_pos + 1,\n",
    "                        \"relevance_score\": result.get(\"relevanceScore\", 0),\n",
    "                        \"text\": documents[idx][:300] + \"...\" if len(documents[idx]) > 300 else documents[idx]\n",
    "                    })\n",
    "                    reranked_documents.append(documents[idx])\n",
    "            \n",
    "            # Display reranked results\n",
    "            print(\"\\nTOP 3 DOCUMENTS AFTER RERANKING:\")\n",
    "            for doc in reranked_results[:min(3, len(reranked_results))]:\n",
    "                print(f\"Moved from position {doc['original_position']} to {doc['new_position']}\")\n",
    "                print(f\"Relevance score: {doc['relevance_score']}\")\n",
    "                print(f\"{doc['text']}\\n\")\n",
    "            \n",
    "            return reranked_documents\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Reranking failed: {e}\")\n",
    "            print(\"Using original search results instead\")\n",
    "    \n",
    "    # Return document texts for format_prompt\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f161f-582e-4a18-8203-a8c02b61139e",
   "metadata": {},
   "source": [
    "## 5. Define SageMaker & Bedrock helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfb585-3169-4622-9dac-97e730cae767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format the prompt for Llama 3 model using retrieved context\n",
    "def format_prompt(query, context):\n",
    "    \"\"\"Format prompt for Llama 3\"\"\"\n",
    "    # Create the system prompt that includes the context and the user's question\n",
    "    system_prompt = f\"\"\"Use the following context to answer the question. If you don't know the answer, say 'I don't know'.\n",
    "        Context:\n",
    "        {\" \".join(context)}\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Format the complete prompt including system and user instructions\n",
    "    return f\"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        {system_prompt}\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        Question: {query}\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\".strip()\n",
    "\n",
    "# Function to generate a response from the SageMaker endpoint based on the formatted prompt\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Generate response using SageMaker endpoint\"\"\"\n",
    "    # Initialize SageMaker runtime client\n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    \n",
    "    # Prepare the payload with prompt and generation parameters\n",
    "    payload = {\n",
    "        \"inputs\": prompt,  # The formatted prompt to pass to the model\n",
    "        \"parameters\": generation_configuration  # Additional parameters for the model (e.g., temperature, tokens)\n",
    "    }\n",
    "    try:\n",
    "        # Call the SageMaker endpoint to generate the response\n",
    "        response = runtime.invoke_endpoint(\n",
    "            EndpointName=ENDPOINT_NAME,  # SageMaker endpoint name\n",
    "            ContentType='application/json',  # Content type for the request\n",
    "            Body=json.dumps(payload)  # Send the payload as JSON\n",
    "        )\n",
    "\n",
    "        # Parse the response body\n",
    "        result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "        \n",
    "        # Handle different response formats (list or dictionary)\n",
    "        if isinstance(result, list):\n",
    "            # If the result is a list, extract the generated text from the first element\n",
    "            return result[0]['generated_text']\n",
    "        elif 'generated_text' in result:\n",
    "            # If the result is a dictionary with 'generated_text', return the generated text\n",
    "            return result['generated_text']\n",
    "        elif 'generation' in result:\n",
    "            # Alternative format with 'generation' key\n",
    "            return result['generation']\n",
    "        else:\n",
    "            # Raise an error if the response format is unexpected\n",
    "            raise RuntimeError(\"Unexpected response format\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Raise an error if the generation process fails\n",
    "        raise RuntimeError(f\"Generation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401c9d7-7208-4dc3-8ee7-54286ddd4fc0",
   "metadata": {},
   "source": [
    "## 6: Compare the Retrieved results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580c3a5-566b-42a3-a1f9-ca0f08f75097",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Compare the results between 2022 and 2023\"\n",
    "\n",
    "print(\"WITHOUT RERANKING:\")\n",
    "context_without_reranking = search_knowledge_base(\n",
    "    query=query,\n",
    "    region_name=variables[\"regionName\"],\n",
    "    kb_id=variables[\"kbFixedChunk\"],\n",
    "    num_results=number_of_results,\n",
    "    use_reranking=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf8472-12e4-4628-a4fd-7ec6184768ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nWITH RERANKING:\")\n",
    "context_with_reranking = search_knowledge_base(\n",
    "    query=query,\n",
    "    region_name=variables[\"regionName\"],\n",
    "    kb_id=variables[\"kbFixedChunk\"],\n",
    "    num_results=number_of_results,\n",
    "    use_reranking=True,\n",
    "    model_arn=rerank_model_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba6463-ed89-4d6a-9352-d4a88eccc4f0",
   "metadata": {},
   "source": [
    "## 7: Compare the Generated results WITH & WITHOUT Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209784f-cb9d-4519-bda0-243f78fa5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WITHOUT RERANKING:\")\n",
    "\n",
    "# Format the prompt by combining the user's query and the retrieved context\n",
    "prompt_without_reranking = format_prompt(query, context_without_reranking)\n",
    "\n",
    "# Generate the response using the formatted prompt\n",
    "response_without_reranking = generate_response(prompt_without_reranking)\n",
    "\n",
    "# Print the user's query and answer\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", response_without_reranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73a394-e973-4d5a-b1d8-933534be7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WITH RERANKING:\")\n",
    "\n",
    "# Format the prompt by combining the user's query and the retrieved context\n",
    "prompt_with_reranking = format_prompt(query, context_with_reranking)\n",
    "\n",
    "# Generate the response using the formatted prompt\n",
    "response_with_reranking = generate_response(prompt_with_reranking)\n",
    "\n",
    "# Print the user's query and answer\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", response_with_reranking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
