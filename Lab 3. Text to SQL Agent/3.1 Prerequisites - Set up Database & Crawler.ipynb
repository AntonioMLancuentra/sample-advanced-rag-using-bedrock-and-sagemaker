{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2c30fe-9e6d-45e1-82c9-cc3ad4bf4248",
   "metadata": {},
   "source": [
    "### Setup Amazon Athena Database & AWS Glue Crawler\n",
    "\n",
    "### Description:  \n",
    "This notebook automates the setup of Amazon Athena database and AWS Glue crawler. \n",
    "\n",
    "It creates Amazon Athena database, configures an S3 bucket as the data source, and sets up an AWS Glue crawler to catalog the data. Once the crawler runs, it populates the AWS Glue Data Catalog with table metadata, enabling seamless querying of data using Athena. \n",
    "\n",
    "This setup is essential for performing serverless SQL queries on structured and semi-structured data stored in Amazon S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759867e",
   "metadata": {},
   "source": [
    "![Text to SQL](./glue.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a244538-0d27-43fe-a9e8-3e1754bea9d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad8676-d77f-42b6-9959-081446a2dc1d",
   "metadata": {},
   "source": [
    "# Uploading File to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176ecf5-f4a6-4416-ba78-1c1877ebafd2",
   "metadata": {},
   "source": [
    "For this lab, we will use sample data files provided in [AWS Big Data Blog](https://aws.amazon.com/blogs/big-data/joining-across-data-sources-on-amazon-quicksight/). The data consists of two tables - Order and Returns. The tables are joined by a common key - Order Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d33a5-1d18-45b6-9208-00dc209a5b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A helper functino to upload CSV files from Excel files.\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "def excel_to_csv(source_bucket, source_key, target_bucket, target_prefix):\n",
    "    \"\"\"\n",
    "    Convert Excel file from S3 to CSV and save back to S3.\n",
    "    \n",
    "    Args:\n",
    "        source_bucket (str): Source S3 bucket name\n",
    "        source_key (str): Source file key (path to xlsx file)\n",
    "        target_bucket (str): Target S3 bucket name\n",
    "        target_prefix (str): Target prefix (folder) for CSV files\n",
    "    \"\"\"\n",
    "    # Initialize S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    # Read the Excel file from S3\n",
    "    response = s3_client.get_object(Bucket=source_bucket, Key=source_key)\n",
    "\n",
    "    excel_data = response['Body'].read()\n",
    "\n",
    "    # Load Excel file into pandas\n",
    "    excel_file = pd.ExcelFile(BytesIO(excel_data))\n",
    "\n",
    "    # Process each sheet\n",
    "    for sheet_name in excel_file.sheet_names:\n",
    "        # Read the sheet into a DataFrame\n",
    "        df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "        df.columns = df.columns.str.replace(' ', '_')\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df.columns = df.columns.str.lower()\n",
    "        print(df.head(10))\n",
    "\n",
    "        # Generate target key for the CSV file\n",
    "        target_key = f\"{target_prefix}/{sheet_name}.csv\"\n",
    "        df.to_csv(f\"s3://{target_bucket}/{target_key}\", index=True,\n",
    "                  index_label=f\"{sheet_name}_index\")\n",
    "\n",
    "        print(f\"Successfully converted sheet '{sheet_name}' to CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bda6b1-f961-4b04-9650-22f8974c9404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "order_table_s3_key = \"artifacts/aws-blog-joining-across-quicksight/orders.xlsx\"\n",
    "returns_table_s3_key = \"artifacts/aws-blog-joining-across-quicksight/returns.xlsx\"\n",
    "source_bucket_name = \"aws-bigdata-blog\"\n",
    "target_bucket_name = variables['s3Bucket']  # The name of your S3 bucket\n",
    "\n",
    "excel_to_csv(source_bucket_name, order_table_s3_key, target_bucket_name, \"transactions/order\")\n",
    "excel_to_csv(source_bucket_name, returns_table_s3_key, target_bucket_name, \"transactions/returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8efd2-eb99-4db4-8ff0-d386adbd8458",
   "metadata": {},
   "source": [
    "# IAM Role Creation and Policy Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b5b63-d8fb-44f3-b4c6-81121f7dcfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "def create_iam_role(role_name: str):\n",
    "    iam_client = boto3.client('iam')\n",
    "    \n",
    "    try:\n",
    "        # Check if the role already exists\n",
    "        response = iam_client.get_role(RoleName=role_name)\n",
    "        print(f\"Role {role_name} already exists.\")\n",
    "        return response\n",
    "    except iam_client.exceptions.NoSuchEntityException:\n",
    "        # Trust policy for Glue service to assume the role\n",
    "        trust_policy = {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Principal\": {\n",
    "                        \"Service\": \"glue.amazonaws.com\"\n",
    "                    },\n",
    "                    \"Action\": \"sts:AssumeRole\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Create the IAM role\n",
    "        response = iam_client.create_role(\n",
    "            RoleName=role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "            Description=\"IAM Role for AWS Glue to access S3 and Athena\"\n",
    "        )\n",
    "        print(f\"Role {role_name} created successfully.\")\n",
    "        \n",
    "        # Wait for role to propagate through AWS systems\n",
    "        print(\"Waiting for role to propagate...\")\n",
    "        time.sleep(10)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243db03e-86b7-4bd9-ab91-2919f611429a",
   "metadata": {},
   "source": [
    "# Attaching Inline Policy to IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037ff69-6dca-4468-a88b-6616ef03fe21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attach_inline_policy_to_role(role_name: str, athena_db_name: str, path_to_the_folder: str, s3_bucket: str):\n",
    "    iam_client = boto3.client('iam')\n",
    "    region = boto3.session.Session().region_name\n",
    "    account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "    inline_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"glue:GetTable\",\n",
    "                    \"glue:GetTableVersion\",\n",
    "                    \"glue:GetTableVersions\",\n",
    "                    \"glue:GetDatabase\",\n",
    "                    \"glue:CreateTable\",\n",
    "                    \"glue:UpdateTable\",\n",
    "                    \"glue:DeleteTable\",\n",
    "                    \"glue:GetCrawler\",\n",
    "                    \"glue:StartCrawler\",\n",
    "                    \"glue:GetCrawlerMetrics\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:glue:region:{variables['accountNumber']}:catalog\",\n",
    "                    f\"arn:aws:glue:region:{variables['accountNumber']}:database/{athena_db_name}\",\n",
    "                    f\"arn:aws:glue:region:{variables['accountNumber']}:table/{athena_db_name}/*\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:ListBucket\",\n",
    "                    \"s3:GetObject\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:s3:::{variables['s3Bucket']}/{path_to_the_folder}/*\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"athena:StartQueryExecution\",\n",
    "                    \"athena:GetQueryResults\",\n",
    "                    \"athena:GetQueryExecution\"\n",
    "                ],\n",
    "                \"Resource\": f\"arn:aws:athena:region:{variables['accountNumber']}:workgroup/primary\"\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"logs:CreateLogGroup\",\n",
    "                    \"logs:CreateLogStream\",\n",
    "                    \"logs:PutLogEvents\"\n",
    "                ],\n",
    "                \"Resource\": f\"arn:aws:logs:region:{variables['accountNumber']}:log-group:/aws/glue/*\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Attach the inline policy to the role\n",
    "    try:\n",
    "        iam_client.put_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyName='GlueCrawlerPolicy',\n",
    "            PolicyDocument=json.dumps(inline_policy)\n",
    "        )\n",
    "        print(f\"Inline policy attached to role {role_name} successfully.\")\n",
    "        \n",
    "        # Also attach AWS managed policy for Glue\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole'\n",
    "        )\n",
    "        print(\"Attached AWSGlueServiceRole managed policy\")\n",
    "        \n",
    "        # Wait for policy to propagate\n",
    "        print(\"Waiting for policies to propagate...\")\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"Error attaching inline policy to role {role_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ba907-63ac-4eae-9b82-905de058f487",
   "metadata": {},
   "source": [
    "# Creating Amazon Athena Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d4ea4-fafa-4f79-b420-cbaadb6312d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_athena_database(athena_db_name: str, s3_bucket: str):\n",
    "    athena_client = boto3.client('athena', region_name=variables['regionName'])\n",
    "    \n",
    "    # First create the results directory if it doesn't exist\n",
    "    s3_client = boto3.client('s3', region_name=variables['regionName'])\n",
    "    try:\n",
    "        s3_client.put_object(\n",
    "            Bucket=s3_bucket,\n",
    "            Key='athena-query-results/',\n",
    "            Body=''\n",
    "        )\n",
    "        print(f\"Created Athena results directory in bucket {s3_bucket}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Create Athena database\n",
    "        query = f\"CREATE DATABASE IF NOT EXISTS {athena_db_name}\"\n",
    "        response = athena_client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            ResultConfiguration={\n",
    "                'OutputLocation': f's3://{s3_bucket}/athena-query-results/'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Wait for query execution\n",
    "        query_id = response['QueryExecutionId']\n",
    "        print(f\"Started Athena database creation, execution ID: {query_id}\")\n",
    "        \n",
    "        # Wait for completion\n",
    "        status = 'RUNNING'\n",
    "        while status in ['RUNNING', 'QUEUED']:\n",
    "            time.sleep(5)\n",
    "            result = athena_client.get_query_execution(QueryExecutionId=query_id)\n",
    "            status = result['QueryExecution']['Status']['State']\n",
    "        \n",
    "        if status == 'SUCCEEDED':\n",
    "            print(f\"Athena database {athena_db_name} created successfully\")\n",
    "        else:\n",
    "            print(f\"Athena database creation failed with status: {status}\")\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Athena database: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3db55-e2d6-4332-ad7e-1bb7f9d21ce3",
   "metadata": {},
   "source": [
    "# Creating and Starting Glue Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f52917-688b-45ed-9658-12684ce5097e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_glue_crawler(crawler_name: str, s3_input_bucket: str, path_to_the_folder: str, role_name: str, athena_db_name: str):\n",
    "    glue_client = boto3.client('glue', region_name=variables['regionName'])\n",
    "    \n",
    "    try:\n",
    "        # Check if the crawler already exists\n",
    "        glue_client.get_crawler(Name=crawler_name)\n",
    "        print(f\"Crawler {crawler_name} already exists.\")\n",
    "    except glue_client.exceptions.EntityNotFoundException:\n",
    "        try:\n",
    "            # Create Glue Crawler with dynamic values\n",
    "            response = glue_client.create_crawler(\n",
    "                Name=crawler_name,\n",
    "                Role=role_name,\n",
    "                DatabaseName=athena_db_name,\n",
    "                Targets={\n",
    "                    'S3Targets': [\n",
    "                        {\n",
    "                            'Path': f's3://{s3_input_bucket}/{path_to_the_folder}',\n",
    "                            'Exclusions': []\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                TablePrefix='retail_',\n",
    "                Description='Crawler for retail transactions data'\n",
    "            )\n",
    "            print(f\"Crawler {crawler_name} created successfully.\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating crawler: {e}\")\n",
    "            # Print role info for debugging\n",
    "            iam_client = boto3.client('iam')\n",
    "            try:\n",
    "                role_info = iam_client.get_role(RoleName=role_name)\n",
    "                print(f\"Role ARN: {role_info['Role']['Arn']}\")\n",
    "            except Exception as re:\n",
    "                print(f\"Error getting role details: {re}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def start_glue_crawler(crawler_name: str):\n",
    "    glue_client = boto3.client('glue', region_name=variables['regionName'])\n",
    "\n",
    "    try:\n",
    "        # Start the Glue Crawler execution\n",
    "        glue_client.start_crawler(Name=crawler_name)\n",
    "        print(f\"Crawler {crawler_name} started successfully.\")\n",
    "    except glue_client.exceptions.CrawlerRunningException:\n",
    "        print(f\"Crawler {crawler_name} is already running.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting crawler: {e}\")\n",
    "        return\n",
    "\n",
    "    # Wait for the crawler to finish\n",
    "    print(\"Waiting for crawler to complete...\")\n",
    "    while True:\n",
    "        try:\n",
    "            response = glue_client.get_crawler(Name=crawler_name)\n",
    "            status = response['Crawler']['State']\n",
    "            if status == 'READY':\n",
    "                print(f'Glue Crawler {crawler_name} has completed successfully.')\n",
    "                break\n",
    "            elif status == 'RUNNING':\n",
    "                print(f'Glue Crawler {crawler_name} is still running...')\n",
    "                time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "            else:\n",
    "                print(f'Glue Crawler {crawler_name} status: {status}')\n",
    "                time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking crawler status: {e}\")\n",
    "            time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caedd90-b8ba-4417-93c9-2a0f03a5b426",
   "metadata": {},
   "source": [
    "# Execute the above Methods to create DB & Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9a4bc-0eb1-4a06-82ec-f57163d9ca10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the S3 bucket name from variables\n",
    "try:\n",
    "    s3_bucket = variables['s3Bucket']\n",
    "except (NameError, KeyError):\n",
    "    # If variables dictionary doesn't exist or doesn't have s3Bucket\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.list_buckets()\n",
    "    buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "    print(f\"Available buckets: {buckets}\")\n",
    "    s3_bucket = input(\"Please enter your S3 bucket name: \")\n",
    "\n",
    "# Inputs from user (or dynamically provided)\n",
    "role_name = \"advanced-rag-workshop-glue-role\"\n",
    "crawler_name = \"advanced-rag-workshop-glue-crawler\"\n",
    "path_to_the_folder = \"transactions\"\n",
    "athena_db_name = \"retail\"\n",
    "\n",
    "print(f\"Using S3 bucket: {s3_bucket}\")\n",
    "\n",
    "# Create IAM role\n",
    "role_response = create_iam_role(role_name)\n",
    "\n",
    "# Attach inline policy to IAM role\n",
    "attach_inline_policy_to_role(role_name, athena_db_name, path_to_the_folder, s3_bucket)\n",
    "\n",
    "# Create Athena Database\n",
    "create_athena_database(athena_db_name, s3_bucket)\n",
    "\n",
    "# Create Glue crawler\n",
    "create_glue_crawler(crawler_name, s3_bucket, path_to_the_folder, role_name, athena_db_name)\n",
    "\n",
    "# Start Glue crawler\n",
    "start_glue_crawler(crawler_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c315161-6333-4b82-b080-2ef3cdea45c7",
   "metadata": {},
   "source": [
    "## Query Athena and Display Results as a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8356f8-272b-49fa-953f-8a5f19982825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# AWS Configuration\n",
    "ATHENA_DATABASE = athena_db_name\n",
    "ATHENA_TABLE = \"retail_order\" #\"retail_returns\"\n",
    "S3_OUTPUT_LOCATION = f\"s3://{variables['s3Bucket']}/athena-query-results/\"\n",
    "AWS_REGION = \"us-west-2\"\n",
    "\n",
    "# Initialize Athena client\n",
    "athena_client = boto3.client(\"athena\", region_name=AWS_REGION)\n",
    "\n",
    "# Define Query\n",
    "query = f\"SELECT * FROM {ATHENA_TABLE} LIMIT 10;\"  # Modify query as needed\n",
    "\n",
    "# Start Query Execution\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=query,\n",
    "    QueryExecutionContext={\"Database\": ATHENA_DATABASE},\n",
    "    ResultConfiguration={\"OutputLocation\": S3_OUTPUT_LOCATION},\n",
    ")\n",
    "\n",
    "# Get Query Execution ID\n",
    "query_execution_id = response[\"QueryExecutionId\"]\n",
    "\n",
    "# Wait for Query to Complete\n",
    "while True:\n",
    "    status = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "    state = status[\"QueryExecution\"][\"Status\"][\"State\"]\n",
    "    if state in [\"SUCCEEDED\", \"FAILED\", \"CANCELLED\"]:\n",
    "        break\n",
    "    time.sleep(2)  # Wait before checking again\n",
    "\n",
    "# Check if Query Succeeded\n",
    "if state == \"SUCCEEDED\":\n",
    "    # Fetch Results\n",
    "    results = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "\n",
    "    # Extract Column Names\n",
    "    columns = [col[\"Label\"] for col in results[\"ResultSet\"][\"ResultSetMetadata\"][\"ColumnInfo\"]]\n",
    "\n",
    "    # Extract Row Data\n",
    "    rows = [\n",
    "        [col.get(\"VarCharValue\", \"\") for col in row[\"Data\"]]\n",
    "        for row in results[\"ResultSet\"][\"Rows\"][1:]  # Skip header row\n",
    "    ]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    # Display as Table\n",
    "    display(df)\n",
    "\n",
    "else:\n",
    "    print(f\"Query failed with state: {state}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
