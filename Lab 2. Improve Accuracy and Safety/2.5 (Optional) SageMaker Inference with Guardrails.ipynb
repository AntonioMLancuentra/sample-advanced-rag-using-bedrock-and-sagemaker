{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f54bd49-7753-4ea7-ad64-561c3f04bee9",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with SageMaker Inference and Guardrails\n",
    "\n",
    "## Description\n",
    "This notebook demonstrates how to enhance a Retrieval-Augmented Generation (RAG) pipeline by integrating Amazon SageMaker Inference with Amazon Bedrock. We will walk through the process of querying a knowledge base, using SageMaker for model inference, applying Guardrails to control the generation of responses, and filtering results with metadata to ensure compliance and quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330a12a",
   "metadata": {},
   "source": [
    "![Guardrails](./guardrail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-section",
   "metadata": {},
   "source": [
    "## 1. Import Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from advanced_rag_utils\n",
    "import boto3\n",
    "from advanced_rag_utils import (\n",
    "    load_variables,\n",
    "    create_standard_filter,\n",
    "    setup_bedrock_client,\n",
    "    retrieve_from_bedrock_with_filter,\n",
    "    format_llama3_prompt,\n",
    "    generate_sagemaker_response,\n",
    "    apply_output_guardrail,\n",
    "    retrieve_generate_apply_guardrails\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c8ad1-b488-4c6d-9cad-5dbec4e9c674",
   "metadata": {},
   "source": [
    "## 2. Load Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f715548e-d107-406b-8175-02082fbfe905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accountNumber': '977018081517',\n",
       " 'regionName': 'us-west-2',\n",
       " 'collectionArn': 'arn:aws:aoss:us-west-2:977018081517:collection/x6j41w4wldt22s0mc4oa',\n",
       " 'collectionId': 'x6j41w4wldt22s0mc4oa',\n",
       " 'vectorIndexName': 'ws-index-',\n",
       " 'bedrockExecutionRoleArn': 'arn:aws:iam::977018081517:role/advanced-rag-workshop-bedrock_execution_role-us-west-2',\n",
       " 's3Bucket': '977018081517-us-west-2-advanced-rag-workshop',\n",
       " 'kbFixedChunk': 'WFJRA66ARJ',\n",
       " 'kbSemanticChunk': 'XRQUIKPQAB',\n",
       " 'kbHierarchicalChunk': 'DBCDV6VOVB',\n",
       " 'kbCustomChunk': 'SVUWGDQTQZ',\n",
       " 'sagemakerLLMEndpoint': 'endpoint-llama-3-2-3b-instruct-2025-05-01-17-04-39',\n",
       " 'guardrail_id': 'vcd1cw90tu5w',\n",
       " 'guardrail_version': '1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load configuration variables from a JSON file\n",
    "variables = load_variables(\"../variables.json\")\n",
    "variables  # Display the loaded variables for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e81ed4-198a-4884-9f5f-463959d76c49",
   "metadata": {},
   "source": [
    "## 3. Set Up Required IDs and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b8fa96-7072-4b10-ac06-3f9f87f522cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Selection  \n",
    "kb_id = variables[\"kbFixedChunk\"]  # Options: \"kbFixedChunk\", \"kbHierarchicalChunk\", \"kbSemanticChunk\"\n",
    "\n",
    "# Retrieve guardrail details\n",
    "guardrail_id = variables[\"guardrail_id\"]\n",
    "guardrail_version = variables[\"guardrail_version\"]\n",
    "\n",
    "# SageMaker endpoint\n",
    "sagemaker_endpoint = variables['sagemakerLLMEndpoint']\n",
    "\n",
    "# Retrieval-Augmented Generation (RAG) Configuration  \n",
    "number_of_results = 3  # Number of relevant documents to retrieve  \n",
    "generation_configuration = {\n",
    "    \"temperature\": 0,  # Lower temperature for more deterministic responses  \n",
    "    \"top_k\": 10,  # Consider top 10 tokens at each generation step  \n",
    "    \"max_new_tokens\": 5000,  # Maximum number of tokens to generate  \n",
    "    \"stop\": \"<|eot_id|>\"  # Stop sequence to end the response generation  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b616d4-1d81-44ce-af45-f4e188f0539b",
   "metadata": {},
   "source": [
    "## 4. Define Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00f993f-efbd-492a-a5c2-97242d02ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standard filter for document type and year\n",
    "metadata_filter = create_standard_filter('10K Report', 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34fd89-baef-4bad-83ba-5820b93c4ca2",
   "metadata": {},
   "source": [
    "## 5. Initialize Bedrock Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initialize-clients",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bedrock clients\n",
    "bedrock_agent_client = setup_bedrock_client(variables[\"regionName\"])\n",
    "bedrock_runtime_client = boto3.client(\"bedrock-runtime\", region_name=variables[\"regionName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cab666-18d4-4c18-9c3f-c7f1b2b2f82f",
   "metadata": {},
   "source": [
    "## 6: Test Guardrails for Investment Advice\n",
    "Let's ask the model for investment advice. When we created the guardrails, we restricted Bedrock from providing any investment advice. Bedrock should return a preconfigured response \"This request cannot be processed due to safety protocols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45aee165-d50d-4cb7-beaa-fff5d35a91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query for testing investment advice restriction\n",
    "query = \"based on your amazon's results should I buy amazon stock?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f12c5f-4477-440f-94a2-fbe36b35bee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: {\"based on your amazon's results should I buy amazon stock?\"}\n",
      "\n",
      "Raw Response (Without Guardrails):\n",
      "\n",
      "\n",
      "I don't know.\n",
      "\n",
      "Guardrail Response:\n",
      "\n",
      "\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Use the comprehensive function to perform the RAG pipeline with guardrails\n",
    "guardrail_response, raw_response, context = retrieve_generate_apply_guardrails(\n",
    "    query=query,\n",
    "    knowledge_base_id=kb_id,\n",
    "    sagemaker_endpoint=sagemaker_endpoint,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version,\n",
    "    metadata_filter=metadata_filter,\n",
    "    generation_config=generation_configuration,\n",
    "    bedrock_agent_client=bedrock_agent_client,\n",
    "    bedrock_runtime_client=bedrock_runtime_client,\n",
    "    num_results=number_of_results,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# Print the query and response\n",
    "print(\"Question:\", {query})\n",
    "# print(f\"Context: {context}\")  # Uncomment for debugging\n",
    "print(\"\\nRaw Response (Without Guardrails):\")\n",
    "print(raw_response)\n",
    "print(\"\\nGuardrail Response:\")\n",
    "print(guardrail_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5dfb7-581f-4264-9024-f6a5a61c8cf7",
   "metadata": {},
   "source": [
    "## 7. Test Guardrails for PII Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed6d7c4-f93e-4692-b8c1-92d595c0c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query for testing PII anonymization\n",
    "query=\"Who is the current CFO of Amazon?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4183f04d-7a31-4753-a73a-7ee7bb97ddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: {'Who is the current CFO of Amazon?'}\n",
      "\n",
      "Raw Response (Without Guardrails):\n",
      "\n",
      "\n",
      "According to the provided context, the current CFO of Amazon is Brian T. Olsavsky, who has served as Senior Vice President and Chief Financial Officer since June 2015.\n",
      "\n",
      "Guardrail Response (With PII Anonymization):\n",
      "\n",
      "\n",
      "According to the provided context, the current CFO of Amazon is {NAME}, who has served as Senior Vice President and Chief Financial Officer since June 2015.\n"
     ]
    }
   ],
   "source": [
    "# Use the comprehensive function to perform the RAG pipeline with guardrails\n",
    "guardrail_response, raw_response, context = retrieve_generate_apply_guardrails(\n",
    "    query=query,\n",
    "    knowledge_base_id=kb_id,\n",
    "    sagemaker_endpoint=sagemaker_endpoint,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version,\n",
    "    metadata_filter=metadata_filter,\n",
    "    generation_config=generation_configuration,\n",
    "    bedrock_agent_client=bedrock_agent_client,\n",
    "    bedrock_runtime_client=bedrock_runtime_client,\n",
    "    num_results=number_of_results,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# Print the query and response\n",
    "print(\"Question:\", {query})\n",
    "# print(f\"Context: {context}\")  # Uncomment for debugging\n",
    "print(\"\\nRaw Response (Without Guardrails):\")\n",
    "print(raw_response)\n",
    "print(\"\\nGuardrail Response (With PII Anonymization):\")\n",
    "print(guardrail_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-by-step-section",
   "metadata": {},
   "source": [
    "## 8. (Optional) Step-by-Step Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "step-by-step-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: {'Who is the current CFO of Amazon?'}\n",
      "\n",
      "Raw Response (Without Guardrails):\n",
      "\n",
      "\n",
      "According to the provided context, the current CFO of Amazon is Brian T. Olsavsky, who has served as Senior Vice President and Chief Financial Officer since June 2015.\n",
      "\n",
      "Guardrail Response:\n",
      "\n",
      "\n",
      "According to the provided context, the current CFO of Amazon is {NAME}, who has served as Senior Vice President and Chief Financial Officer since June 2015.\n"
     ]
    }
   ],
   "source": [
    "# If you prefer to execute the steps individually:\n",
    "\n",
    "# 1. Retrieve context from Bedrock KB with metadata filtering\n",
    "context = retrieve_from_bedrock_with_filter(\n",
    "    query=query,\n",
    "    knowledge_base_id=kb_id,\n",
    "    metadata_filter=metadata_filter,\n",
    "    bedrock_client=bedrock_agent_client,\n",
    "    num_results=number_of_results,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# 2. Format prompt using retrieved context\n",
    "prompt = format_llama3_prompt(query, context)\n",
    "\n",
    "# 3. Generate response using SageMaker endpoint\n",
    "raw_response = generate_sagemaker_response(\n",
    "    prompt=prompt,\n",
    "    endpoint_name=sagemaker_endpoint,\n",
    "    generation_config=generation_configuration\n",
    ")\n",
    "\n",
    "# 4. Apply guardrails to the output\n",
    "guardrail_response = apply_output_guardrail(\n",
    "    output_text=raw_response,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version,\n",
    "    bedrock_client=bedrock_runtime_client,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# 5. Display results\n",
    "print(\"Question:\", {query})\n",
    "# print(f\"Context: {context}\")  # Uncomment for debugging\n",
    "print(\"\\nRaw Response (Without Guardrails):\")\n",
    "print(raw_response)\n",
    "print(\"\\nGuardrail Response:\")\n",
    "print(guardrail_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
