{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c12a22c-1690-4624-93aa-02082c006e33",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with Metadata Filtering\n",
    "\n",
    "### Description:\n",
    "This notebook demonstrates how to query and retrieve data from an Amazon Bedrock-powered knowledge base using different configurations, filters, and citation extraction. The steps include creating a query, retrieving responses, and printing the citations used for generating the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc37008",
   "metadata": {},
   "source": [
    "![Metadata Filtering](./metadata_filtering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e05a5d-8cf4-4c26-a66e-9069d145752f",
   "metadata": {},
   "source": [
    "## 1. Load Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033e1f7-8060-4489-b5f7-e1bb6e3f89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration variables from a JSON file to access knowledge base ID, account number, and guardrail info.\n",
    "import json\n",
    "\n",
    "with open(\"../variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables  # Display the loaded variables for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f9f7f-3a4c-4f95-b7b4-50e20d8db859",
   "metadata": {},
   "source": [
    "## 2. Set Up Required IDs and Model ARNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92773810-baf9-4718-aaa2-683e2fba2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accountNumber=variables['accountNumber']   \n",
    "knowledge_base_id = variables['kbSemanticChunk']   \n",
    "model_id = 'us.amazon.nova-pro-v1:0' \n",
    "model_arn = f\"arn:aws:bedrock:us-west-2:{accountNumber}:inference-profile/{model_id}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787578b9-2c24-47f0-8430-9b26d8157aae",
   "metadata": {},
   "source": [
    "## 3. Configure Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07b9c5-ed24-4bfa-9aaf-a0f7dd6491b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "# Configure the Bedrock client\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=\"us-west-2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ff073-78af-4909-b583-362bb98e7c3b",
   "metadata": {},
   "source": [
    "## 4. Define Function to Retrieve and Generate Without Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5c546-c0da-4629-8d02-e24740609852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate_without_filter(query, knowledge_base_id, model_arn):\n",
    "    \"\"\"\n",
    "    Retrieves and generates a response based on the given query.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The input query.\n",
    "    - knowledge_base_id (str): The ID of the knowledge base.\n",
    "    - model_arn (str): The ARN of the model.\n",
    "    - one_group_filter (dict): The filter for the vector search configuration.\n",
    "\n",
    "    Returns:\n",
    "    - response: The response from the retrieve_and_generate method.\n",
    "    \"\"\"\n",
    "    response = bedrock_agent_runtime.retrieve_and_generate(\n",
    "        input={\n",
    "            \"text\": query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                'knowledgeBaseId': knowledge_base_id,\n",
    "                \"modelArn\": model_arn,\n",
    "                \"retrievalConfiguration\": {\n",
    "                    \"vectorSearchConfiguration\": {\n",
    "                        \"numberOfResults\": 5\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043e897-864e-42bf-b31f-3cb35961fa1a",
   "metadata": {},
   "source": [
    "## 5. Define Function to Retrieve and Generate With Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927a20b-a528-455f-8cab-7013120f1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate_with_filter(query, knowledge_base_id, model_arn, metadata_filter):\n",
    "    \"\"\"\n",
    "    Retrieves and generates a response based on the given query.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The input query.\n",
    "    - knowledge_base_id (str): The ID of the knowledge base.\n",
    "    - model_arn (str): The ARN of the model.\n",
    "    - one_group_filter (dict): The filter for the vector search configuration.\n",
    "\n",
    "    Returns:\n",
    "    - response: The response from the retrieve_and_generate method.\n",
    "    \"\"\"\n",
    "    response = bedrock_agent_runtime.retrieve_and_generate(\n",
    "        input={\n",
    "            \"text\": query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                'knowledgeBaseId': knowledge_base_id,\n",
    "                \"modelArn\": model_arn,\n",
    "                \"retrievalConfiguration\": {\n",
    "                    \"vectorSearchConfiguration\": {\n",
    "                        \"numberOfResults\": 5,\n",
    "                        \"filter\": metadata_filter\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261e509-7fc8-40fb-a6e1-a017eb793e63",
   "metadata": {},
   "source": [
    "## 6. Define Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b6684-1175-4aff-a85e-9b1f5b3c8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what was the % increase in sales?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e9ceb-d844-416e-ab9b-ac4301807621",
   "metadata": {},
   "source": [
    "## 7. Retrieve Response Without Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107946cb-8a6e-4e42-8a8b-95ccd204b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_withoutMetadata=retrieve_and_generate_without_filter(query, knowledge_base_id, model_arn)\n",
    "print(response_withoutMetadata['output']['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff170a-0d68-4bf8-81d5-9dc7c0c0fa07",
   "metadata": {},
   "source": [
    "## 8. Retrieve and Print Citations Without Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0aedf-2b15-42d9-b8f1-46499c55fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract citations used to generate the response\n",
    "response_without_MD = response_withoutMetadata['citations'][0]['retrievedReferences']\n",
    "print(\"# of citations or chunks used to generate the response: \", len(response_without_MD))\n",
    "\n",
    "# Function to print citations or chunks of text retrieved\n",
    "def citations_rag_print(response_ret):\n",
    "    for num, chunk in enumerate(response_ret, 1):\n",
    "        print(f'Chunk {num}: ', chunk['content']['text'], end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ', chunk['location'], end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ', chunk['metadata'], end='\\n'*2)\n",
    "\n",
    "# Print citations\n",
    "citations_rag_print(response_without_MD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f1a6c-ee60-4016-8559-222f77310071",
   "metadata": {},
   "source": [
    "## 9. Define Metadata Filter\n",
    "\n",
    "The code below defines a metadata filter to narrow down the knowledge base search:\n",
    "- Creates a complex filter using logical operators (andAll)\n",
    "- The filter has two conditions that must both be true:\n",
    "  1. docType must equal '10K Report'\n",
    "  2. year must equal 2023\n",
    "- This filter will limit retrieval to only chunks from 2023 10K reports\n",
    "- The structure demonstrates how to build more complex queries with multiple conditions\n",
    "\n",
    "This filter will be used to demonstrate selective retrieval from specific documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b0092-1cef-49fe-ace7-1f7250fd61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a metadata filter for advanced filtering based on specific conditions\n",
    "one_group_filter= {\n",
    "    \"andAll\": [\n",
    "        {\n",
    "            \"equals\": {\n",
    "                \"key\": \"docType\",\n",
    "                \"value\": '10K Report'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"equals\": {\n",
    "                \"key\": \"year\",\n",
    "                \"value\": 2023\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c40149e-0ac6-4ede-99c7-ab2e41f43ee0",
   "metadata": {},
   "source": [
    "## 10. Retrieve Response With Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81dcdb-9456-49ed-a2d1-1102ec199879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to retrieve a response with metadata filtering\n",
    "response_with_Metadata = retrieve_and_generate_with_filter(query, knowledge_base_id, model_arn, one_group_filter)\n",
    "\n",
    "# Print the response text\n",
    "print(response_with_Metadata['output']['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c632fb1-271d-46dc-ad9a-9d9a4c7d145a",
   "metadata": {},
   "source": [
    "## 11. Retrieve and Print Citations With Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92920fad-2e96-4d8d-96c1-e8aebc70ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract citations used to generate the response with metadata filter\n",
    "response_with_MD = response_with_Metadata['citations'][0]['retrievedReferences']\n",
    "print(\"# of citations or chunks used to generate the response: \", len(response_with_MD))\n",
    "\n",
    "# Print citations for the filtered response\n",
    "citations_rag_print(response_with_MD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05fe8e",
   "metadata": {},
   "source": [
    "## 12. Advanced Metadata Filtering\n",
    "\n",
    "Dynamically creating metadata fliters allows  to create query-specific filters programmatically rather than hardcoding them.\n",
    "\n",
    "This cell defines a function to create  metadata filters programatically based on various parameters:\n",
    "- company: Filter by company name\n",
    "- year: Filter by year (can be a single year or list of years)\n",
    "- docType: Filter by document type\n",
    "- min_page/max_page: Filter by page number ranges\n",
    "- s3_prefix: Filter by S3 URI prefix\n",
    "The function builds a filter configuration based on the provided parameters,\n",
    "combining them with appropriate operators (equals, greaterThanOrEquals, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_filter(company=None, year=None, docType=None, min_page=None, max_page=None, s3_prefix=None):\n",
    "    \"\"\"\n",
    "    Creates a dynamic metadata filter for Amazon Bedrock Knowledge Base queries.\n",
    "    \n",
    "    Parameters:\n",
    "    - company (str or list): Filter by company name (e.g., 'Amazon')\n",
    "    - year (int or list): Filter by year or list of years\n",
    "    - docType (str): Filter by document type (e.g., '10K Report')\n",
    "    - min_page (int): Filter for pages greater than or equal to this number\n",
    "    - max_page (int): Filter for pages less than or equal to this number\n",
    "    - s3_prefix (str): Filter by S3 URI prefix\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A metadata filter configuration or None if no valid filters\n",
    "    \"\"\"\n",
    "    filter_conditions = []\n",
    "    \n",
    "    # Add company filter if specified and not empty\n",
    "    if company:\n",
    "        if isinstance(company, list):\n",
    "            # Filter out empty strings and check if we have any values left\n",
    "            company_list = [c for c in company if c]\n",
    "            if len(company_list) >= 2:\n",
    "                # If we have at least 2 valid values, use orAll\n",
    "                company_conditions = []\n",
    "                for c in company_list:\n",
    "                    company_conditions.append({\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"company\",\n",
    "                            \"value\": c\n",
    "                        }\n",
    "                    })\n",
    "                filter_conditions.append({\"orAll\": company_conditions})\n",
    "            elif len(company_list) == 1:\n",
    "                # If only one valid company, use a direct equals condition\n",
    "                filter_conditions.append({\n",
    "                    \"equals\": {\n",
    "                        \"key\": \"company\",\n",
    "                        \"value\": company_list[0]\n",
    "                    }\n",
    "                })\n",
    "        elif isinstance(company, str) and company.strip():  # Check if string is not just whitespace\n",
    "            filter_conditions.append({\n",
    "                \"equals\": {\n",
    "                    \"key\": \"company\",\n",
    "                    \"value\": company\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Add year filter (single year or multiple years)\n",
    "    if year:\n",
    "        if isinstance(year, list):\n",
    "            # Filter out empty values and check if we have any values left\n",
    "            year_list = [y for y in year if y]\n",
    "            if len(year_list) >= 2:\n",
    "                # If we have at least 2 valid values, use orAll\n",
    "                year_conditions = []\n",
    "                for y in year_list:\n",
    "                    year_conditions.append({\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"year\",\n",
    "                            \"value\": y\n",
    "                        }\n",
    "                    })\n",
    "                filter_conditions.append({\"orAll\": year_conditions})\n",
    "            elif len(year_list) == 1:\n",
    "                # If only one valid year, use a direct equals condition\n",
    "                filter_conditions.append({\n",
    "                    \"equals\": {\n",
    "                        \"key\": \"year\",\n",
    "                        \"value\": year_list[0]\n",
    "                    }\n",
    "                })\n",
    "        elif str(year).strip():  # Convert to string and check if not just whitespace\n",
    "            filter_conditions.append({\n",
    "                \"equals\": {\n",
    "                    \"key\": \"year\",\n",
    "                    \"value\": year\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Add document type filter if specified and not empty\n",
    "    if docType and (not isinstance(docType, str) or docType.strip()):\n",
    "        filter_conditions.append({\n",
    "            \"equals\": {\n",
    "                \"key\": \"docType\",\n",
    "                \"value\": docType\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add minimum page filter if specified\n",
    "    if min_page is not None:\n",
    "        filter_conditions.append({\n",
    "            \"greaterThanOrEquals\": {\n",
    "                \"key\": \"x-amz-bedrock-kb-document-page-number\",\n",
    "                \"value\": min_page\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add maximum page filter if specified\n",
    "    if max_page is not None:\n",
    "        filter_conditions.append({\n",
    "            \"lessThanOrEquals\": {\n",
    "                \"key\": \"x-amz-bedrock-kb-document-page-number\",\n",
    "                \"value\": max_page\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Add S3 prefix filter if specified and not empty\n",
    "    if s3_prefix and (not isinstance(s3_prefix, str) or s3_prefix.strip()):\n",
    "        filter_conditions.append({\n",
    "            \"startsWith\": {\n",
    "                \"key\": \"x-amz-bedrock-kb-source-uri\",\n",
    "                \"value\": s3_prefix\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Return the complete filter only if we have TWO OR MORE conditions\n",
    "    # The API requires at least 2 conditions for andAll\n",
    "    if len(filter_conditions) >= 2:\n",
    "        return {\"andAll\": filter_conditions}\n",
    "    # If we have exactly ONE condition, return it directly without andAll\n",
    "    elif len(filter_conditions) == 1:\n",
    "        return filter_conditions[0]\n",
    "    else:\n",
    "        # Return None if no valid conditions\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfff6a",
   "metadata": {},
   "source": [
    "## Query Financial Data Function\n",
    "This cell creates a higher-level function that uses the dynamic filter:\n",
    "- Takes a query text and various filter parameters\n",
    "- Creates a filter using the create_dynamic_filter function\n",
    "- Prints the filter configuration for debugging\n",
    "- Calls retrieve_and_generate_with_filter with the created filter\n",
    "- Returns the complete response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc105b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_financial_data(query_text, kb_id, model_arn, **filter_params):\n",
    "    \"\"\"\n",
    "    Perform a query against financial data with dynamic filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    - query_text (str): The natural language query\n",
    "    - kb_id (str): Knowledge base ID\n",
    "    - model_arn (str): Model ARN\n",
    "    - **filter_params: Parameters to pass to create_dynamic_filter\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Response from Bedrock\n",
    "    \"\"\"\n",
    "    # Create the filter\n",
    "    filter_config = create_dynamic_filter(**filter_params)\n",
    "    \n",
    "    # Log the filter for debugging\n",
    "    print(\"Using filter configuration:\")\n",
    "    print(json.dumps(filter_config, indent=2) if filter_config else \"No filter applied\")\n",
    "    \n",
    "    # Run the query with or without filter based on whether we have a valid filter\n",
    "    if filter_config is not None:\n",
    "        response = retrieve_and_generate_with_filter(\n",
    "            query_text, kb_id, model_arn, filter_config\n",
    "        )\n",
    "    else:\n",
    "        # If no filter conditions, call the function without filter\n",
    "        response = retrieve_and_generate_without_filter(\n",
    "            query_text, kb_id, model_arn\n",
    "        )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare growth rates across all Amazon business segments\n",
    "from utils import print_citations\n",
    "response = query_financial_data(\n",
    "    \"Compare the year-over-year growth rates for AWS, North America, and International segments, including factors that influenced performance differences\",\n",
    "    knowledge_base_id,\n",
    "    model_arn,\n",
    "    company=\"Amazon\",\n",
    "    year=[2023, 2024]\n",
    ")\n",
    "print_citations(response)\n",
    "#print(response['output']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db256efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 2023 documents in a specific folder\n",
    "s3_prefix_2023 = f\"s3://{variables['s3Bucket']}/pdf_documents/\"\n",
    "\n",
    "response_2023 = query_financial_data(\n",
    "    \"What was the AWS revenue growth in 2023?\",\n",
    "    knowledge_base_id,\n",
    "    model_arn,\n",
    "    year=[2023,2024],\n",
    "    s3_prefix=s3_prefix_2023\n",
    ")\n",
    "\n",
    "#print(response_2023['output']['text'])\n",
    "print_citations(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f328c22-93d6-4a48-aad0-0a5642a7e32b",
   "metadata": {},
   "source": [
    "### Dynamic Entity extraction to create filters on the fly\n",
    "In the examples so far you knew the filters that you need to apply. Perhaps your application forces the user to pick a year or department name while asking questions. In those situations, the above approach would work.\n",
    "However, you may have a situation where there is no way for a user to specify filters. Thus, the application may, at run time, have to figure out the filters based on a question.\n",
    "For example, assume that your documents are stored in respective department folders such as HR, Finance, Legal, Science, Engineering, Customer Support, etc. \n",
    "Assume that your user asks an HR related question. There are two options for you.\n",
    "### Option 1: \n",
    "You create a vector embedding for HR related questions and search the vector space in the entire knowledgebase. This will give you some context and might even pick up some HR related content from customer support content.\n",
    "### Option 2: \n",
    "You ask an LLM to determine the topic to which the question most likely belongs to.Then you use the topic as a filter to query the knowledge base. This limits the search to fewer topics and hence reduces the noise from unrelated topics.\n",
    "While this mightb improve accuracy because of richer context with reduced noise, this would also introduce extra costs because of an extra call to LLM to determine the topic to which the questuon belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5b9d0-5836-4678-bb35-237517b1b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_by_key_path(d, path):\n",
    "    \"\"\"\n",
    "    Retrieve a value from a nested dictionary using a key path.\n",
    "\n",
    "    Args:\n",
    "        d (dict): The dictionary to search.\n",
    "        path (list): List of keys forming the path to the desired value.\n",
    "\n",
    "    Returns:\n",
    "        The value at the specified path, or None if not found.\n",
    "    \"\"\"\n",
    "    current = d\n",
    "    for key in path:\n",
    "        try:\n",
    "            current = current[key]\n",
    "        except (KeyError, IndexError, TypeError):\n",
    "            return None  # Return None if the path is invalid (key not found, wrong type, etc.)\n",
    "    return current\n",
    "    \n",
    "def invoke_converse(\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    model_id: str,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 4000\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Chat with a Bedrock model using the Converse API.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): System instructions/context\n",
    "        user_prompt (str): User's input/question\n",
    "        model_id (str): Bedrock model ID\n",
    "        temperature (float): Controls randomness (0.0 to 1.0)\n",
    "        max_tokens (int): Maximum tokens in response\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: Model's response or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Bedrock Runtime client with configuration\n",
    "        client = boto3.client('bedrock-runtime', region_name=variables['regionName'] )\n",
    "        \n",
    "        # Prepare the system prompt from session state\n",
    "        system_prompt = [{'text': system_prompt}]\n",
    "        messages = []\n",
    "\n",
    "        # Format the user's question as a message\n",
    "        message = {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [            \n",
    "                {\n",
    "                    \"text\": f\"{user_prompt}\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Set inference configuration\n",
    "        messages.append(message)\n",
    "        inferenceConfig = {\n",
    "            \"maxTokens\" : 4096,\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "        \n",
    "        #invoke the API\n",
    "        answer = \"\"\n",
    "        response = client.converse(modelId=model_id, \n",
    "                                messages=messages,\n",
    "                                system=system_prompt,\n",
    "                                inferenceConfig = inferenceConfig)\n",
    "        \n",
    "        # Process the response\n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] == 200 :\n",
    "            # Extract and concatenate the content from the response \n",
    "            content_list = get_value_by_key_path(response, ['output', 'message', 'content'])\n",
    "            answer = \"\"\n",
    "            for content in content_list :\n",
    "                text = content.get('text')\n",
    "                if text:  # Concatenate only if text is not None\n",
    "                    answer += text\n",
    "        else :\n",
    "            # Format an error message if the request was unsuccessful\n",
    "            answer = f\"Error: {response['ResponseMetadata']['HTTPStatusCode']} - {response['Error']['Message']}\"\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in invoke_converse: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e9b5c-0331-4fca-84c3-e69c7ba962b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prompt template with Model Instructions:\n",
    "system_prompt = \"\"\"\n",
    "You are an expert in extracting entity from queries so that those entities can be used as filters.\n",
    "\n",
    "Model Instructions:\n",
    "- If company name and year is mentioned in the Query, extract them as entities.\n",
    "- Return the information strictly in JSON format where company and year are keys and their corresponding values are an array of strings.\n",
    "- If you are not sure if company name and year is mentioned in the query, please return an empty list for the corresponding entity.\n",
    "- Please do not return any explanation.\n",
    "\n",
    "$Query$\n",
    "\"\"\"\n",
    "\n",
    "# user prompt\n",
    "user_prompt = \"Compare the year-over-year growth rates for AWS, North America, and International segments, including factors that influenced performance differences in years 2023 and 2024.\"\n",
    "user_prompt = \"In Amazon's cash flow statement, what was the net income in years 2023 and 2024?\"\n",
    "\n",
    "# Send the system prompt and user prompt to an LLM and get the response.\n",
    "model_id = \"anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "response = invoke_converse(system_prompt, user_prompt, model_id)\n",
    "\n",
    "# load the response into a json format.\n",
    "data = json.loads(response)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34858df3-085c-47b8-b6fb-d219bce2d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract years as a list of integers.\n",
    "if 'year' in data :\n",
    "    years = data['year']\n",
    "    years = [int(x) for x in years]\n",
    "else :\n",
    "    years = []\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe712d-373b-4cac-969d-186e3691c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract company names as a list of strings.\n",
    "if 'company' in data :\n",
    "    company = data['company']\n",
    "else :\n",
    "    company = []\n",
    "company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b4a69-a33b-48a3-a5c2-07927f3a7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_financial_data(\n",
    "    user_prompt,\n",
    "    knowledge_base_id,\n",
    "    model_arn,\n",
    "    company=company,\n",
    "    year=years\n",
    ")\n",
    "print_citations(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
